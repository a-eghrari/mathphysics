% file: AGAT_dump.tex
% Algebraic Geometry, Algebraic Topology, in unconventional ``grande'' format; fitting a widescreen format
% 
% github        : ernestyalumni
% linkedin      : ernestyalumni 
% wordpress.com : ernestyalumni
%
% This code is open-source, governed by the Creative Common license.  Use of this code is governed by the Caltech Honor Code: ``No member of the Caltech community shall take unfair advantage of any other member of the Caltech community.'' 
% 

\documentclass[10pt]{amsart}
\pdfoutput=1
%\usepackage{mathtools,amssymb,lipsum,caption}
\usepackage{mathtools,amssymb,caption}


\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage[table]{xcolor}
\usepackage{pdfpages}
%\usepackage[version=3]{mhchem}
%\usepackage{mhchem}

\usepackage{tikz}
% decorations.pathmorphing for decoration, snake
\usetikzlibrary{matrix,arrows,decorations.pathmorphing,backgrounds} % background for framed option
\usetikzlibrary{arrows.meta}
\usetikzlibrary{cd}

\usepackage{multicol}

% ----------------------------------------------------------------------------------------
% 20180203

\usetikzlibrary{calc}

% ----------------------------------------------------------------------------------------


\hypersetup{colorlinks=true,citecolor=[rgb]{0,0.4,0}}

\oddsidemargin=15pt
\evensidemargin=5pt
\hoffset-45pt
\voffset-55pt
\topmargin=-4pt
\headsep=5pt
\textwidth=1120pt
\textheight=595pt
\paperwidth=1200pt
\paperheight=700pt
\footskip=40pt


\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{axiom}{Axiom}
%\newtheorem*{main}{Main Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}

\newtheorem{definition}{Definition}
\newtheorem{remark}{Remark}

\newenvironment{claim}[1]{\par\noindent\underline{Claim:}\space#1}{}
\newenvironment{claimproof}[1]{\par\noindent\underline{Proof:}\space#1}{\hfill $\blacksquare$}

%This defines a new command \questionhead which takes one argument and
%prints out Question #. with some space.
\newcommand{\questionhead}[1]
  {\bigskip\bigskip
   \noindent{\small\bf Question #1.}
   \bigskip}

\newcommand{\problemhead}[1]
  {
   \noindent{\small\bf Problem #1.}
   }

\newcommand{\exercisehead}[1]
  { \smallskip
   \noindent{\small\bf Exercise #1.}
  }

\newcommand{\solutionhead}[1]
  {
   \noindent{\small\bf Solution #1.}
   }


\title{The Algebraic Geometry Algebraic Topology Dump}
\author{Ernest Yeung \href{mailto:ernestyalumni@gmail.com}{ernestyalumni@gmail.com}}
\date{5 mars 2017}
\keywords{Algebraic Geometry, Algebraic Topology}
\begin{document}

\definecolor{darkgreen}{rgb}{0,0.4,0}
\lstset{language=Python,
 frame=bottomline,
 basicstyle=\scriptsize,
 identifierstyle=\color{blue},
 keywordstyle=\bfseries,
 commentstyle=\color{darkgreen},
 stringstyle=\color{red},
 }
%\lstlistoflistings

\maketitle

From the beginning of 2016, I decided to cease all explicit crowdfunding for any of my materials on physics, math.  I failed to raise \emph{any} funds from previous crowdfunding efforts.  I decided that if I was going to live in \emph{abundance}, I must lose a scarcity attitude.  I am committed to keeping all of my material \textbf{open-sourced}.  I give all my stuff \emph{for free}.   

In the beginning of 2017, I received a very generous donation from a reader from Norway who found these notes useful, through \emph{PayPal}.  If you find these notes useful, feel free to donate directly and easily through \href{https://www.paypal.com/cgi-bin/webscr?cmd=_donations&business=ernestsaveschristmas%2bpaypal%40gmail%2ecom&lc=US&item_name=ernestyalumni&currency_code=USD&bn=PP%2dDonationsBF%3abtn_donateCC_LG%2egif%3aNonHosted}{PayPal}, which won't go through a 3rd. party such as indiegogo, kickstarter, patreon.  Otherwise, under the \emph{open-source MIT license}, feel free to copy, edit, paste, make your own versions, share, use as you wish.    

\noindent gmail        : ernestyalumni \\
linkedin     : ernestyalumni \\
twitter      : ernestyalumni \\

\begin{multicols*}{2}

  
\setcounter{tocdepth}{1}
\tableofcontents



\begin{abstract}
Everything about Algebraic Geometry, Algebraic Topology

\end{abstract}

\part{Algebra; Groups, Rings, R-Modules, Categories}

We should know some algebra.  I will follow mostly Rotman (2010) \cite{JRotman2010}.  

\section{Prime numbers, GCD (greatest common denominator), integers, Euler's totient, Chinese Remainder Theorem, integer divison, modulus, remainders; Euclid's Lemma}


%--------------------------------------------------------------------------------
% 20180311 
%-------------------------------------------------------------------------------

\begin{definition}[natural numbers $\mathbb{N}$]
	natural numbers $\mathbb{N}$  
	
	\begin{equation}
	\mathbb{N} = \lbrace \text{ integers } n | n \geq 0 \rbrace  
	\end{equation}
i.e. $\mathbb{N}$ is set of all nonnegative integers.  	
\end{definition}

\begin{definition}[prime]
natural number $p$ is \textbf{prime} if $p\geq 2$, and $\nexists$ \emph{ factorization} $p=ab$, where $a<p$, $b<p$ are natural numbers.  	
\end{definition}

\begin{definition}
	$a,b\in \mathbb{Z}$ \textbf{relatively prime} if $\gcd(a,b)=1 $
\end{definition}



%--------------------------------------------------------------------------------
% END of 20180311 
%-------------------------------------------------------------------------------



\begin{axiom} \textbf{Least Integer Axiom}
	$\exists \, $ smallest integer in every $C \subset \mathbb{N}$, $C\neq \emptyset$
\end{axiom}
cf. pp. 1, Ch. 1 Things Past of Rotman (2010) \cite{JRotman2010}  


\begin{theorem}[\textbf{Division Algorithm}]\label{Thm:DivisionAlgorithm} 
	$\forall \, a , b \in \mathbb{Z}$, $a\neq 0$, $\exists \, ! \, q,r \in \mathbb{Z}$ s.t. 
	\[
	b = qa + r \text{ and } 0 \leq r < |a|
	\]
\end{theorem}


\begin{proof}
	Consider $n \in \mathbb{Z}$, $b-na \in \mathbb{Z}$ \\
	Let $C= \lbrace b - na | n \in \mathbb{Z} \rbrace \bigcap \mathbb{N}$.  \\
	\phantom{\quad} $C\neq \emptyset$ (otherwise, consider $b-na < 0$, $b<na$, then contradiction) \\
	By Least Integer Axiom, $\exists \, $ smallest $r\in C$, $r= b-na$.  \\
	\phantom{\quad } define $q=n$ when $r=b-na$.  \\
	Suppose \\
	$\begin{aligned}  & \quad \\ & qa + r = q'a + r' \\ & (q-q')a = r'-r \\ & |(q-q')a| = |r'-r| \end{aligned}$, \\

	$0\leq r' < |a|$.  Now $0\leq |r'-r | < |a|$ \\
	\phantom{\quad } if $|q-q'| \neq 0$, $|(q-q')a | \geq |a|$ 
	\[
	\Longrightarrow q=q', r=r'
	\]
	Conclude both sides are $0$ (by contradiction)
\end{proof}
cf. pp. 2, Thm. 1.4, Ch. 1 Things Past of Rotman (2010) \cite{JRotman2010}  

\begin{definition}[divisor]
	$a,b \in \mathbb{Z}$, $a$ \textbf{divisor} of $b$ if $\exists \, d \in \mathbb{Z}$ s.t. $b=ad$. \\
	$a$ \textbf{divides} $b$ or $b$ multiple of $a$, denote 
	\[
	a | b
	\]
	$a|b$ iff $b$ has remainder $r=0$ after dividing by $a$
\end{definition}
cf. pp. 3, Ch. 1 Things Past of Rotman (2010) \cite{JRotman2010}  


\subsection{Greatest Common Denominator (GCD); Euclid's Lemma}

\begin{definition}[common divisor]
	\textbf{common divisor} of integers $a$ and $b$, is integer $c$, s.t. $ c | a$ \emph{and} $c|b$.  

\textbf{greatest common divisor} or \textbf{gcd} of $a$ and $b$, denoted $(a,b) \equiv \text{gcd}(a,b)$ defined by 
\[
(a,b) \equiv \text{gcd}(a,b) = \begin{cases} 0 & \text{ if } a = 0 = b \\ 
 \text{ the largest common divisor of $a$ and $b$ } & \text{ otherwise } \end{cases}  
\]
	\end{definition} 
cf. pp. 3, Ch. 1 Things Past of Rotman (2010) \cite{JRotman2010}  

\begin{definition}[Greatest Common Divisor (GCD), practical definition]
Say $\text{gcd}(a, b) = d$. Thus, we have that $\exists \,  a = dr$ and $b = ds$, $a, b\in \mathbb{Z}$, where $\text{gcd}(r, s) = 1$
\end{definition}
cf. \href{https://math.stackexchange.com/questions/1535408/proof-of-greatest-common-divisor}{Proof of greatest common divisor, math stackexchange}


\begin{theorem}\label{Thm:lincombgcd}
	If $a,b\in \mathbb{Z}$, then $\text{gcd}(a,b) \equiv (a,b)=d$ is linear combination of a and b, i.e. $\exists \, s,t \in \mathbb{Z}$ s.t.
\begin{equation}
d= sa + tb
\end{equation}
\end{theorem}
cf. pp.4, Thm. 1.7, Ch. 1 Things Past of Rotman (2010) \cite{JRotman2010}

\begin{proof}
Let $I:=$ 
\[
I :=\lbrace sa+tb|s,t\in \mathbb{Z} \rbrace
\]
If $I\neq \lbrace 0 \rbrace$, let $d$ be smallest positive integer in $I$.   \\
$d\in I$, so $d=sa + tb$ for some $s,t\in \mathbb{Z}$.  

Claim: $I=(d) \equiv \lbrace kd| k\in \mathbb{Z} \rbrace = $ set of all multiples of $d$.  

Clearly $(d)\subseteq I$, since $kd=k(sa+tb) = (ks)a+(kt)b\in I$.  

Let $c\in I$.  

By division algorithm Thm. \ref{Thm:DivisionAlgorithm}, $c=qd + r$, $0\leq r <d$
\[
r=c-qd = s'a+t'b - qsa - qtb = (s'-sq)a + (t'-qt)b \in I
\]
If $r\in I$, but $r<d$, contradiction that $\min_{ \substack{ i \in I \\ i>0 \\ } } i =d$.  

So $r=0$, and $d|c=c/d$.  
\[
c \in (d), \text{ so } I\subseteq (d) \Longrightarrow I =(d)
\]
\end{proof}


\begin{theorem}[\textbf{Euclid's Lemma}; 1.10 of Rotman (2010) \cite{JRotman2010}]
If $p$ prime and $p|ab$, then $p|a$ or $p|b$.  

More generally,  \\
if prime $p$ divides product $a_1a_2\dots a_n$, \\
then it must divide at least 1 of the factors $a_i$.  

i.e. (notation),  

If prime $p$, and $ab/p \in \mathbb{Z}$, \\
then $a/p\in \mathbb{Z}$ or $b/p \in \mathbb{Z}$.  

More generally, \\
if prime $p$, s.t. $a_1a_2 \dots a_n/p \in \mathbb{Z}$, \\
then $\exists \, $ 1 \, $a_i$ s.t. $a_i/p \in \mathbb{Z}$
\end{theorem}
\begin{proof}
If $p\nmid a$, i.e. $a/p \notin \mathbb{Z}$, then $\text{gcd}(p,a)  \equiv (p,a) =1$.  

From Thm. \ref{Thm:lincombgcd}, 
\[
1 = sp+ta
\]
\[
\Longrightarrow b = spb + tab = p(sb+td)
\]
$ab/p$ and so $ab=pd$, so $b=spb+tdp$, i.e. $b$ is a multiple of $p$ ($b/p \in \mathbb{Z} \equiv p | b$).  




\end{proof}

\begin{corollary}[1.11 of Rotman (2010) \cite{JRotman2010}]\label{Cor:relprimefactors}
Let $a,b,c \in \mathbb{Z}$.  

If $c,a$ relatively prime, i.e. $\text{gcd}(c,a)=1$, and if $c|ab \equiv ab/c\in \mathbb{Z}$,
then $c|b \equiv b/c \in \mathbb{Z}$
\end{corollary}
\begin{proof}
\[
\text{gcd}(c,a)=1 = sc+ta \Longrightarrow b=sbc + tab = sbc + t(qc) = c(sb+tq) \Longrightarrow b/c = sb+tq 
\]
\end{proof}

\begin{theorem}[Euclidean Algorithm]
	Let $a,b \in \mathbb{Z}^+$.  \\
	$\exists \, $ algorithm that finds $d= \gcd{a,b}$
\end{theorem}

cf. pp. 5, Thm. 1.14 (Euclidean Algorithm), Ch. 1 Things Past of Rotman (2010) \cite{JRotman2010}.  

\begin{proof}
	\end{proof}

\begin{definition}
	Let fixed $m\geq 0$.  Then $a,b \in \mathbb{Z}$ are \textbf{congruent modulo } $m$, denoted by 
	\[
	a \equiv b \bmod{m} 
	\]
if $m|(a-b)$, i.e. $(a-b)/m \in \mathbb{Z}$, i.e. if $(a-b)/m\in\mathbb{Z}$, i.e. $(a-b)$ integer multiple of $m$
\end{definition}

\begin{proposition}
	If $m\geq 0$ is fixed, $m\in \mathbb{Z}$, then $\forall \, a,b,c \in \mathbb{Z}$
	\begin{enumerate}
		\item $a \equiv a\bmod{m}$ 
		\item if $a \equiv b\bmod{m}$, then $b \equiv a\bmod{m}$
		\item if $a \equiv b\bmod{m}$, and $b \equiv c\bmod{m}$, then $a \equiv c\bmod{m}$
	\end{enumerate}
\end{proposition}

cf. Prop. 1.18 of Rotman (2010) \cite{JRotman2010}

\begin{proof}
	\begin{enumerate}
		\item $(a-a)/m=0/m=0$
		\item $(b-a)/m=(-1)(a-b)/m \in \mathbb{Z}$
		\item $(a-c)/m=(a-b+b-c)/m=(a-b)/m+(b-c)/m\in\mathbb{Z}$  
	\end{enumerate}
\end{proof}

EY : 20171225 to recap, 

\begin{equation}
\boxed{ 
	\begin{gathered}
	a \equiv b \bmod{n} \\
	\text{ meaning } \\ 
	\frac{a-b}{n} \in \mathbb{Z} \text{ or }  a- b =kn, \  k\in \mathbb{Z} \text{ or } a  = b+kN \text{ but rather } \\
	\begin{aligned}
	& a = pn + r \\
	& b= qn +r
	\end{aligned}
	\end{gathered}	
}
\end{equation}
for $a= b+ kn$, but $b$ need not be a remainder of division of $a$ by $n$.  More precisely, $a= b\bmod{n}$ asserts that $a,b$ have the same remainder when divided by $n$, i.e. 
\[
\begin{aligned}
& a = pn + r \\ 
& b = qn + r
\end{aligned}
\]


So $a\sim b$ or $[a] = [b]$ is an equivalence relation since \\
$a\sim a$ since $a\equiv a \bmod{N}$, since $a=a+0N$, \\
if $a\sim b$, then $b\sim a$, since $a-b=kN$, then $b=a-kN$ \\
if $a\sim b$, $b\sim c$, then $a\sim c$, since $\begin{aligned} & \quad \\ 
	& a-b = kN \\
	& b-c = lN \end{aligned}$, then $a-c = (k+l)N$.  
	
	



cf. Prop. 1.19 of Rotman (2010) \cite{JRotman2010}  
\begin{proposition}
Let $m\geq 0$ be fixed 
\begin{enumerate}
	\item If $a=qm +r$, then $a \equiv r \bmod{m}$ 
	\item  If $0\leq r' <r <m$, then $r \not\equiv\bmod{m}$ i.e. $r$ and $r'$ aren't congruent $\bmod{m}$  
	\item $a \equiv b \bmod{m}$ iff $a,b$ leave same remainder after dividing by $m$  
	\item If $m\geq 2$, $\forall \, a \in \mathbb{Z}$, $a \equiv b \bmod{m}$ for some $b\in 0,1,\dots m-1$  
\end{enumerate}	
\end{proposition}

\begin{proof}
\begin{enumerate}
	\item If $a=qm +r$, then $a \equiv r \bmod{m}$ 
	\[
	\frac{a-r}{m} = q \in \mathbb{Z}  
	\]
	\item  \emph{Want}: If $0\leq r' <r <m$, then $r \not\equiv\bmod{m}$.  
	
	Suppose $\frac{r-r'}{m} = k \in \mathbb{Z}$.  Then $r-r' = km$ or $r=r' + km$.  
	\[
	\begin{gathered}
	m > r > r' \leq 0 \\
	m > r' + km > r' \leq 0 \\
	m-r' > km > 0 
	\end{gathered}
	\]
	But $k>0$ (since $m>0$ and $r-r' = km >0$) and $m-r' > km > 0$ is a contradiction.  
	
	\item \emph{Want}: $a \equiv b \bmod{m}$ iff $a,b$ leave same remainder after dividing by $m$.  By 
	
	By Division Algorithm, this is true: 
	\[
	\begin{aligned}
	& a=q_a m + r_a \\ 
	 & b= q_b m + r_b 
	\end{aligned}
	\] 
	\[
	\begin{gathered}
	\frac{a-b}{m} = q_a + \frac{r_a}{m} - q_b - \frac{r_b}{m} = k = q_a - q_b + \frac{r_a - r_b}{m} \in \mathbb{Z}
	\end{gathered}
	\]
	Now 
	\[
	\begin{aligned}
	& |m| > r_a \leq 0 \\ 
	& |m| > r_b \leq 0 
	\end{aligned}
		\]
		$2|m| > r_a + r_b$.  
		
		And if $r_a > r_b$, $|m| > r_a > r_a -r_b > 0$.  
		
		In both cases, $r_a=r_b$ since $q_a - q_b + \frac{r_a - r_b}{m} \in \mathbb{Z}$ needs to be enforced.   
		
	\item \emph{Want}: If $m\geq 2$, $\forall \, a \in \mathbb{Z}$, $a \equiv b \bmod{m}$ for some $b\in 0,1,\dots m-1$.  
	
	By Division Algorithm Thm. \ref{Thm:DivisionAlgorithm}, $a = q_a m + r_a$, \, $0 \leq r_a < |m|$.  $\frac{a-r_a}{m} = q_a \in \mathbb{Z}$ so let $b= r_a$.  
	
\end{enumerate}	
\end{proof}

\begin{theorem}[1.26 of Rotman (2010) \cite{JRotman2010}]\label{Thm:relprimeinvertible} 
If $\text{gcd}(a,m) \equiv (a,m) = 1$, then $\forall \, b \in \mathbb{Z}$, $\exists \, x $ s.t. 
\[
ax \equiv b\bmod{m}
\]
In fact, $x=sb$, where $sa\equiv 1\bmod{m}$ is 1 solution.  Moreover, any 2 solutions are congruent $\bmod{m}$.

i.e.  % \\

If $\gcd{a,b} = 1$, then $\forall \, y \in \mathbb{Z}$, $\exists \, x$ s.t. $ax \equiv y \bmod{b}$, $x=sy$, where $sa\equiv 1\bmod{b}$ is 1 solution.  \\
Moreover, any 2 solutions are congruent $\bmod{m}$.  This implies that    \\

$ax\equiv y \bmod{b}$ or $\frac{Ax-y}{b} \in \mathbb{Z}$, and $\frac{(as-1)y }{b} \in \mathbb{Z}$.  \\
$sa \equiv 1 \bmod{b}$ or $\frac{sa-1}{b} \in \mathbb{Z}$, which implies that $sa-1 = b(-t)$ or 

\[
sa + tb =1
\]
for some $s,t\in \mathbb{Z}$.  
\end{theorem}
\begin{proof}
$\gcd(a,m) = 1=sa+tm$, by Thm. \ref{Thm:lincombgcd}   

Then $b=b\cdot 1=  b(sa+tm) = sab+tmb$ or $b=tbm+sab$ or $a(sb) = -tbm + b$.  

So $a(sb)\bmod{m}  \equiv b$.  

Let $x:= sb$ and so $ax \bmod{m}=b$.   \\
Now suppose $x \neq sb$ s.t. $ax\bmod{m}=b$.  Then $ax=qm +b$.  From $a(sb) \bmod{m}=b$, we also get $a(sb) = q'm + b$.  Then $a(x-sb) \bmod{m}=0$, so $m|a(x-sb) \equiv a(x-sb)/m\in \mathbb{Z}$.  

By Corollary \ref{Cor:relprimefactors} (which says, if $\gcd(c,a)=1$ and if $ab/c\in\mathbb{Z}$, then $b/c \in \mathbb{Z}$), 
since $\gcd(m,a) = (m,a)=1$, and since $a(x-sb)/m \in \mathbb{Z}$, then $(x-sb)/m\in\mathbb{Z}$.  So $(x-sb)=qm$ or $(sb)\bmod{m} = x$.  


\end{proof}



\begin{proposition}[3.1 of Scheinerman (2006) \cite{Sche2006}]\label{Prop:commongcd}
Let $a,b\in \mathbb{Z}$, let $c=a\bmod{b}$, i.e. $a=qb+c$ s.t. $0\leq c <b$.  

Then 
\begin{equation}
\text{gcd}(a,b) = \text{gcd}(b,c)
\end{equation}
\end{proposition}
cf. Sec. 3.3 Euclid's method of Scheinerman (2006) \cite{Sche2006}

\begin{proof}
If $d$ common divisor of $a,b$, i.e. $a/d, b/d \in \mathbb{Z} \equiv d|a, d|b$.   \\
$c/d \in \mathbb{Z} \equiv d|c$ since $c=a-qb$.  

If $d$ is common divisor of $b,c$, i.e. $d|b, d|c \equiv c/d, b/d\in\mathbb{Z}$, \\
then $d|a \equiv a/d \in \mathbb{Z}$ since $a=qb+c$.  So set of common divisors of $a,b$ same as set of common divisors of $b$ and $c$.  

Then $\text{gcd}(a,b) = \text{gcd}(b,c)$.  
\end{proof}




\subsection{Euler's totient; relatively prime}

%\begin{definition}
%if $a,b \in \mathbb{Z}$, \\
%a \textbf{divisor} of b, if $\exists \, d\in \mathbb{Z}$ s.t. $b=ad$.   \\
%Also, $a$ \textbf{divides} $b$ or $b$ multiple of $a \equiv a | b$.  \\
%$a|b \equiv b/a \in \mathbb{Z}$  
%\end{definition}
%cf. pp. 3 of Ch. 1 Things Past, Sec. 1.1 Some Number Theory of Rotman (2010) \cite{JRotman2010}.  

cf. Ch. 5 Arrays, Sec. 5.1 Euler's totient of Scheinerman (2006) \cite{Sche2006}

For 
\[
\begin{aligned}
	& \varphi : \mathbb{Z}^+ \to \mathbb{Z}^+ \\ 
	& \varphi : n \mapsto \varphi(n) := \text{ number of elements of } \lbrace 1,2, \dots n \rbrace \\
	\text{ that are relative prime to } \\
	& n = | \lbrace i | i \in \lbrace 1,2, \dots n \rbrace , (n,i)=1 \text{ or equivalently } n \propto i \rbrace |
\end{aligned}
\]

e.g. $\varphi(10) = 4$ since $\varphi(10) = | \lbrace 1,3,7,9\rbrace|$.  

we want $|(a,b) | 1 \leq a,b, \leq n , \text{gcd}(a,b) \equiv (a,b) = 1 |$.  

\[
\begin{gathered}
p_n = \frac{1}{n^2} \left[ -1 + 2\sum_{i=1}^n \varphi(k) \right] = \\
= \text{ probability that 2 integers, chosen uniformly and independently from $\lbrace 1,2,\dots n\rbrace$ are relatively prime }
\end{gathered}
\]

If $p$ is prime, $\forall \, i \in \lbrace 1,2,\dots p \rbrace$, $(p,i) \equiv \text{gcd}(p,i)=1$, i.e. relatively prime to $p$, except 1 $i\in \lbrace 1,2,\dots p\rbrace$.  

Therefore 
\[
\varphi(p) = p-1
\]
Consider $\varphi(p^2)$.  

$\lbrace 1,2,\dots p^2\rbrace$, only numbers \emph{not} relatively prime to $p^2$ are multiples of $p$ since \\
$p,2p, 3p, \dots p^2$ all divide $p^2$, i.e. $p|p^2, 2p|p^2 \dots (p-1)p | p^2 \equiv p^2 /p , p^2 /2p , \dots p^2 / p(1-p)$.  

Assume $\varphi(p^n) = p^2 - p^{n-1} = p^{n-1}(p-1)$.  

\[
\varphi(p^{n+1}) = \varphi(pp^{n}) = p^n\varphi(p) = p^n(p-1)
\]
Therefore,
\begin{proposition}[5.1]
Let $p$ prime, $n\in \mathbb{Z}^+$
\end{proposition}


e.g. $\varphi(77)$.  

$\forall \, n $ s.t. $1\leq n \leq 77$.  
\[
\begin{aligned}
	& \text{gcd}(n,77)=1 \\ 
	& \text{gcd}(n,7)=1 \\ 
	& \text{gcd}(n,11)=1  
\end{aligned}
\]
By Prop. \ref{Prop:commongcd}, 
\[
\begin{aligned}
	& \text{gcd}(n,7) = \text{gcd}(7, n\mod{7}) \\ 
	& \text{gcd}(n,11) = \text{gcd}(11, n\mod{11}) 
\end{aligned}
\]

%--------------------------------------------------------------------------------
% 20180311 
%-------------------------------------------------------------------------------
cf. Example (10) of Dummit and Foote \cite{DuFo2003}.  

To recap, 
\begin{definition}[Euler $\varphi$-function]
$\forall \, n \in \mathbb{Z}^+$, \\
let $\varphi(n)  := $ number of positive integers $a \leq n$ with a relatively prime to $n$, i.e. $\gcd(a,n) = 1 \equiv (a,n)$
\end{definition}
e.g. $\varphi(12)=4$, since $1,5,7,11$ are only positive integers less than or equal to 12.  

If $p$ prime, 
$\varphi(p) = p-1$.  \\
More generally, \\
$\forall \, a \geq 1$, 
\begin{equation}\label{Eq:EulerTotientOfPrimeFactor}
\boxed{ \varphi(p^a) = p^a - p^{a-1} = p^{a-1} (p-1) }
\end{equation}

$\varphi$ is multiplicative in the sense that 
\begin{equation}\label{Eq:EulerTotientIsMultiplicative}
\varphi(ab) = \varphi(a) \varphi(b)  \text{ if } \gcd(a,b) = 1
\end{equation}
$\Longrightarrow $ general formula.  

If $n=p_1^{\alpha_1}p_2^{\alpha_2} \dots p_s^{\alpha_s}$ (Fumdanetal Thm. of Arithmetic, $\forall \, n \in \mathbb{Z}, n>1$), then 
\begin{equation}
\boxed{ 
	\begin{aligned}
	\varphi(n) & = \varphi(p_1^{\alpha_1})  \varphi(p_2^{\alpha_2}) \dots \varphi(p_s^{\alpha_s}) \\ 
	& p_1^{\alpha_1 - 1 } (p_1 - 1) p_2^{\alpha_2 - 1} (p_2 - 1 ) \dots p_s^{\alpha_s -1} (p_s - 1) 
	\end{aligned} }
\end{equation}


cf. pp. 69 Thm. 5.4 (Chinese Remainder) of Scheinerman (2006) \cite{Sche2006}.  
\begin{theorem}
	Let $n\in \mathbb{Z}^+$, \\
	let $p_1,p_2, \dots p_t$ be distinct prime divisors of $n$ (i.e. $\forall \, p_i$, $\frac{n}{p_i^{k_i}} \in \mathbb{Z}$ for some $k_i \geq 1$) \\
	Then
	\begin{equation}
	\varphi(n) = n\left( 1 - \frac{1}{p_1} \right)\left( 1- \frac{1}{p_2} \right) \ldots \left( 1 - \frac{1}{p_t} \right) 	
	\end{equation}
\end{theorem}

\begin{proof}
	By Fundamental Thm. of Arithmetic, 
	\[
	n = p_1^{e_1} p_2^{e_2} \dots p_t^{e_t} 
	\]
	where $p_j$ are distinct primes, and $e_j$ are positive integers.  
	
	From Eqns. \ref{Eq:EulerTotientOfPrimeFactor}, \ref{Eq:EulerTotientIsMultiplicative}, i.e. where 
	\[
	\begin{gathered}
	\varphi(p^a) = p^a - p^{a-1} = p^{a-1} (p-1) \\
	\varphi(ab) = \varphi(a) \varphi(b)  \text{ if } \gcd(a,b) = 1
		\end{gathered}
		\]
		\[
		\begin{gathered}
	\varphi(n) = \varphi(p_1^{e_1}p_2^{e_2} \dots p_t^{e_t}) = \varphi(p_1^{e_1}) \varphi(p_2^{e_2}) \dots \varphi(p_t^{e_t}) = \\
	= p_1^{e_1} (1- \frac{1}{p_1} )p_2^{e_2} (1- \frac{1}{p_2} ) \dots p_t^{e_t} (1- \frac{1}{p_t} ) = n(1- \frac{1}{p_1}) (1- \frac{1}{p_2}) \dots (1- \frac{1}{p_t})
		\end{gathered}
		\]
	\end{proof}


\exercisehead{10}
cf. pp. 7 Exercise 10 Dummit and Foote \cite{DuFo2003}.  

Prove: $\forall \, $ given $N \in \mathbb{Z}^+$ (positive number), \\
$\exists \, $ only finite many integers $n$ with $\varphi(n) = N$, where $\varphi$ denotes Euler's $\varphi$-function.  

EY, Indeed, by definition, \\
\[
\begin{gathered}
\varphi(n) = N \\
a_1, a_2 \dots a_N \text{ s.t. } a_i \leq n \\
\gcd(a_i,n)=1 \text{ i.e. } 1 = s_i a_i + t_i n 
\end{gathered}
\]


Given $N \in \mathbb{Z}^+$, let $n \in \mathbb{Z}$, s.t. $\varphi(n) = N$ (given hypothesis).  

Let $p= $ least (i.e. smallest) prime s.t. $p > N+1$.  

If $q\geq p$ is a prime divisor of $n$, i.e. 
\[
n = q^k m 
\]
for some $k\geq 1$, and $m$ with $q$ not dividing $m$.  

Then 
\[
\varphi(n) = \varphi(q^k) \varphi(m) = q^{k-1}(q-1) \varphi(m) \geq q-1 \geq p -1 > N
\]
Contradiction.  

Thus, $\nexists$ prime divisor of $n$ greater than $N+1$.  

Particularly, distinct prime divisors of $n$ belong to a finite set, say these primes are $p_1,p_2 \dots p_m$.  

\begin{definition}
	prime divisor $q$ of $n$ if $q$ is prime and 
	\begin{equation}
	 \frac{n}{q} \in \mathbb{Z} \text{ i.e. } n =q^k m \text{ for some } k \geq 1 \text{ and } \frac{m}{q} \notin \mathbb{Z}^+
	\end{equation}
\end{definition}

Now
\[
n=p_1^{a_1}p_2^{a_2} \dots p_m^{a_m} 
\]
for some $0<a_i$, so 
\[
\varphi(n) = \varphi(p_1^{a_1}) \varphi(p_2^{a_2}) \dots \varphi( p_m^{a_m}), \text{ so } \varphi(n) = \prod_{i=1}^m p_i^{ a_i -1} (p_i-1)
\]
Note, $\forall \, $ prime $p_i$, $\varphi(n) \geq p_i^{a_i -1}(p_i-1) \geq p_i - 1 > N$ for sufficiently large $a_i$.  

Thus, $\forall \, p_i$, $\exists \, $ only finitely many permissible choices for exponents $a_i$.  \\
So set of all $n$ with $\varphi(n) = N$ is subset of finite set, hence finite.  

$\forall \, N \in \mathbb{Z}^+$, $\exists \, $ largest integer $n$ with $\varphi(n) = N$.  \\
Thus, as $n\to \infty$, $\varphi(n) \to \infty$.  




%--------------------------------------------------------------------------------
% END of 20180311 
%-------------------------------------------------------------------------------



Scheinerman (2006) \cite{Sche2006}

cf. Ex. 1.19, pp. 13, Sec. 1.1 Some Number Theory of Rotman (2010) \cite{JRotman2010}
\exercisehead{1.19}
If $a$ and $b$ are relatively prime and if each divides an integer $n$, then their product $ab$ also divides $n$, i.e. 
\begin{theorem}\label{Thm:relprimeproddivisible}
	If $\gcd{a,b}=1$, and if $n/a \in \mathbb{Z} \equiv a | n$, and $n/b \in \mathbb{Z} \equiv b | n$, then $n/ab \in \mathbb{Z} \equiv ab | n$.  
\end{theorem}
\begin{proof}
	$\gcd{a,b}=1$, so $sa + tb= 1$ for some $s,t \in \mathbb{Z}$ (Thm. \ref{Thm:relprimeinvertible}).  
	
	$\frac{n}{a}, \frac{n}{b} \in \mathbb{Z}$, so $n=au$, $n=bv$  
	
	$n = n\cdot 1 = n(sa+tb) = bvsa + autb = ab(vs + ut)$, so $\frac{n}{ab} = vs + ut \in \mathbb{Z}$.  
	\end{proof}

\subsubsection{Chinese Remainder Theorem}

\begin{theorem}
	If $m,m'$ relatively prime (i.e. $\gcd(m,m')=1$), then for 
\[
\begin{aligned}
	& x \equiv b \bmod{m} \\ 
	& x\equiv b'\bmod{m'}
\end{aligned}
\]
i.e. given $b,b'm,m'$, and wanting to find $x$, 
$\exists \, x$ and $\forall \, 2 x$'s, $x=x'\mod{mm'}$, i.e.  \\  

  Let $m,n$ relatively prime positive integers (i.e. $\gcd{m,n}=1$), \\
  $\forall \, a,b\in \mathbb{Z}$, \\
  then pair of congruences \\
  $\begin{aligned}
  & x \equiv a\bmod{m} \\
  & x \equiv b\bmod{n} 
  \end{aligned}$
 
 has a solution ($x$), and this solution $x$ is uniquely determined, modulo $mn$.  
\end{theorem}


\begin{proof}
cf. \href{http://www.math.uconn.edu/~kconrad/blurbs/ugradnumthy/crt.pdf}{The Chinese Remainder Theorem by Keith Conrad}


Suppose  \\
$
\begin{aligned}
& (x-a) / m \in \mathbb{Z} \text{ or } x - a = my \\ 
& (x-b)/n \in \mathbb{Z} \text{ or } x-b= nz \text{ or } a + my - b = nz 
\end{aligned}
$ \\
$\gcd{m,n}  =1$, so then $\forall \, b \in \mathbb{Z}$, $\exists \, w$ s.t. $mw \equiv b \bmod{n}$ i.e. $\frac{mw-b}{n} \in \mathbb{Z}$, in fact, $w=sb$, where $sm \equiv 1\bmod{n}$, or $\frac{sm-1}{n} \in \mathbb{Z}$, is 1 solution (Thm. \ref{Thm:relprimeinvertible}).  

\[
\begin{aligned}
my & = b-a+nz \\
smy & = sb - sa + snz = (1+nv) y = s(b-a) + snz \text{ or } y = s(b-a) + n(sz-vy) \\
\text{ or } y & \equiv s(b-a) \bmod{n}  
\end{aligned}\]

\[
\begin{aligned}
x = a+my & = a+m(s(b-a) + n(sz-vy)) = a+ ms(b-a) + mn(sz-vy) \equiv a+ms(b-a) + mnu \\ 
x-a & = m(s(b-a) + nu) \Longrightarrow x = a\bmod{m} \\
x-b & = a+ms(b-a) + mnu -b = a+(1+m)(b-a) + mnu -b = m(b-a) + mnu \Longrightarrow x \equiv b\bmod{n}
\end{aligned}
\]

%\textbf{Second way to prove existence of solution}:  
\textbf{Uniqueness}:  
Suppose $x,y \in \mathbb{Z}$ s.t. 
\[
\begin{aligned} 
& x \equiv a \bmod{m} \\
& x \equiv b \bmod{n} \end{aligned} \qquad \  
\begin{aligned} 
& y \equiv a \bmod{m} \\
& y \equiv b \bmod{n} \end{aligned}
\]

Given $\gcd{m,n}=1$, $sm+tn=1$.  

Since $\frac{x-a}{m}, \frac{y-a}{m} \in \mathbb{Z}$, $\frac{x-y}{m} \in \mathbb{Z}$, likewise, $\frac{x-a}{n}, \frac{y-a}{n} \in \mathbb{Z}$, $\frac{x-y}{n} \in \mathbb{Z}$ \\
Since $\frac{x-y}{m}, \frac{x-y}{n} \in \mathbb{Z}$, $\frac{x-y}{mn} \in \mathbb{Z}$ by Thm. \ref{Thm:relprimeproddivisible}.  

Thus, $x-y = mn k$ for some $k\in \mathbb{Z}$.  For instance, $k=0$, $x=y$.  

This shows any 2 solutions are the same, modulo $mn$.  
\end{proof}


cf. Ch. 1 Things Past, Thm. 1.28 of Rotman (2010) \cite{JRotman2010}, pp. 68 Thm. 5.2 (Chinese Remainder) of Scheinerman (2006) \cite{Sche2006}.  




\section{Groups}
cf. pp. 16 Chapter 1 Introduction to Groups. Dummit and Foote (2004) \cite{DuFo2003}
\begin{definition}[binary operation]
	\begin{enumerate}
		\item binary operation $*$ on set $G$ is a function $*: G \times G \to G$.  $\forall \, a, b \in G$, $a* b \equiv *(a,b)$
		\item binary operation $*$ on set $G$ is \emph{associative}: if $\forall \, a, b, c \in G$, $a*(b*c) = (a*b) * c$ 
		\item If $*$ is binary operation on set $G$, $a,b $ of $G$ commute if $a*b = b*a$. \\
		$*$ (or $G$) is \textbf{commutative} if $\forall \, a, b \in G$ $a* b = b*a$.  
	\end{enumerate}
\end{definition}
cf. pp. 16. Sec. 1.1. Basic Axioms and Examples, Dummit and Foote (2004) \cite{DuFo2003} 

\begin{definition}[Group]
\begin{enumerate}
\item Group is an ordered pair $(G, *)$ where $G$ is a set, $*$ is a binary operation on $G$ s.t. 
\begin{enumerate}
\item $(a*b)*c = a*(b*c)$, $\forall \, a,b ,c \in G$, i.e. $*$ \emph{associative}
\item $\exists \, e \in G$, s.t. $\forall \, a\in G$, $a*e = e*a = a$  ($\exists \, $ \emph{identity} $e$)
\item $\forall \, a\in G$, $\exists \, a^{-1}\in G$, called an \emph{inverse} of $a$, s.t. $a*a^{-1} = a^{-1} * a = e$
\end{enumerate}
\item (optional; abelian or \emph{commutative}) $(G,*)$ abelian (or commutative) if $a*b = b*a$, $\forall \, a,b \in G$. 
\end{enumerate}
\end{definition}
e.g.
\begin{enumerate}
\item  $\mathbb{Z}$, $\mathbb{Q}$, $\mathbb{R}$, $\mathbb{C}$ are groups under $+$ with $e=0$ and $a^{-1} = -a$, $\forall \, a$. 
\item $\mathbb{Q} - \lbrace 0 \rbrace$, $\mathbb{R} - \lbrace 0 \rbrace$, $\mathbb{C} - \lbrace 0 \rbrace, \mathbb{Q}^+, \mathbb{R}^+$ groups under $\times$ with $e=1$, $a^{-1} = \frac{1}{a}$
\item (\textbf{direct product of groups})If $(A,*), (B,\circ)$ are groups, we can form new group $A\times B$ called \textbf{direct product} s.t.
\[
A \times B = \lbrace (a,b) | a\in A, b\in B\rbrace
\] and $(a_1,b_1)(a_2,b_2) = (a_1*a_2, b_1 \circ b_2)$ cf. Example 6, Sec. 1.1 Dummit and Foote (2004) \cite{DuFo2003}
\end{enumerate}

\begin{proposition}
If $G$ group under operation $*$, then 
\begin{enumerate}
\item identity of $G$ is unique
\item $\forall \, a \in G$, $a^{-1}$ uniquely determined.
\item $(a^{-1})^{-1} = a \quad \, \forall \, a \in G$ 
\item $(a*b)^{-1} = (b^{-1}) * (a^{-1})$ 
\item $\forall \, a_1, a_2, \dots a_n \in G$, $a_1 , a_2 \dots a_n $ independent of how expression is bracketed (generalized associative law)
\end{enumerate}
\end{proposition}
cf. Prop. 1, Sec. 1.1 Dummit and Foote (2004)\cite{DuFo2003}

\subsection{$\mathbb{Z} / n \mathbb{Z}$: The Integers Modulo $n$}

cf. Dummit and Foote (2004) \cite{DuFo2003}, Sec. 0.3, $\mathbb{Z}/n\mathbb{Z}$: The Integers Modulo $n$.

Recall Sec. 0.2 Properties of the Integers, pp. 4, Dummit and Foote (2004) \cite{DuFo2003}. $\forall \, a, b \in \mathbb{Z}$, $a | b$ if $\exists \, c \in \mathbb{Z}$ s.t. $b=ac$. 

\begin{definition}[modulo equivalence relation]
Let $n\in \mathbb{Z}^+$ (positive integer). Define
\begin{equation}
a \sim b \text{ iff } n | (b-a), \text{ i.e. } 
\end{equation}
$\exists \, c \in \mathbb{Z}$ s.t. $b-a = nc$ or $a+nc = b$. Rewrite this as $a= b- nc \equiv b + Nk$ or even $\begin{aligned} & \quad \\ & a = pn + r \\ & b = qn + r \end{aligned}$. 
\end{definition} 

\begin{proposition}[modulo is an equivalence relation]
	modulo $n$ is an equivalence relation
\end{proposition} 

\begin{proof}
Clearly $a \sim a$ (choose $k=0$ in $a= b + Nk$), $a\sim b$ implies $b\sim a$ (choose $k \mapsto -k$) $\forall \, a, b \in \mathbb{Z}$, so $\sim $ is reflexive and symmetric.

If $a\sim b$, and $b\sim c$, $a= b + Nk$, $b=c +Nl$, so $a= c + N(k+l)$, so $a\sim c$, and $\sim$ is transitive.

$\Longrightarrow \sim$ is equivalence relation.

\end{proof} 

$a \equiv b \bmod{n}$ or $a \equiv b \bmod{n}$, i.e. $a$ is congruent to $b \bmod{n}$ if $a\sim b$. 

$\forall \, k \in \mathbb{Z}$ denote equivalence class of $a \equiv \overline{a}$, called \emph{congruence class} or \textbf{residue class} of $a\bmod{n}$.

\begin{equation}
\overline{a} = \lbrace a + kn | k \in \mathbb{Z} \rbrace = \lbrace a , a \pm n, a \pm 2n, a \pm 3n ,\dots \rbrace 
\end{equation}

If $\overline{a} = pn +r$, $\frac{ \overline{a}}{n} = p + \frac{r}{n}$ , $0\leq r < n$, so remainder $r$ determines equivalence class $\overline{a}$.

These residue classes partition $\mathbb{Z}$. 
\begin{definition}[$\mathbb{Z} / n \mathbb{Z}$]
$\mathbb{Z} / n\mathbb{Z} \equiv$ set of equivalence classes under this equivalence relation $\equiv$ called integers modulo $n$ (or integers mod $n$)
\end{definition} 

\begin{definition}[modular arithmetic]
	$\forall \, \overline{a}, \overline{b} \in \mathbb{Z} / n \mathbb{Z}$, define sum and product by 
	\begin{equation}
	\overline{a} + \overline{b} = \overline{a+b}, \, \overline{a} \cdot \overline{b} = \overline{ab}
	\end{equation}
	i.e. $\forall \, \overline{a}, \overline{b}$ in $\mathbb{Z}/n\mathbb{Z}$, take \emph{any representive} integer $a$ in class $\overline{a}$ and \emph{any representative} integer $b$ in class $\overline{b}$ and add (respectively, multiply), as usual in $\mathbb{Z}$, and take equivalence class of result.
\end{definition}

\begin{theorem}[Theorem 3 of Dummit and Foote (2004) \cite{DuFo2003}, Sec. 0.3]
	$\overline{a} + \overline{b} = \overline{a+b}$, $\overline{a} \cdot \overline{b} = \overline{ab}$ on $\mathbb{Z}/n\mathbb{Z}$ well-defined, and don't depend on representation choice, i.e. $a_1, a_2 \in \mathbb{Z}$, $b_1, b_2 \in \mathbb{Z}$, with $\overline{a}_1 = \overline{b}_1$, $\overline{a}_2 = \overline{b}_2$, then $\overline{a_1 + a_2} = \overline{b_1 + b_2}$, and $\overline{a_1 a_2} = \overline{b_1 b_2}$
\end{theorem} 

\begin{proof}
	Suppose $a_1 = b_1 \bmod{n}$, so $a_1 = b_1 + sn$, likewise $a_2 = b_2 \bmod{n}$ means $a_2 = b_2 + tn$, so \\
	$a_1 + a_2 = b_1 + b_2 + (s+t)n$, so $\overline{a_1 + a_2} = \overline{b_1 + b_2}$ from $a_1 + a_2 = (b_1 + b_2) \bmod{n}$

This shows that sum of residue classes is independent of the representatives chosen.

Similarly, 
\[
a_1 a_2 = (b_1 + sn) (b_2 + tn) = b_1 b_2 + (b_1 t + b_2 s + stn) n \text{ so } a_1 a_2 = b_1b_2(\bmod{n})
\]

\end{proof}

\subsubsection{Elementary number theory application: Last 2 digits of $2^{1000}$}

What is the last 2 digits of $2^{1000}$?

Now $2^{1000} / 100 =$ last 2 digits of $2^{1000}$. So $2^{1000} \bmod{100} = $?

Observe $2^{10} = 1024$ \qquad \, $2^{10} \bmod{100} = 24$

\[
\begin{gathered}
\begin{aligned}
& 2^{20} \bmod{100} = (2^{10})^2 \bmod{100} = (24)^2 \bmod{100} = 576 \bmod{100} = 76 \bmod{100} \\
& 2^{80} \bmod{100} = 2^{160} \bmod{100} = 2^{320} \bmod{100} = 2^{640} \bmod{100} = 76 \bmod{100}
\end{aligned}
\end{gathered}
\]
where $(2^{20})^4 \bmod{100} = 76^4 \bmod{100} = 76 \bmod{100}$, \\
$(76)^{2} \bmod{100} = 76 \bmod{100}$ \\

So $2^{1000} \bmod{100} = 2^{640} 2^{320} 2^{40} \bmod{100} = 76 \cdot 76 \cdot 76 \bmod{100} = 76 \bmod{100}$ where $(76)^3 \bmod{100} = 76 \bmod{100}$. 

Note that we used $\overline{a_1a_2} = \overline{a}_1 \cdot \overline{a}_2$ definition extensively.

$2^{1000} \bmod{100} = 76 \bmod{100}$

Collection of residue classes having multiplicative inverse in $\mathbb{Z} / n\mathbb{Z}$ is an important subset of $\mathbb{Z} / n\mathbb{Z}$, $\equiv (\mathbb{Z} / n\mathbb{Z})^{\times}$

\begin{definition}[cf. pp. 10, Dummit and Foote (2003)\cite{DuFo2003}]
\begin{equation}
(\mathbb{Z} / n\mathbb{Z})^{\times} = \lbrace \overline{a} \in \mathbb{Z} / n \mathbb{Z} | \exists \, \overline{c} \in \mathbb{Z} / n \mathbb{Z} \text{ with } \overline{a} \cdot \overline{c} = 1 \rbrace 
\end{equation}
\end{definition}

\begin{proposition}[Prop. 4, pp. 10, Dummit and Foote (2003) \cite{DuFo2003}]
\[
(\mathbb{Z} / n\mathbb{Z})^{\times} = \lbrace \overline{a} \in \mathbb{Z} / n \mathbb{Z} | (a,n) = 1 \rbrace
\], representatives of residue classes $\overline{a}$ are relatively prime to $n$.

$(a,n) \equiv \gcd{(a,n)}$, greatest common divisor of $a$ and $n$. 
\end{proposition}

\begin{proof}
	Since $(a,n) = 1$, $1= sa + tn$ so $as = 1 - tn$, so $as = 1 \bmod{n} \equiv \overline{1}$, so $\overline{s} = s\bmod{n}$ is a multiplicative inverse of $\overline{a}$.
	
	$\Longrightarrow \overline{a} \in (\mathbb{Z} / n\mathbb{Z})^{\times}$.  If $\overline{a} \cdot \overline{c} = \overline{1}$, then $ac= 1 + kn$ or $ac+ k' n=1$
	
\end{proof}

\exercisehead{2} cf. Ex. 2, pp. 11, Dummit and Foote (2003) \cite{DuFo2003}, Sec. 0.3. $\mathbb{Z} / n \mathbb{Z} \ni \overline{a}$ if $\overline{a} = a + kn$. \\
By Division Algorithm, Thm. \ref{Thm:DivisionAlgorithm}, $\forall \, a, N \in \mathbb{Z}$, $n\neq 0$, $a=qn + r$, $0\leq r < |n| = n$.

Comparing expressions $a=  r + qn$ and $\overline{a} = a + kn$, then equivalence classes of $\mathbb{Z}/n\mathbb{Z}$ can only be of $r$ s.t. $0\leq r < |n|$.

\exercisehead{3} cf. Ex. 3, pp. 11, Dummit and Foote (2003) \cite{DuFo2003}, Sec. 0.3. If $a= \sum_{j=0}^{n-1} a_j b^j$, $b=10$, $a\in \mathbb{Z}^+$ (positive integer), then prove $a \equiv a_n + a_{n-1} + \dots + a_1 + a_0 (\bmod{9})$. 

\emph{Observe} that $10 \equiv 1 (\bmod{9})$. So, \\

Use the fact that $b\equiv 1 \bmod{(b-1)}$.
\[
\begin{gathered}
	a_j b^j \bmod{(b-1)} = a_j \bmod{(b-1)} \cdot b^j \bmod{(b-1)} = a^j \bmod{(b-1)} \cdot (b \bmod{(b-1)})^j = a_j \bmod{(b-1)} 1^j \bmod{(b-1)} = \\
	a^j \bmod{(b-1)} \\
	a \bmod{(b-1)} = \sum_{j=0}^{n-1} a^jb^j \bmod{(b-1)} = \sum_{j=0}^{n-1} a^j \bmod{(b-1)} = \left( \sum_{j=0}^{n-1} a_j \right) \bmod{(b-1)}
\end{gathered}
\]

if $b=0$, this says that remainder after division by 9 is same as sum of the decimal digits mod 9 - particularly, an integer is divisible by 9 iff sum of digits is divisible by 9.

If $b=2$, this says $a$ odd (even) if sum of bits is odd (even).

\subsubsection{As an abelian group}

cf. Dummit and Foote, pp. 17, Ch. 1, Sec. 1.1, Examples, Example 4.

$\mathbb{Z}/n\mathbb{Z}$ is an abelian group under operation $+$ of addition of residue classes, as described in Ch. 0. In Ch. 3 of Dummit and Foote (2003) \cite{DuFo2003}, prove binary operation $+$ is well-defined and associative.

$(\overline{a})^{-1} = \overline{-a}$ \, $\forall \, a \in \mathbb{Z}/ n \mathbb{Z}$, identity of $\angle \mathbb{Z}/n\mathbb{Z}, + \rangle = \overline{0}$.

\exercisehead{3} cf. Exercise 3 in pp. 21, Exercises, of Sec. 1.1, Dummit and Foote (2003) \cite{DuFo2003}. 

\[
\overline{a}  + (\overline{b} + \overline{c}) = (\overline{a} + \overline{b}) + \overline{c} 
\]
is associative, since,
\[
\begin{gathered}
\overline{a} + (\overline{b} + \overline{c}) = \overline{a} + (\overline{b+c}) = \overline{a} + (\overline{b + tn + c + un}) = \overline{a} + \overline{b+c} = \overline{a+b+c} \\
(\overline{a} + \overline{b}) + \overline{c} = (\overline{a+b}) + \overline{c} = (\overline{a + sn + b+ tn}) + \overline{c} = \overline{a+b} + \overline{c} = \overline{a+b+c}
\end{gathered}
\]

\subsection{Cyclic groups and cyclic subgroups}

cf. Sec. 2.3, pp. 54, Dummit and Foote (2003), \cite{DuFo2003}

\begin{definition}[Cyclic group]\label{Def:CyclicGroup}
	group $H$ is \textbf{cyclic} if $H$ can be generated by a single element, i.e. $\exists \, x \in H$ s.t. $H= \lbrace x^n | n\in \mathbb{Z} \rbrace$ ("multiplication" operation notation) $\equiv H = \lbrace nx | n \in \mathbb{Z} \rbrace$ ("additive" operation notation). \\
	
	In both cases, write $H = \langle x \rangle$ and say $H$ \emph{generated} by $x$ (i.e. $x$ is \emph{generator} of $H$)
\end{definition}
	cyclic group may have more than 1 generator; e.g. $H = \langle x \rangle$ and $H = \langle x^{-1} \rangle$ because $(x^{-1})^n = x^{-n}$ and $-n \in \mathbb{Z}$. 
	
\exercisehead{19} cf. Exercise 19, Sec. 1.1, pp. 22, Dummit and Foote (2003) \cite{DuFo2003}.

Let $x \in G, a, b\in \mathbb{Z}^+$

In the following steps, I'll use induction a lot.
\begin{enumerate}
	\item[(a)] $x^{a+b} = x^a x^b $ and $(x^a)^b = x^{ab}$, prove.
	\[
	\begin{gathered}
		x^ax^b = x^a \cdot x \cdot x^{b-1} = x^{a+1} x^{b-1} = \dots = x^{a+b - 1} \cdot x = x^{a+b} \quad \, (\text{used associativity of group operation}) \\
		(x^a)^b = \underbrace{x^a \cdot x^a \cdots x^a }_{b \text{ times } } = x^{2a} \cdot \underbrace{x^a \dots x^a}_{ b- 2 \text{ times} } = x^{3a} \cdot \underbrace{x^a \dots x^a }_{b-3 \text{ times } } = \dots = x^{(b-1) a} \cdot x^a = x^{ (b-1) a + a} = x^{ba}
	\end{gathered}
	\]
	\item[(b)] 
	\[
	\begin{gathered}
		x^a \cdot x^{-a} = x^a \cdot (x^{-1})^a = x^{a-1} \cdot 1 \cdot (x^{-1})^{a-1} = \dots = x\cdot x^{-1} = 1 \Longrightarrow (x^a)^{-1} = x^{-a}
	\end{gathered}
	\]
	The steps previous depended upon defining $x^{-a} = (x^{-1})^a$
	\item[(c)] if $b=0$, $x^{a+0} = x^a = x^a x^b \Longrightarrow x^0 = 1$. $x^{ab} = x^0 = (x^a)^0 = 1$. \\
	
	$x^{a-b} = x^a \cdot x^{-b}$ since $x^{-b} = (x^{-1})^b$. \\
	
	$(x^a)^{-b} = ((x^a)^{-1})^b = (x^{-a})^b = x^{-ab}$ \\
	
	So $x^{a+b} = x^a x^b$, $(x^a)^{-1} = x^{-a}$ $\, \forall \, a,b \in \mathbb{Z}$
\end{enumerate}

\begin{theorem}[Cyclic groups are abelian]\label{Thm:CyclicGroupsAreAbelian}
	Cyclic groups are abelian since $x^a x^b = x^{a+b} = x^{b+a} = x^b x^a$
\end{theorem}

\begin{proposition}[]\label{Prop:OrderDividesExponentOfCyclicGroupGeneratorRelation}
cf. Dummit and Foote (2003) \cite{DuFo2003}, Prop. 3, pp. 55, Sec. 2.3

	Let arbitrary group $G$, $x\in G$, let $m, n \in \mathbb{Z}$. \\

	If $x^n = 1$, $x^m = 1$, then $x^d =1$, where $d= (m,n) \equiv \gcd{(m,n)}$ \\
	If $x^m = 1$, for some $m \in \mathbb{Z}$, then $|x|$ divides $m$ (recall $|x| \equiv $ order of $x :=$ smallest positive integer $n$ s.t. $x^n = 1$, Def. on pp. 20, Sec. 1.1 of Dummit and Foote (2003) \cite{DuFo2003}).
\end{proposition}

\begin{proof}
	By Euclidean Algorithm (Sec. 0.2, (6) of Dummit and Foote (2003) \cite{DuFo2003}), $\exists \, r, s \in \mathbb{Z}$ s.t. since $d= \gcd{(m,n)}$, $d|m$ and $d|n$, i.e. $m/d, n/d \in \mathbb{Z}$, i.e. $m = pd + r$, $n=qd + s$, with $r=s=0$. \\
	
	Consider $mr+ns = pdr + qds = (pr+qs)d$. Choose $r,s$ s.t. $pr + qs = 1$ (TODO: need to prove Euclidean Algorithm) \\

	$x^d = x^{mr + ns} = (x^m)^r (x^n)^s = 1^r 1^s = 1$. \\
	
	If $x^m = 1$, let $n=|x|$. If $m=0$, $n |m$, i.e. $m/n = 0/n$, so assume $m \neq 0$. \\
	
	Since some nonzero power of $x,m$, is identity $n < \infty$. \\
	
	Let $d= (m,n) = \gcd{(m,n)}$, so $x^d = 1$ by preceding result for Prop. \ref{Prop:OrderDividesExponentOfCyclicGroupGeneratorRelation}. \\
	
	Since $0 < d \leq n$, and $n$ is smallest positive power of $x$ s.t. $x^n= 1$ (def. of order of a group), $d=n$, so $n | m \equiv m/n = m / |x|$. 
\end{proof} 

\begin{theorem}[Dummit and Foote, Thm. 4 (2003) \cite{DuFo2003}]\label{Thm:CyclicGroupSameOrderIsomorphism}
	Any 2 cyclic groups of the same order are isomorphic; more specifically, 
	\begin{enumerate}
		\item[(1)] if $n\in \mathbb{Z}^+$, $\langle x \rangle, \langle y \rangle$ are cyclic groups of order $n$, then
		\begin{equation}
			\begin{aligned}
				\varphi : & \langle x \rangle \to \langle y \rangle \\
				& x^k \mapsto y^k 
			\end{aligned}
		\end{equation}
		is well-defined and an isomorphism.
		\item[(2)] If $\langle x \rangle$ is infinite cyclic group, map $\varphi$ 
		\begin{equation}
			\begin{aligned}
				\varphi & : \mathbb{Z} \to \langle x \rangle \\
				& k \mapsto x^k
			\end{aligned}
		\end{equation}
		is well-defined and is an isomorphism.
	\end{enumerate}
\end{theorem} 

\begin{proof}
	Suppose $\langle x \rangle, \langle y \rangle$ are cyclic groups of order $n$. Let $\varphi: \langle x \rangle \to \langle y \rangle$ s.t. $\varphi(x^k) = y^k$. \\
	
	$\varphi$ \textbf{well-defined}? \emph{Prove}: \\
	if $x^r = x^s$, then $\varphi(x^r) = \varphi(x^s)$. \\
	
	Since $x^{r-s} = 1$, by Prop. \ref{Prop:OrderDividesExponentOfCyclicGroupGeneratorRelation}, $|x| | r-s$, i.e. $r-s / |x|$, so $r-s = |x|$ or $r = tn + s$, so 
	\[
	\varphi(x^r) = \varphi(x^{tn + s}) = y^{tn + s} = (y^n)^t y^s = 1^t y^s = y^s = \varphi(x^s)
	\]
	
	$\varphi$ well-defined. \\

$\varphi(x^a x^b) = \varphi(x^{a+b}) = y^{a+b} = y^a y^b = \varphi(x^a) \varphi(x^b)$, so $\varphi$ homomorphism.  \\

Since $y^k = \varphi(x^k)$, $\varphi$ surjective. \\

Since both groups have same finite order, any surjection from 1 to the other is bijection, so $\varphi$ isomorphism.  \\

Alternatively, $\begin{aligned}
& \varphi^{-1}:\langle y \rangle \to \langle x \rangle
& \varphi^{-1}(y^k) = x^k 
\end{aligned}$ \quad \, and \quad \, $\begin{aligned} & \varphi \circ \varphi^{-1}(y^k) = y^k \\
& \varphi^{-1}\circ \varphi(x^k) = x^k \end{aligned}$.

If $\langle x \rangle$ infinite cyclic group, let $\varphi : \mathbb{Z} \to \langle x \rangle$ defined by $\varphi(k) = x^k$.  $\varphi$ well-defined since if $k = l$ for $x,y \in \mathbb{Z}$, 
\[
x^k = x^l = \varphi(k) = \varphi(l)
\]

By Prop. 2 of Dummit and Foote (2003) \cite{DuFo2003}, pp. 55, Sec. 2.3, (if $H=\langle x \rangle$, $|H| = |x|$), if $x^a \neq x^b$, $\forall\, a, b \in \mathbb{Z}$, $a\neq b$, $\varphi$ injective. $\forall \, x^k \in \langle x \rangle$, $k \in \mathbb{Z}$, so $\varphi(k) = x^k$ is surjective. \\
Law of exponents ensure $\varphi$ homomorphism, (as above), hence $\varphi$ isomorphism. 

\end{proof}

\begin{theorem}[Cyclic Group and Integer Modulo $N$ are isomorphic]\label{Thm:CyclicGroupIntegerModuloNIsomorphic}
	Up to isomorphism, $Z_n$ is the unique cyclic group of order $n$ and $Z_n \simeq \mathbb{Z}/ n\mathbb{Z}$
\end{theorem}

\subsection{Binary Representation, fixed-width integers as Abelian group}

For $x\in \mathbb{Z}$, $B2U(x) = \sum_{i=0}^{w-1} x_i \cdot 2^i \equiv \sum_{i=0}^{w-1} x_i b^i$, where $b=2$, $w= $ total number of bits to represent $x$. \\

Consider $n=2^w$. \\

Observe that if $\sum_{i=0}^{w-1} 1 \cdot 2^i = S$, $2S = \sum_{i=1}^{w-1} 2^i + 2^w = S - 1  + 2^w$. So $S = 2^w-1$, and so consider integers modulo $n=2^w$. 

\[
\mathbb{Z} / 2^w \mathbb{Z} = \lbrace \overline{a} = \lbrace a + kn | k \in \mathbb{Z} \rbrace \rbrace = \lbrace \overline{a} = \lbrace a + k 2^w | k \in \mathbb{Z} \rbrace \rbrace
\]
and was shown that $0\leq a < 2^w$.

Observe that if $x=  2^w + \sum_{i=0}^{w-1} x_i \cdot 2^i$, \\

since $x \leq 2^w - 1$, \, $\forall \, x,y \in \mathbb{Z} / 2^w \mathbb{Z}$, $x+y\leq 2 \cdot 2^w - 2 = 2^{w+1} - 2 = \sum_{i=0}^w 2^i + 1 - 2 = \sum_{i=0}^w 2^i - 1 \sim \left( \sum_{i=0}^{w-1} 2^i - \right) \bmod{2^w}$ \\


Consider $2^w - 1 = \sum_{i=0}^{w-1} 1 \cdot 2^i$. Then $2^w = \sum_{i=0}^{w-1} 1 \cdot 2^i + 1  = \sum_{i=0}^w x_i \cdot 2^i$ where $x_i = 0$ unless $i=w$, so $x_w = 1$. Define one's complement addition s.t. $2^w \bmod{2^w} = 0 \bmod 2^w$ \\

Then $B2U(x) \bmod{2^w}$ is a cyclic group s.t. $(\overline{1})^{2^w} \equiv \sum_{i=1}^{2^w} 1 = \sum_{i=0}^{2^w -1} 1 = 2^w \bmod{2^w} = 0 \bmod{w^2}$, $\forall \, w \in \mathbb{Z}^+$.

\section{Groups; normal subgroups}  

\begin{definition}[normal subgroup $K \lhd G$] \qquad \, \\
\textbf{normal subgroup} $K$ of $G \equiv K \lhd G$   - 

subgroup $K\subset G$, if $\forall \, k \in K$, $\forall \, g \in G$, 
\[
gkg^{-1} \in K
\]
\end{definition}

\begin{definition}[quotient group] \qquad \, \\
\textbf{quotient group} $G\mod{K} \equiv G/K$ -  

if $G/K = $ family of all left cosets of subgroups $K\subset G = $
\[ 
= \lbrace gK | g\in G, gK = \lbrace gk | k \in K \rbrace 
\]
and 

$K = $ normal subgroup of $G$, i.e. $K \lhd G$, and so 
\[
aK bK = abK \qquad \, \forall \, a,b \in G, 
\]
so $G/K $ group.  
\end{definition}





% 20170925 

\begin{definition}[exact sequence of groups]
	\textbf{exact sequence} if $\text{im}f_{n+1} = \text{ker}f_n$  \qquad \, $\forall \, n $ for sequence of group homomorphisms and groups 
\begin{equation}
\begin{tikzpicture}
%\matrix(m)[matrix of math nodes, row sep=3em, column sep=3em, text height=1.5ex, text depth=0.25ex]
\matrix(m)[matrix of math nodes, row sep=4em, column sep=4em]
{
	G_{n+1}   &  G_n & G_{n-1} \\
};
%\path[->,font=\scriptsize]
\path[->]
(m-1-1) edge node[auto]{$f_{n+1}$} (m-1-2)
(m-1-2) edge node[auto]{$f_n$} (m-1-3);
\end{tikzpicture} 
\end{equation}
\end{definition}

	
\begin{theorem}
	\begin{enumerate}
		\item \[
		\begin{tikzpicture}
		%\matrix(m)[matrix of math nodes, row sep=3em, column sep=3em, text height=1.5ex, text depth=0.25ex]
		\matrix(m)[matrix of math nodes, row sep=4em, column sep=4em]
		{
			1   &  A & B \\
			%\path[->,font=\scriptsize]
		};
		\path[->]
		(m-1-2) edge node[auto]{$f$} (m-1-3);
		\end{tikzpicture} 
		\]
		\item \[
		\begin{tikzpicture}
		%\matrix(m)[matrix of math nodes, row sep=3em, column sep=3em, text height=1.5ex, text depth=0.25ex]
		\matrix(m)[matrix of math nodes, row sep=4em, column sep=4em]
		{
			B   &  C & 1 \\
		};
		%\path[->,font=\scriptsize]
		\path[->]
		(m-1-1) edge node[auto]{$g$} (m-1-2);
		\end{tikzpicture} 
		\]
		\item \[
		\begin{tikzpicture}
		%\matrix(m)[matrix of math nodes, row sep=3em, column sep=3em, text height=1.5ex, text depth=0.25ex]
		\matrix(m)[matrix of math nodes, row sep=4em, column sep=4em]
		{
			1 & A   &  B & 1 \\
		};
		%\path[->,font=\scriptsize]
		\path[->]
		(m-1-2) edge node[auto]{$h$} (m-1-3);
		\end{tikzpicture} 
		\]
		
	\end{enumerate}
\end{theorem}

\begin{proof}
	\begin{enumerate}
		\item $\text{im}(1\to A)=1$, since $1\to A$ is a group homomorphism $((1\to A)(1) = 1_A)$.  \\
		if $1\to A \xmapsto[]{f} B$ exact, $\text{ker}f = \text{im}(1\to A)=1$, so if $f(x)=1$, $x=1$, $f$ injective.  \\
		If $f$ injective, $\text{ker}f=1$.  $1=\text{im}(1\to A)$.  $1\to A \xmapsto{f}B$, exact.  
		\item $\text{ker}(C\to 1) = C$, by def. of $C\to 1$ \\
		if $B \xmapsto{g} C \to 1$ exact, $\text{im}g = g(B) = \text{ker}(C\to 1)= C$.  $g(B) = C$ implies $g$ surjective.  \\
		If $g$ surjective, $g(B) = C =\text{ker}(C\to 1)$.  $B\xmapsto{g} C \to 1$ exact.  
		\item From (i), $1\to A \xmapsto{h}B$ exact iff $h$ injective.  
		From (ii), $A\xmapsto{h}B \to 1$, exact iff $h$ surjective.  \\
		$h$ isomorphism.  
	\end{enumerate}
\end{proof}








% 20170925 END





\subsection{1st, 2nd, 3rd Isomorphism Theorems}

\begin{theorem}[1st Isomorphism Theorem (Modules) Thm. 7.8 of Rotman (2010) \cite{JRotman2010}]
If $f:M\to N$ is $R$-map of modules, then $\exists \, R$-isomorphism s.t. 
\begin{equation}
	\begin{aligned}
	& \varphi : M /\text{ker}f \to \text{im}f \\ 
	& \varphi: m + \text{ker}f \mapsto f(m)
\end{aligned} \qquad \qquad \, \begin{tikzpicture}
%\matrix(m)[matrix of math nodes, row sep=3em, column sep=3em, text height=1.5ex, text depth=0.25ex]
\matrix(m)[matrix of math nodes, row sep=4em, column sep=4em]
{
M   &  N \\
M/\text{ker}f  &  \\};
%\path[->,font=\scriptsize]
\path[->]
(m-1-1) edge node[auto]{$f$} (m-1-2)
edge node[auto]{$\pi$} (m-2-1) 
(m-2-1) edge node[right]{$\varphi = \cong$} (m-1-2);
\end{tikzpicture} 
\end{equation}
%Essentially, 
%\begin{equation}

%\end{equation}
\end{theorem}

\begin{proof}
	View $M,N$ as abelian groups.  

Recall natural map $ \begin{aligned} & \quad \\ 
	& \pi : M \to M/N \\
& m\mapsto m + N \end{aligned}$  

Define $\varphi$ s.t. $\varphi \pi = f$.  

($\varphi$ well-defined).  Let $m+\text{ker}f = m' + \text{ker}f$, $m,m' \in M$, then $\exists \,  n \in \text{ker}f$ s.t. $m=m'+n$.  
\[
\varphi(m+\text{ker}f) = \varphi\pi (m) = f(m) = f(m' +n ) = f(m') + f(n) = \varphi \pi(m') + 0 = \varphi(m' + \text{ker}f )
\]
$\Longrightarrow \varphi $ well-defined.  

($\varphi$ surjective).  Clearly, $\text{im}\varphi \subseteq  \text{im} f$.   \\
Let $y\in \text{im}f$.  So $\exists \,  m \in M$ s.t. $y=f(m)$.  $f(m) = \varphi \pi (m) = \varphi(m+\text{ker}f) = y$.  So $y\in \text{im}\varphi$.  $\text{im}f\subseteq \text{im}\varphi$.  \\
$\Longrightarrow \varphi $ surjective.  

($\varphi$ injective)  If $\varphi(a+\text{ker}f) = \varphi(b+\text{ker}f)$, then 
\[
\begin{gathered}
\varphi\pi(a) = \varphi\pi(b) \text{ or } f(a) = f(b) \text{ or } 0 = f(a) -f(b) = f(a-b) \text{ so } a-b \in \text{ker}f
	(a-b) + \text{ker}f = \text{ker}f \text{ so } a + \text{ker}f = b +\text{ker}f 
\end{gathered}
\]
$\varphi$ isomorphism.  

$\varphi$ $R$-map.  $\varphi(r(m+N)) = \varphi(rm+N) = f(rm)$.    \\
Since $f$ $R$-map, $f(rm) = rf(m) = r\varphi(m+N)$.  $\varphi$ is $R$-map indeed.  


\end{proof}


\begin{theorem}[2nd Isomorphism Theorem (Modules) Thm. 7.9 of Rotman (2011) \cite{JRotman2010}]
If $S,T$ are submodules of module $M$, i.e. $S,T \in M$, then $\exists \, $ $R-$isomorphism  
\begin{equation}
\begin{gathered}
	S/(S\cap T) \to (S+T)/T
\end{gathered} \qquad \, 
\qquad \qquad \, \begin{tikzpicture}
\matrix(m)[matrix of math nodes, row sep=4em, column sep=4em]
{
S   &  (S+T)/T = \text{im}h \\
S/(S\cap T) = S/\text{ker}h  &  \\};
\path[->]
(m-1-1) edge node[auto]{$h$} (m-1-2)
edge node[auto]{$\left. \pi \right|_S$} (m-2-1) 
(m-2-1) edge node[right]{$ \cong$} (m-1-2);
\end{tikzpicture} 
\end{equation}
\end{theorem}

\begin{proof}
Let natural map $\pi : M \to M/T$.   \\
\phantom{Let} So $\text{ker}\pi = T$.  

Define $h:= \left. \pi \right|_S$, so $h: S\to M/T$, so $\text{ker}h = S\cap T$, 
\[
(S+T)/T = \lbrace (s+t) + T | a\in S+T, s\in S, t\in T \rbrace
\]
i.e. $(S+T)/T$ consists of all those cosets in $M/T$ having a representation in $S$.  

By 1st. isomorphism theorem, 
\[
S/S\cap T \xrightarrow{ \cong} (S+T)/T
\]

\end{proof}  % END of pf. of 2nd Isomorphism Theorem (Modules) Thm. 7.9 of Rotman (2011)

\begin{theorem}[3rd Isomorphism Theorem (Modules) Thm. 7.10 of Rotman (2011) \cite{JRotman2010}]
If $T\subseteq S \subseteq M$ is a tower of submodules, then $\exists \, $ $R$-isomorphism
\begin{equation}
\begin{gathered}
	(M/T)/(S/T) \to M/S
\end{gathered} \qquad \,  \begin{tikzpicture}
\matrix(m)[matrix of math nodes, row sep=4em, column sep=4em]
{
M/T   &  M/S\\
(M/T)/(S/ T) = (M/T)/\text{ker}g  &  \\};
\path[->]
(m-1-1) edge node[auto]{$g$} (m-1-2)
edge node[auto]{$ \pi $} (m-2-1) 
(m-2-1) edge node[right]{$ \cong$} (m-1-2);
\end{tikzpicture} 
\end{equation}
\end{theorem}

\begin{proof}
	Define $g:M/T \to M/S$ to be \textbf{coset enlargement}, i.e. 
\begin{equation}
	g:M +T \mapsto m+S
\end{equation}
$g$ well-defined: if $m+T = m'+T$, then $m-m' \in T\subseteq S$, and $m+S = m'+S \Longrightarrow g(m+T) = g(m'+T)$

$\text{ker}g = S/T$ since 
\[
\begin{aligned}
	& g(s+T) = s+S = S  \qquad \, (S/T \subseteq \text{ker}g)   \\
	& g(m+T) = m + S = 0 = S = s + S, \text{ so } m=s \Longrightarrow \text{ker}g \subseteq S/T
\end{aligned}
\]
$\text{im}g = M/S $ since 
\[
\begin{aligned}
	& g(m+T) = m+S \Longrightarrow \text{ im}g \subseteq M/S \\ 
 	& m+S = g(m+T)
\end{aligned}
\]
Then by 1st isomorphism, and commutative diagram, done.  
\end{proof} % END of pf. of 3rd Isomorphism Theorem (Modules) Thm. 7.10 of Rotman (2011) 

\section{Rings} 

cf. Ch. 7 "Introduction to Rings" pp. 223, Dummit and Foote (2014)\cite{DuFo2003}

\begin{definition}[Ring]
ring $R$ is a set, together with 2 binary operations $+, \times $ (addition and multiplication, $\times \equiv \cdot $) s.t. 
\begin{enumerate} 
\item \begin{enumerate}
	\item $(R, +)$ abelian group 
	\item $\times $ associative: $a(bc) = (ab)c \quad \, \forall \, a, b, c \in R$  
	\item distributivity in $R$: $\forall \, a , b, c \in R$ 
	\[
	(a+b)c = ac + bc \text{ and } a(b+c) = ab + ac
	\]
\end{enumerate}	
\item $R$ \emph{commutative} if multiplication commutative
\item $R$ has an identity $1$ if $\exists \, 1 \in R$ s.t.
\[
1a = a1 = a \quad \, \forall \, a \in R
\]
\end{enumerate}
\end{definition}

\begin{definition}[division ring]
	ring $R$ with identity $1$, where $1\neq 0$ is a \textbf{division ring} (or skew field) if $\forall \, a \in R$, $a\neq 0$, $\exists \, $ multiplicative inverse $1/a$, i.e. $\exists \, b\in R$ s.t. $ab=ba = 1$
\end{definition}

e.g. 
\begin{enumerate}
	\item rational numbers $\mathbb{Q}$ \\
	real numbers $\mathbb{R}$ \\
	complex numbers $\mathbb{C}$ \\ 
	are commutative rings with identity (in fact, they're fields) \\
	Ring axioms for each follow ultimately from ring axioms for $\mathbb{Z}$ \\
	(verified when $\mathbb{Z}$ constructed from $\mathbb{Z}$ (Sec. 7.5)), $\mathbb{C}$ from $\mathbb{R}$ (Example 1, Sec. 13.1). \\
	Construction of $\mathbb{R}$ from $\mathbb{Z}$ carried out in basic analysis texts
	\item \textbf{quotient group} $\mathbb{Z}/n\mathbb{Z}$ is a commutative ring with identity (element 1) under operations of addition and multiplication of residue classes (frequently referred to as "modular arithmetic").  \\
	We saw additive abelian groups axioms followed from general principles of theory of quotient groups ($\mathbb{Z}/n\mathbb{Z}$) was prototypical quotient group. cf. Example 4, pp. 224, Dummit and Foote (2014)\cite{DuFo2003}
	\item \textbf{the (real) Hamiltonian Quaternions}.  
	\begin{definition}[(real) Hamiltonian Quaternions]
		Let $\mathbb{H} = \lbrace a+ bi + cj + dk | a,b,c,d \in \mathbb{R} \rbrace$ s.t. 
		"componentwise" addition is defined as 
		\begin{equation}
		(a+bi + cj+dk) + (a' + b'i + c'j + d'k) = (a+a') + (b+b')i + (c+c')j + (d+d')k
		\end{equation} and multiplication defined by expanding using distributive laws 
		\[
		(a+bi + cj +dk)(a' + b'i + c'j +d' k)
		\]
		using 
		\begin{equation}
		\begin{aligned}
		& i^2 = j^2 =k^2 = -1 \\
		& ij = -ji = k \\
		& jk = -kj = i \\
		& ki = -ik = j
		\end{aligned}
		\end{equation}
	\end{definition}
Working out the multiplication
\[
\begin{gathered}
(a+bi + cj + dk)(a'+b'i + c'j + d'k) =  \\
= \begin{aligned}
& aa' + ab' i + ac'j + ad'k + ba' i - bb' + bc' k -bd' j + \\
& ca'j - cb' k - cc' + cd' i + da' k + db' j - dc' i -dd' = \\
\end{aligned} \\
= aa' - bb' -cc' -dd' + (ab' + ba' + cd' -dc')i + (ac' - bd' + ca' +db')j + (ad' + bc' - cb' + da')k 
\end{gathered}
\]
Hamiltonian Quaternions are noncommutative ring with identity ($1= 1 + 0i + 0j + 0k$). 

Similarly define \emph{rational} Hamiltonian Quaternions ring by taking $a,b,c,d\in \mathbb{Q}$.  

real and rational Hamiltonian Quaternions both are divison rings, where inverse of nonzero element defined as 


\begin{equation}
(a+bi +cj + dk)^{-1} = \frac{ a-bi -cj -dk}{ a^2 + b^2 + c^2 + d^2 }
\end{equation} cf. Example 5, pp. 224, Dummit and Foote (2014)\cite{DuFo2003}

\item \textbf{rings of functions} (important class) \\
Let $X$ be any nonempty set. \\
Let $A$ be any ring. 

\begin{definition}[function ring]
	collection $R= \lbrace f:X\to A \rbrace$ is a ring under pointwise addition and multiplication of functions s.t. 
	\begin{equation}
	\begin{aligned}
	(f+g)(x) & = f(x) + g(x) \\
	(fg)(x) & = f(x)g(x)
	\end{aligned}
	\end{equation}
\end{definition}
	
cf. Example 6, pp. 225, Dummit and Foote (2014)\cite{DuFo2003}

\item cf. Example 7 of p. 225, Dummit and Foote (2014)\cite{DuFo2003} \emph{ring which doesn't have an identity}:

\begin{itemize}
	\item  ring $2\mathbb{Z}$ of even integers (sum and product of even integers is an even integer) \\
\item function $f: \mathbb{R} \to \mathbb{R}$ has compact support if $\exists \, a, b \in \mathbb{R}$, (depending on $f$) s.t. $f(x) = 0$, \quad \, $\forall \, x \notin [a,b]$ \\
$\lbrace f: \mathbb{R}\to \mathbb{R} | f \text{ has compact support } \rbrace$ is a commutative ring without identity (since an identity couldn't have compact support), 

Similarly, \\
$\lbrace \text{ cont. } f : \mathbb{R} \to \mathbb{R} | f \text{ has compact support } \rbrace$ is a commutative ring without identity. 
\end{itemize}	
\end{enumerate}

\begin{proposition}[Dummit and Foote (2014)\cite{DuFo2003}, Prop. 1, pp. 226]
Let $R$ be a ring. \\
Then
\begin{enumerate}
	\item $0a = a0 = 0$ \, $\forall \, a \in R$ 
	\item $(-a) 0 = a(-b) = -(ab) \quad \, \forall \, a,b \in R$ (recall $-a$ is additive inverse of $a$)
	\item $(-a)(-b) =ab$ \quad \, $\forall \, a, b \in R$ 
	\item if $R$ has identity $1$, identity unique and $-a = (-1) a$
\end{enumerate}
\end{proposition}

\begin{proof}
Use distributivity and additive existence inverse for abelian group $(R, +)$. 

\begin{enumerate}
	\item \[
	\begin{gathered}
	0a = (0 + 0) a = 0a + 0a \to 0a = 0 
	a0 = a(0 + 0) = a0 + a0 \text{ so } a0 = 0 	
	\end{gathered}
	\]
	\item 
	\[
	\begin{gathered} 
	ab + (-a)b = (a + (-a)) b = 0b = 0 \Longrightarrow (-a) b = -(ab) \\
	ab + a(-b) = a(b + (-b)) = a0 = 0 \Longrightarrow a(-b) = -(ab) 	
	\end{gathered} 
	\]
	\item \[
	(-a)(b + (-b)) = (-a)b + (-a)(-b) = -(ab) + (-a)(-b) = 0 \Longrightarrow (-a)(-b) =ab
	\]
	\item \[
	(-1)a  + a = (-1) a + 1a = (-1 + 1) a = 0a = 0 \text{ so } -a = (-1) a
	\]
	Suppose $\exists \, 1'$ s.t. $1' a = a1' = a$ and $1' \neq 1$  
	\[
	\begin{gathered}
	-a + a = 0 = (-1) a + 1' a = (-1 + 1') a = 0 a \Longrightarrow 0 = -1 + 1' 
	\end{gathered}
	\]
	Then $1' = 1$. Contradiction. 
\end{enumerate}
\end{proof}

\begin{definition}
Let $R$ be a ring.
\begin{enumerate}
	\item \textbf{zero divisor} $a$, $a\neq 0$, $a\in R$ if $\exists \,  b\in R, \, b\neq 0$ so either $ab= 0$ or $ba=0$. 
	\item Assume $R$ has identity $1\neq 0$. \\
	\textbf{unit} in $R$, $u\in R$ if $\exists \,$ some $v\in R$ s.t. $uv = vu =1$. \\
	$R^x \equiv $ set of units in $R$. 
	\[
	\forall \, u,v \in R^x, \, (uv) (v^{-1}u^{-1}) = u(1)u^{-1} = 1
	\]
	$1 \in R^x$ so, $1u = u1 = u$ \\
	if $u\in R^x$, $u^{-1} \in R^x$ since $uu^{-1} = u^{-1} u =1$ 
$R^x$ is a \textbf{group of units}
\end{enumerate}	
\end{definition} 

Thus a \emph{field} $= $ commutative ring $F$ with identity $1\neq 0$ s.t. $\forall \, a\in $ field, $a\neq 0$ is a unit, i.e. $F^x = F - \lbrace 0 \rbrace$. 

\begin{proposition}
	zero divisor can never be a unit. 
\end{proposition}

\begin{proof}
	Suppose a unit in $R$, and $ab=0$ for some $b\neq 0$, $b\neq R$. \\
	Then $va=1$ s.t. some $v\in R$ and 
	\[
	b =1b = vab = v(ab) = v(0) = 0
	\]
	Contradiction.
\end{proof} 	

\section{Commutative Rings}

cf. Ch. 3 "Commutative Rings I" of Rotman (2010) \cite{JRotman2010}


\begin{definition} commutative ring $R$ is a set with 2 binary operations, addition and multiplication, s.t.
	\begin{enumerate}
		\item[(i)] $R$ abelian group under addition 
		\item[(ii)] (commutativity) $ab=ba$ \quad $\forall \, a,b \in R$  (this isn't there for noncommutativity)
		\item[(iii)] (associativity) $a(bc) = (ab)c$ \quad \, $\forall \, a,b,c\in R$
		\item[(iv)] $\exists \, 1 \in R$ s.t. $1a = a$ \, $\forall \, a  \in R$ \quad \, (many names used: one, unit, identity)
		\item[(v)] (distributivity) $a(b+c) = ab+ac$ \quad \, $a,b,c \in R$ (this splits up into 2 distributivity laws for noncommutativity)
	\end{enumerate}
\end{definition}

To reiterate, abelian group under addition $R$ (is defined as)
\begin{enumerate}
	\item associative $\forall \, x , y ,z \in R$, $x + (y+z) = (x+y)+z$ 
	\item $\exists \, 0 \in R$, $0+x = x + 0$, \, $\forall \, x \in R$ 
	\item $\forall \, x \in R$, $\exists \, (-x) \in R$ s.t. $x+(-x) = 0 = (-x) + x$
\end{enumerate}
abelian, if commutativity: $x+y=y+x$.  

\subsection{Linear Algebra; Linear Algebra with commutative rings as fields}

\subsubsection{Linear Algebra}

\begin{definition}[subspace]
	If $V$ vector space over field $k$, \\
	then \textbf{subspace} of $V$ is subset $U$ of $V$ s.t. 
	\begin{enumerate}
		\item $0\in U$
		\item $u,u' \in U$ imply $u+u' \in U$ 
		\item $u\in U$, and $a\in k$ imply $au \in U$
	\end{enumerate}
	\textbf{proper subspace} of $V \equiv U \subsetneq V$ is subspace $U \subseteq V$ with $U \neq V$.
\end{definition}
$U =V$, $U = \lbrace 0 \rbrace$ are always subspaces of a vector space $V$. 

\textbf{Examples} (Example 3.70 Rotman (2010) \cite{JRotman2010}) 
\begin{enumerate}
	\item[(ii)] If $V=(a_1, \dots a_n)$, $v\neq 0$, $v\in \mathbb{R}^n$, \\
	line through origin $l = \lbrace av | a \in \mathbb{R} \rbrace$ is a subspace of $\mathbb{R}^n$. \\
	plane through origin $=\lbrace av_1 + bv_2 | v_1 , v_2 \text{ fixed pair of noncollinear vectors, } a,b \in \mathbb{R} \rbrace$ are subspaces of $\mathbb{R}^n$
	\item[(iii)] If $m\leq n$, $\mathbb{R}^m$ regarded as set of all vectors in $\mathbb{R}^n$ s.t. last $n-m$ coordinates are $0$, then $\mathbb{R}^m$ subspace of $\mathbb{R}^n$.
	e.g. $\mathbb{R}^2 = \lbrace (x,y,0) \in \mathbb{R}^3 \rbrace \subsetneq \mathbb{R}^3$
	\item[(iv)] If $k$ field, \textbf{homogeneous linear system over $k$ } of $m$ equations in $n$ unknowns is a set of equations
	\[
	\begin{aligned}
	a_{11} x_1 + \dots + a_{1n} x_n = 0 & \\
	a_{21} x_1 + \dots + a_{2n} x_n = 0 & \\
	\vdots \vdots & \\
		a_{m1} x_1 + \dots + a_{mn} x_n = 0 & 
	\end{aligned}
	\] 
	where $a_{ji} \in k$.
	
	\textbf{solution} of this system is vector $(c_1 \dots c_n) \in k^n$ s.t. $\sum_i a_{ji} c_i  =0$, $\forall \, j$. \\
	solution $(c_1 \dots c_n)$ \textbf{nontrivial} if $\exists$ some $c_i \neq 0$. \\
	\textbf{solution space} (or null space) of system $=$ set of all solutions. \\
	solution space also a subspace of $k^n$
\end{enumerate}

e.g. $k = \mathbb{I}_p$, 
\[
\begin{aligned}
& 3x - 2y + z \equiv 1 \bmod{7} \\
& x + y -2 z \equiv 0 \bmod{7} \\
& -x + 2y + z \equiv 4 \bmod{7}
\end{aligned}
\]
\begin{definition}[list]
	list $:=$ vector space $V$ is ordered set $v_1 \dots v_n$ of vectors in $V$, i.e. 
	$\exists \, $ some $n\geq 1$, $\exists \, $ some function $\varphi$ 
	\[
	\varphi : \lbrace 1,2\dots n \rbrace \to V
	\]
	with $\varphi(i) = v_i \quad \, \forall \, i$
\end{definition}

Thus, $X = \text{im}\varphi$.

$X$ ordered, $\varphi$ need not be injective. 

\begin{definition}[k-linear combination]
	$k$-linear combination of list $v_1\dots v_n$ in $V$, $V\equiv $ vector space over field $k$, is vector $v$ of form 
	\[
	v = a_1 v_1 + \dots + a_n v_n  = \sum_{i=1} a_i v_i \quad \, \forall \, a_i \in k, \, \quad \, \forall \, i
	\]
\end{definition}

\begin{definition}[list]
	If list $X = v_1 \dots v_m$ in vector space $V$, then \\
	\textbf{subspace spanned by } $X$, $\langle v_1 \dots v_m \rangle := $ set of all $k$-linear combinations of $v_1 \dots v_m$.  Also, say $v_1 \dots v_m $ spans $\langle v_1 \dots v_m\rangle$. 
\end{definition}

\begin{lemma}[$\langle v_1 \dots v_m \rangle$ is smallest subspace of $V$ containing $v_1\dots v_m$]\label{Lemma:smallest_subspace}
\begin{enumerate}
	\item[(i)] Every intersection of subspaces of $V$ is itself a subspace.
	\item[(ii)] If $X= v_1 \dots v_m$ list in $V$, then intersection of all subspaces of $V$ containing $X$ is $\langle v_1 \dots v_m \rangle$, subspace spanned by $v_1\dots v_m$, so $\langle v_1 \dots v_m \rangle$ is smallest subspace of $V$ containing $X$. 
\end{enumerate}
\end{lemma}
cf. (Lemma 3.71 Rotman (2010) \cite{JRotman2010}) 

\begin{proof}
\begin{enumerate}
	\item[(i)] Consider $\bigcap_{\alpha \in I} V_{\alpha}$, $\forall \, \alpha \in I$, $V_{\alpha} $ subspace of $V$
	\begin{enumerate}
		\item[(i)] $0\in V_{\alpha}$, $\forall \, \alpha \in I$, so $0\in \bigcap_{\alpha \in I} V_{\alpha}$,
		\item[(ii)] Let $u,u' \in \bigcap_{\alpha \in I} V_{\alpha}$. Then $u,u' \in V_{\alpha}$, $\forall \, \alpha \in I$. Consider $\beta \in I$. $u, u' \in V_{\beta}$, so $u+u' \in V_{\beta}$.  Without loss of generality, $u + u' \in V_{\alpha}$, $\forall \, \alpha \in I$.  Then $u+u' \in \bigcap_{\alpha \in I} V_{\alpha}$
		\item[(iii)] Let $u\in \bigcap_{\alpha \in I} V_{\alpha}$.  Consider $\alpha \in k$. Since $u\in V_{\alpha}$, $\forall \, \alpha \in I$, $au\in V_{\alpha}$, $\forall \, \alpha \in I$.  \\
		Then $au \in \bigcap_{\alpha \in I} V_{\alpha}$
	\end{enumerate}
\item[(ii)] Let $X = \lbrace v_1 \dots v_m \rbrace$, let $\mathcal{S} \equiv $ family of all subspaces of $V$ containing $X$. 

$\bigcap_{S \in \mathcal{S}} S \subseteq \langle v_1 \dots v_m \rangle$ because $\langle v_1 \dots v_m \rangle \in \mathcal{S}$, since, \\
\qquad \, $\langle v_1 \dots v_m \rangle$ is \emph{a} subspace of $V$ containing $X$. 

If $S\in \mathcal{S}$, then $S\ni v_1 \dots v_m$.  As shown above, $\forall \, v\in \langle v_1 \dots v_m \rangle$, $v\in S$, and thus $v\in \bigcap_{S\in \mathcal{S}} S$. $\langle v_1 \dots v_m \rangle \subseteq \bigcap_{S\in \mathcal{S}} S$.  
\end{enumerate}
	\end{proof}

Were all terminology in algebra consistent, \\
$\langle v_1 \dots v_m \rangle \equiv $ subspace \emph{generated} by $X$.  

Reason for different terms is that group theory, rings, vector spaces developed independently of each other.

\textbf{Example 3.72 of Rotman (2010) \cite{JRotman2010}}
\begin{enumerate}
	\item[(i)]
	\item[(ii)]
	\item[(iii)] \textbf{polynomial vector space; polynomials as a vector space}.  \\
	Vector space need not be spanned by finite list. \\
	e.g. $V=k[x]$, \\
	Suppose $X= f_1(x) \dots f_m(x)$ finite list in $V$. \\
	If $d= $ largest degree of any of $f_i(x)$, \\
	then every (nonzero) $k$-linear combination of $f_1(x), \dots f_m(x)$ has degree at most $d$. \\
	Thus $x^{d+1} \notin \langle f_1(x) \dots f_m(x) \rangle$, so $X$ doesn't span $k[x]$
\end{enumerate}

\begin{definition}[finite-dimensional vector space; infinite-dimensional vector space]
	Vector space $V$ is \textbf{finite-dimensional} if it's spanned by a finite list; otherwise $V$ is \textbf{infinite-dimensional}.
\end{definition}

\begin{proposition}[linear dependent span properties]
If vector space $V$, list $X=v_! \dots v_m$ spanning $V$, following are equivalent:
	\begin{enumerate}
		\item[(i)] $X$ isn't shortest spanning list 
		\item[(ii)] some $v_i$ is in subspace spanned by others, i.e. $v_i \in \langle v_i \dots \widehat{v}_i \dots v_m \rangle$, 
		\item[(iii)]		$\exists \, a_1 \dots a_m$ not all $0$ s.t. $\sum_{l=1}^m a_l v_l = 0$
	\end{enumerate}
\end{proposition}

\begin{proof}
(i) $\Longrightarrow$ (ii). If $X$ isn't shortest spanning list, then 1 of vectors in $X$ can be thrown out, and shorter list still spans, i.e. cf. Lemma \ref{Lemma:smallest_subspace}(Lemma 3.71, Rotman (2010) \cite{JRotman2010}); let $\mathcal{S} \equiv $ family of all subspaces of $V$ containing $X$. 

EY: 20180610 
Let $\bigcap_{S\in \mathcal{S}} S$. $\bigcap_{S \in \mathcal{S}} S \neq \langle v_1 \dots v_m \rangle$, $\bigcap_{S \in \mathcal{S}} S \subset \langle v_1 \dots v_m \rangle$ \\
$\exists \, v \in \langle v_1 \dots v_m \rangle$, say$v= \sum_{i=1}^m a_i v_i$ s.t. $\exists \, S \in \mathcal{S}$, s.t. $v\notin S$.  

(ii) $\Longrightarrow$ (iii) If $v_i = \sum_{j\neq i} c_j v_j$, define $a_i  = -1 \neq 0$, $a_j = c_j$, $\forall \, j \neq i$.  Then $\sum_{l=1}^m a_l v_l = -v_i + \sum_{j\neq i } c_j v_j = 0$

(iii) $\Longrightarrow$ (i) Suppose for $i \in 1 \dots m$, $a_i \neq 0$.  $v_i = -\sum_{j\neq i} \frac{a_j}{a_i} v_j$.  $\langle v_1 \dots \widehat{v}_i \dots v_m\rangle$ still spans $V$ (i.e. deleting $v_i$ gives a shorter list, which still spans).  

For instance, if $v\in \langle v_1 \dots v_m \rangle$, $v= \sum_{l=1}$%m c_l v_l = \sum_{j\neq i} c_j v_j + c_i \left( - \sum_{j\neq i} \frac{a_j}{a_i} v_j \right) = \sum_{j\neq i } \left( c_j - \frac{ c_i a_j}{a_i} \right) v_j$ so $\langle v_1\dots v_m \rangle$ wasn't shortest spanning list.





	\end{proof}

\exercisehead{3.67} Suppose $\text{dim}V >1$. Then $\exists \, $ at least 2 elements in a basis of $V$, say $e_1$, $e_2$. (Thm. 3.78 of Rotman (2010) \cite{JRotman2010}, "Every finite-dim. vector space $V$ has a basis; Def. of $\text{dim}$, "number of elements in a basis of $V$").   

Consider subspaces $\langle e_1 \rangle$, $\langle e_2 \rangle$, subspaces spanned by $e_1,e_2$, respectively. Whether $V= \langle e_1, e_2 \rangle$ or $V= \langle e_1, e_2\rangle$, $\langle e_1 \rangle , \langle e_2 \rangle \neq \lbrace 0 \rbrace$ nor $V$. Contradiction of hypothesis.  

Thus, "If only subspaces of a vector space $V$ are $\lbrace 0 \rbrace$ and $V$ itself, $\text{dim}(V) \leq 1$."



\begin{proposition}[Matrix representation of linear transformation; 3.94 of Rotman (2010) \cite{JRotman2010}]\label{Prop:MatRepofLinearTransform}
	If linear transformation $T: k^n \to k^m$, then $\exists \,  A \in \text{Mat}_k(m,n)$ s.t. 
	\[
	T(y) = Ay, \qquad \  \forall \, y \in k^n
	\]
\end{proposition}

\begin{proof}
	Let $\begin{aligned} & (e_1\dots e_n) & \text{standard basis of $k^n$ }   \\
	& (e_1' \dots e_m') & \text{standard basis of $k^m$ }  \end{aligned}$

Define $A=[a_{ij}]$, s.t. $T(e_j) = A_{*j} = A_{ij} e_i'$ ($j$th column), 

If $\begin{aligned} 
& S:k^n \to k^m \\ 
& S(y) = A(y) \end{aligned}$, then 
\[
T(e_j) = a_{ij}e_i' = Ae_j
\]
and so $\forall \, y = y_je_j \in k^n$, 
\[
T(y) = T(y_je_j) = y_j T(e_j) = y_j A_{ij}e'_i = Ay
\]


	\end{proof}

\section{Modules}

\subsection{R-modules}

cf. Sec. 7.1 Modules of Rotman (2010) \cite{JRotman2010}

\begin{definition}[$R$-module]
	$R$-module is (additive) abelian group $M$, \\
	equipped with scalar multiplication $\begin{aligned} & \quad \\
	& R \times M \to M \\
	& (r,m) \mapsto rm \end{aligned}$ 
	
	s.t. $\forall \, m,m' \in M$, $\forall \, r,r',1 \in R$
	\begin{enumerate}
		\item[(i)] $r(m+m')=rm+rm'$
		\item[(ii)] $(r+r')m = rm+r'm$
		\item[(iii)] $(rr')m = r(r'm)$
		\item[(iv)] $1m = m$
	\end{enumerate}
\end{definition}

Example 7.1 \begin{enumerate}
	\item[(i)] $\forall \, $ \emph{vector space} over field $k$ is a $k$-module.  (by inspection of the axioms for a vector space, associativity, distributivity!)
	\item[(ii)] $\forall \, $ abelian group is a $\mathbb{Z}$-module, by laws of exponents (Prop. 2.23)
	
	Indeed, for
	\[
	\begin{aligned}
	\mathbb{Z} \times M & \to M \\ 
	(r,m) & \mapsto rm \equiv m^r 
	\end{aligned}
	\]
	and so
	\[
	r(m\cdot m') \equiv (m\cdot m')^r = m^r (m')^r = rm + rm' 
	\]
	(since $M$ abelian)
	\item[(iii)] For commutative ring, scalar multiplication, defined to be given multiplication of elements of $R$
	\[
	\begin{aligned}
	R\times R & \to R \\
	(a,b) & \mapsto ab 
	\end{aligned}
	\]
	For reference, recall some of the properties of a commutative ring:
	\[
	\begin{aligned}
	& ab = ba \\ 
	& a(bc) = (ab)c \\ 
	& 1a = a \\ 
	& a(b+c) = ab + ac
	\end{aligned}
	\]
	
	$\forall \, $ ideal $I$ in $R$ is an $R$-module, \\
	for if $\begin{aligned} & \quad \\
	& i \in I \\
	& r\in R \end{aligned}$ , then $ri \in I$.
	
	$0\in I$ \\
	$\forall \, a,b \in I, \, a+b \in I$
	
	
	If $a\in I$, $r\in R$, then $ra \in I$.
	
	
	\item[(iv)]
	\item[(v)] Let linear $T:V \to V$, $V$ finite-dim. vector space over field $k$.  
	
	Recall $k[x] \equiv $ set of polynomials with coefficients in $k$.  
	
	Define $\begin{aligned} & \quad \\
	& k[x] \times V \to V \\
	& f(x)v =\left(\sum_{i=0}^m c_i x^i\right)v =\sum_{i=0}^m c_iT^i(v) \end{aligned}$ \quad \, $\forall \, f(x) = \sum_{i=0}^m c_ix^i \in k[x]$
	
	$\Longrightarrow $ denote $k[x]$-module $V^T$.  
	
	Special case: Let $A \in \text{Mat}_k(n,n)$, let linear $\begin{aligned} & \quad \\
	& T :k^n \to k^n \\
	& T(w) = Aw \end{aligned}$.  
	
	vector space $k^n$ is $k[x]$-module if we define scalar multiplication 
	\[
	\begin{aligned} & \quad \\
	& k[x] \times k^n \to k^n \\
	& f(x)w = \left( \sum_{i=0}^m c_ix^i \right)w = \sum_{i=0}^m c_i A^i w \end{aligned}
	\] 
	\quad \, $\forall \, f(x) = \sum_{i=0}^m c_ix^i \in k[x]$
	
	In $(k^n)^T$, $xw = T(w)$ \\
	In $(k^n)^A$, $xw = Ax $ \\
	$T(w) = Ax$ and so $(k^n)^T = (k^n)^A$  (EY : 20151015 because of induction?)
\end{enumerate}


\begin{definition}[R-homomorphism (or R-map)]
If ring $R$, $R$-modules $M,N$, then \\
function $f: M\to N$, \\
if $\forall \, m, m' \in M$, $\forall \, r\in R$, 
\[
\begin{gathered}
	f(m+m') = f(m) + f(m') \\ 
f(rm) = rf(m)
\end{gathered}
\]
\end{definition}

Example 7.2. of Rotman (2011) on pp. 425 \cite{JRotman2010}] 

\begin{enumerate}
	\item[(i)] If $R$ field, then $R$-modules are vector spaces and $R$-maps are linear transformations.  Isomorphisms are then nonsingular linear transformations.  
	\item[(ii)] 
	\item[(iii)]
	\item[(iv)]
	\item[(v)] Let linear $T:V \to V$, let $v_1 \dots v_n$ be basis of $V$, let $A$ be matrix of $T$ relative to this basis.  
	
	Let $e_1 \dots e_n$ be standard basis of $k^n$.  \\
	Define $\begin{aligned} & \quad \\
	& \varphi : V \to k^n \\
	& \varphi(v_i) = e_i \end{aligned}$
	
	\[
	\begin{aligned}
	& \varphi(xv_i) = \varphi(T(v_i)) = \varphi(v_j a_{ji} ) = a_{ji} \varphi(v_j) = a_{ji}e_j \\
	& x\varphi(v_i) = A\varphi(v_i) = Ae_i
	\end{aligned}
	\]
	$\Longrightarrow \varphi(xv) = x\varphi(v) \quad \, \forall \, v \in V$
	
	By induction on $\deg{f}$, $\varphi(f(x)v) = f(x) \varphi(v)$ \quad \, $\forall \, f(x) \in k[x]$ \quad \, $\forall \, v \in V$ 
	
	$\Longrightarrow \varphi$ is $k[x]$-map \\
	$\Longrightarrow \varphi$ is $k[x]$-isomorphism of $V^T$ and $(k^n)^A$.  
	
\end{enumerate}


\begin{proposition}[7.3 of Rotman (2011) \cite{JRotman2010}]\label{Prop:kxmoduleisomorphism}
	Let vector space over field $k$, $V$, let linear $T,S : V \to V$ \\
	Then $k[x]$-modules $V^T, V^S$ are $k[x]$-isomorphic iff $\exists \, $ vector space isomorphism $\varphi : V \to V$ s.t. $S = \varphi T \varphi^{-1}$.  
\end{proposition}

\begin{proof}
	If $\varphi:V^T \to V^S$is a $k[x]$-isomorphism, 
	\[
	\varphi(f(x)v) = f(x)\varphi(v) \quad \, \forall \, v \in V , \, \forall \, f(x) \in k[x]
	\]
	if $f(x)=x$, then $\varphi(xv) = x\varphi(v)$
	\[
	\begin{aligned}
	& xv = T(v) \\ 
	& x\varphi(v) = S(\varphi(v)) \\ 
	\Longrightarrow & \varphi \circ T(v) = S \circ \varphi(v) \Longrightarrow \varphi \circ T = S \circ \varphi 
	\end{aligned}
	\]
	$\varphi$ isomorphism, so $S = \varphi \circ T \circ \varphi^{-1}$
	
	Conversely, if given isomorphism $\varphi: V \to V$ s.t. $S = \varphi T \varphi^{-1}$, then $S\varphi = \varphi T$.  
	\[
	S\varphi(v) = \varphi T(v) = \varphi(xv) = x\varphi(v)
	\]
	Then by induction, $\varphi(x^nv) = x^n\varphi(v)$ (for $S^n\varphi(v) = x^n\varphi(v) = (\varphi T \varphi^{-1})^n \varphi(v) = \varphi T^n v = \varphi(x^nv)$).  \\
	By induction on $\deg{(f)}$, $\varphi(f(x)v) = f(x)\varphi(v)$.  
	
	
\end{proof}



\begin{corollary}[7.4 of Rotman (2011) \cite{JRotman2010}] 
	Let $k$ be a field, \\
	Let $A,B \in \text{Mat}_k(n,n)$.  \\
	Then $k[x]$-modules $(k^n)^A$, $(k^n)^B$ are $k[x]$-isomorphic.  
	
	(recall, $k[x]\equiv $ set of polynomials with coefficients in $k = \lbrace \sum_{i=0}^m c_ix^i | c_i \in k \rbrace$, and define scalar multiplication 
	\[
	\begin{aligned}
		& k[x] \times k^n \to k^n \\
		& f(x) w = \left( \sum_{i=0}^m c_i x^i \right) w = \sum_{i=0}^m c_iA^i w, \qquad \  \forall \, f(x) = \sum_{i=0}^m c_i x^i \in k[x] 
	\end{aligned}
	\]
	)
	
	iff $\exists \, $ nonsingular $P$ with 
	\[
	B=PAP^{-1}
	\]
	
	\end{corollary}

\begin{proof}
	Define 
	
	$\begin{aligned} & T:k^n \to k^n \\
	& T(y) = A(y) \end{aligned}$
where $y\in k^n $ is a column.  

By Example 7.1 (v) of Rotman (2011)  \cite{JRotman2010}, recall, 

and so for $k[x]$-module, $(k^n)^T = (k^n)^A$.  

Similarly, define 
\[
\begin{aligned} 
	& S: k^n \to k^n  \\
	& S(y) = B(y) 
	\end{aligned}
	\]
	Denote corresponding $k[x]$-module by $(k^n)^B$.  
	
	Given $(k^n)^A \cong (k^n)^B$ (isomorphic), by Prop. \ref{Prop:kxmoduleisomorphism}, \\
	$\exists \, $ isomorphism $\varphi :k^n \to k^n$ s.t. $B=\varphi A \varphi^{-1}$.  

By Prop. \ref{Prop:MatRepofLinearTransform}, i.e. Prop. 3.94 of Rotman (2011)  \cite{JRotman2010}, in that every linear transformation has a matrix representation (even in the standard "Euclidean" basis), $\exists \,  P \in \text{Mat}_{k}(n,n)$, s.t. 
\[
\varphi(y) = Py \qquad \  y\in k^n
\]
($P$ nonsingular because $\varphi$ isomorphism)

Thus, 
\[
\begin{aligned}
& B\varphi(y) = \varphi A(y)  \\ 
& BPy = P(Ay) \qquad \  \forall \, y \in k^n  \\
\Longrightarrow & PA = BP \text{or } B= PAP^{-1}
\end{aligned}
\]

Conversely, given $B=PAP^{-1}$, $P$ nonsingular matrix,  \\
define isomorphism 
\[
\begin{aligned}
& \varphi :k^n \to k^n \\ 
& \varphi(y) = Py \qquad \  \forall \, y \in k^n
\end{aligned}
\]

By Prop. \ref{Prop:kxmoduleisomorphism}, \\
$(k^n)^B$, $(k^n)^A$ are $k[x]$-isomorphic.  \\
i.e. $\varphi : (k^n)^A \to (k^n)^B $ is a $k[x]$-module isomorphism.  


	\end{proof}

\begin{definition}[$\text{Hom}_R(M,N)$]
\begin{equation}
\text{Hom}_R(M,N) = \lbrace \text{ all $R$-homomorphisms $M\to N$ } \rbrace = \lbrace f | f:M\to N , \text{ s.t. } \forall \, m,m' \in M, \, \forall \, r \in R, \begin{aligned} & f(m+m') =f(m) + f(m') \\ & f(rm) = rf(m) \end{aligned} \rbrace
\end{equation}
If $f,g \in \text{Hom}_R(M,N)$, \\
define
\begin{equation}
\begin{aligned}
& f+g:M \to N \\
& f+g:m\mapsto f(m) + g(m)
\end{aligned}
\end{equation}
\end{definition}

\begin{proposition}[$\text{Hom}_R(M,N)$ $R$-module, 7.5 of Rotman (2011)  \cite{JRotman2010}]
	If $M,N$ $R$-modules, where $R$ commutative ring, \\
	then $\text{Hom}_R(M,N)$ $R$-module, \\
	with addition 
	\[
	\begin{aligned}
	& f+g: M\to N \qquad \  \forall \, f,g \in \text{Hom}_R(M,N) \\
	& f+g:m\mapsto f(m) + g(m)
	\end{aligned}
	\]
and scalar multiplication 
\[
rf:m \mapsto f(rm)
\]
	Moreover, distributive laws: \\
	If $p:M'\to M$, $q:N\to N'$, then 
	\[
	(f+g)p = fp+gp \text{ and } q(f+g) = qf + qg
	\]
$\forall \, f,g \in \text{Hom}_R(M,N)$	
	
	
	
\end{proposition}

\begin{proof}
	$\forall \, f,g \in \text{Hom}_R(M,N)$, $\forall \, r,r', 1 \in R$, 
	\begin{enumerate}
		\item[(i)] 
		\[
		r(f+g)(m) = (f+g)(rm) = f(rm) + g(rm) = rf(m) + rg(m) = (rf+rg)(m) 
		\]
		\item[(ii)]
		\[
		(r+r')f(m) = f((r+r')m) = f(rm+r'm) = f(rm) + f(r'm) = (rf+ r'f)(m)
		\]
		\item[(iii)]
		\[
		(rr')f(m) = f(rr'm) = rf(r'm) = f(r'rm) = f(rr'm) \Longrightarrow (rr')f = r(r'f)
		\]
		\item[(iv)]
		\[
		1f(m) = f(1m) = f(m) \Longrightarrow 1f =f
		\]
	\end{enumerate}
	\end{proof}



\begin{definition}
	if $R$-module $M$, the submodule $N$ of $M$, denoted $N\subseteq M$, is additive subgroup $N$ of $M$, \\
	closed under scalar multiplication $rn \in N$ whenever $n\in N$, $r\in R$
\end{definition}




\begin{definition}[quotient module $M/N$] \qquad \, \\ 
\textbf{quotient module} $M/N$  -

For submodule $N$ of $R$-module $M$, then, \\
remember $M$ abelian group, $N$ subgroup, \\
quotient group $M/N$ equipped with scalar multiplication 
\[
\begin{gathered}
	r(m+N) = rm+N \\ 
M/N = \lbrace m +N | m \in M \rbrace
\end{gathered}
\]
\textbf{natural map} 
\begin{equation}
\begin{aligned}
& \pi : M \to M /N \\ 
& m\mapsto m + N 
\end{aligned}
\end{equation}
easily seen to be $R$-map.  

Scalar multiplication in quotient module well-defined: \\
If $m+N=m'+N$, $m-m' \in N$, so $r(m-m') \in N$ (because $N$ submodule), so 
\[
rm - rm' \in N \text{ and } rm+ N = rm' +N
\]


\end{definition}


\begin{proposition}[7.15 of Rotman (2010) \cite{JRotman2010}]  
\begin{enumerate}
\item[(i)] $S \bigsqcup T \simeq M$ 
\item[(ii)] $\exists \, $ injective $R$-maps $\begin{aligned} & \quad \\ 
	& i : S\to M \\ 
& j :T \to M \end{aligned}$, s.t. 

\begin{equation}
\begin{gathered} 
M = \text{im}(i) + \text{im}(j)  \text{ and } \\ 
\text{im}(i) \bigcap \text{im}(j) = \lbrace 0 \rbrace  
\end{gathered}
\end{equation}
\item[(iii)] $\exists \, $ R-maps 
\[
\begin{aligned}
	& i : S\to M \\ 
	& j : T\to M 
\end{aligned}
\]
s.t. $\forall \, m \in M$, $\exists \, !$ 
\[
\begin{aligned}
	& s \in S \\ 
	& t \in T 
\end{aligned}
\] with $m=is + jt$.  
\item[(iv)] $\exists \, $ R-maps 
\[
\begin{gathered}
\begin{aligned}  & i: S\to M \\ 
& j:T \to M \end{aligned} \qquad \, \begin{aligned}
& p : M \to S \\ 
& q : M \to T \end{aligned}
\end{gathered}
\]
s.t. 
\[
\begin{gathered}
	\begin{aligned}
	& pi = 1_S \\ 
& qj = 1_T 
\end{aligned} \qquad \ , \begin{aligned}
	& pj = 0  \\
	& qi = 0 
\end{aligned} \qquad \, ip + jq = 1_M
\end{gathered}
\]
\end{enumerate}
\end{proposition}

\begin{proof}
\begin{itemize}
\item (i)$\to$ (ii)  Given $S \bigsqcup T \simeq  M$,  \\ 
 let $\varphi : S \bigsqcup T \to   M$ be this isomorphism.  

Define
\[
\begin{aligned}
	& i:= \varphi \lambda_S \qquad \, & (\lambda_S : s\mapsto (s,0)) \qquad \, & i :S \to M \\ 
	& j:= \varphi \lambda_T \qquad \, & (\lambda_T : t\mapsto (0,t)) \qquad \, & j :T \to M 
\end{aligned}
\]
$i,j$ are injections, being composites of injections.  

If $m\in M$, $\exists \, ! \, (s,t) \in S\bigsqcup T$, s.t. $\varphi(s,t)=m$.  

Then 
\[
m = \varphi(s,t) = \varphi((s,0) + (0,t)) = \varphi\lambda_S(s)  \varphi \lambda_T(t) = is + jt \in \text{im}(i) + \text{im}(j)
\]

Let $c\in \text{im}(i) + \text{im}(j)$.  Since $\begin{aligned}  & \quad \\ 
	& i : S\to M \\
& j : T \to M \end{aligned}$, $c\in M$.  

$\Longrightarrow M = \text{im}(i) + \text{im}(j)$.  



If $x\in \text{im}(i) \bigcap \text{im}(j)$, 
\[
\begin{aligned}
	& x = i(s) \text{ for some } s\in S \\ 
		& x = j(t) \text{ for some } t\in T  
\end{aligned}
\]

\[
\begin{gathered}
	is=jt = \varphi \lambda_S(s) = \varphi \lambda_T(t) = \varphi(s,0) = \varphi(0,t) 
\end{gathered}
\]
$\varphi$ isomorphism, so $\exists \, \varphi^{-1}$ $\Longrightarrow (s,0) = (0,t)$, so $s=t=0$.  $x=0$  
\item (ii)$\to $ (iii) Given $\begin{aligned} & \quad \\ & i:S\to M \\ & j:T\to M \end{aligned}$, s.t. $M= \text{im}(i) + \text{im}(j)$, so \\

$\forall \, m \in M$, $m=i(s) + j(t)$ for some $s\in S,t\in T$.  

Suppose $\begin{aligned} & \quad \\ 
	& s' \in S \\
& t' \in T \end{aligned}$, s.t. $m=i(s'_ + j(t')$.  
\[
i(s-s') = j(t-t') \in \text{im}(i) \bigcap \text{im}(j) = \lbrace 0 \rbrace
\]
So $s=s',t=t'$, since $i,j$ injective.  
\item (iii)$\to$ (iv)   

Given $\forall \, m \in M$, $\exists \, ! \, s\in S,t\in T$ s.t. 
\[
m=i(s) + j(t)
\]
Define 
\[
\begin{aligned}
	& p:M \to S \\ 
	& p(m) := s
\end{aligned} \qquad \, \begin{aligned}
	& q: M \to T \\ 
	& q(m) := t
\end{aligned}
\]
\[
\begin{aligned}
	& pi(s) = s \\ 
	& qj(t) = t 
\end{aligned} \qquad \, \begin{aligned}
& pj(t) =0  \\
& qi(s) = 0 \end{aligned} \qquad \, 
(ip+jq)(m) = ip(m) + jq(m) = i(s) + j(t) = m 
\]
\end{itemize}
\end{proof}

\subsection{Vector Spaces as a Module}

Lang made the key insight on vector spaces as a whole in Sec 5. "Vector Spaces" in pp. 139-140 of Lang (2005) \cite{Lang2005}: 

\begin{theorem}[Existence of a basis for vector spaces, Thm. 5.1 Lang (2005) \cite{Lang2005}]\label{Thm:ExistenceOfBasisForVectorSpaces}
	Let $V$ be a vector space over a field $K$, assume $V \neq \lbrace 0 \rbrace$. 
	
	Let $\Gamma$ be a set of generators of $V$ over $K$ and let $S$ be a subset of $\Gamma$ which is linearly independent. 
	
	Then $\exists \, $ basis $\mathcal{B}$ of $V$ s.t. $S \subset \mathcal{B} \subset \Gamma$.

\end{theorem}
	
Indeed, while this wikipedia article \footnote{\url{https://en.wikipedia.org/wiki/Vector_space}} on Vector space does a good job generalizing the properties defining a vector in a vector space, a vector's properties is separate from what \emph{characterizes} a vector space. Here, we can \emph{specify} a vector space by its generators, and furthermore, from Thm. \ref{Thm:ExistenceOfBasisForVectorSpaces}, it has a basis that characterizes a vector space. This can be useful for implementation in C++.

\section{Vector Spaces}

cf. Ch. 11, "Vector Spaces" pp. 408, Dummit and Foote \cite{DuFo2003}

\begin{center}
\begin{tabular}{l | l }
\textbf{Terminology for $R$ any Ring} & \textbf{Terminology for $R$ a Field } \\
\hline
$M$ is an $R$-module & $M$ is a vector space over $R$ \\
$m$ is an element of $M$ & $m$ is a vector in $M$ \\
$\alpha$ is a ring element & $\alpha$ is a scalar \\
$N$ is a submodule of $M$ & $N$ is a subspace of $M$ \\
$M/N$ is a quotient module & $M/N$ is a quotient space \\
$M$ is a free module of rank $n$ & $M$ is a vector space of dimension $n$ \\
$M$ is a finitely generated module & $M$ is a finite dimensional vector space \\
$M$ is a nonzero cyclic module & $M$ is a 1-dimensional vector space \\
$\varphi : M \to N$ is a $R$-module homomorphism & $\varphi : M \to N$ is a linear transformation \\
$M$ and $N$ are isomorphic as $R$-modules & $M$ and $N$ are isomorphic vector spaces \\
the subset $A$ of $M$ generates $M$ & the subset $A$ of $M$ spans $M$ \\
$M = RA$ & each element of $M$ is a linear combination of elements of $A$ i.e., $M=\text{Span}(A)$
\end{tabular} 
\end{center}
cf. pp. 408, 11.1 "Definitions and Basic Theory", Dummit and Foote \cite{DuFo2003}

Vector spaces are free $F$-modules, i.e. vector spaces have bases.  \\

\emph{Examples}:

\begin{enumerate}
	\item Space $V= F[x]$ of polynomials in the variable $x$ with coefficients from field $F$ is a vector space over $F$. elements $1,x,x^2, \dots $ are linearly independent by def. (i.e. polynomial is $0$ iff all its coefficients are $0$). Since these elements also span $V$, by def., they're a basis for $V$ (basis of vector space $V$ is ordered set of linearly independent vectors which span $V$)
	\item Collection of solutions of a linear, homogeneous, constant coefficient differential equation (e.g. $y'' - 3y' + 2y = 0$) over $\mathbb{C}$ form a vector space over $\mathbb{C}$, since differentiation is a linear operator. \\
 	e.g. $e^t, e^{2t}$ are linearly independent ($ae^t + be^{2t} =0$, then so $a+b =0 \, (t=0)$, $ae + be^2 = 0 \, (t=1) \Longrightarrow a=b=0$) \\
 	By Thm. in differential eqns. that these elements span set of solutions of this eqn., hence form a basis.
\end{enumerate}

\begin{proposition}[1, Dummit and Foote \cite{DuFo2003}]
	Assume set $\mathcal{A} = \lbrace v_1, v_2 , \dots v_n \rbrace$ spans vector space $V$ but no proper subset of $\mathcal{A}$ spans $V$. Then $\mathcal{A}$ basis of $V$. In particular, any finitely generated (finitely spanned) vector space over $F$ is a free $F$-module.
\end{proposition}

\begin{proof}
\emph{Want}: $v_1, v_2, \dots v_n$ linearly independent. \\

Suppose $\sum_{i=1}^n \alpha_i v_i = 0$ s.t. not all $\alpha_i = 0$. \\

By reordering, assume $\alpha_1 \neq 0$ and then $v_1 = \frac{-1}{\alpha_1} (\alpha_2 v_2 + \dots + \alpha_n v_n)$. \\
Then $\lbrace v_2, v_3, \dots v_n \rbrace$ also spans $V$ since any linear combination of $v_1, v_2, \dots v_n$ can be written as a linear combination of $v_2, v_3, \dots v_n$ using $v_1 = \frac{-1}{\alpha_1} (\alpha_2 v_2 + \dots + \alpha_n v_n)$. Contradiction.	
	
\end{proof}


\emph{Example}. 

Let $F$ be a field, consider $F[x]/(f(x))$ where $f(x) = x^n + \sum_{j=0}^{n-1} a_j x^j$ \\
ideal $(f(x))$ is a subspace of vector space $F[x]$, quotient $F[x]/(f(x))$ is a vector space over $F$. \\

By Euclidean Algorithm, $\forall \, $ polynomial $a(x) \in F[x]$ can be written uniquely in form
\[
a(x) = q(x) f(x) + r(x)
\]
where $r(x) \in F[x]$, and $0\leq \text{deg}{r(x)} \leq n -1$ \\
Since $q(x) f(x) \in (f(x))$, it follows $\forall\, $ element of quotient is represented by polynomial $r(x)$ of degree $\leq n - 1$ \\
2 distinct such polynomials cannot be the same in the quotient since this would say their difference (which is a polynomial of degree at most $n-1$) would be divisible by $f(x)$ (which is of degree $n$), i.e. 
\[
f(x) = x^n + \sum_{j=1}^{n-1} a_j x^j
\]
$\forall \, a(x) \in F[x]$, $a(x) = q(x) f(x) + r(x)$, $q(x) f(x) \in (f(x))$ (ideal) \\

Consider $r_1(x)$, $\text{deg}(r_1(x)) = n_1 \leq n -1$, $\text{deg}(r_2(x)) = n_2 \leq n -1$. \\
If $a_1(x), a_2(x) \in F[x]$, $\begin{aligned} 
& \quad \\ 
a_1(x) & = q_1(x) f(x) + r_1(x) \\ 
a_2(x) & = q_2(x) f(x) + r_2(x) \end{aligned}$  $a_1(x) - a_2(x) = (q_1(x) - q_2(x)) f(x) + (r_1(x) - r_2(x))$.

If $r_1(x) = r_2(x)$, then $a_1(x) - a_2(x) = (q_1(x) - q_2(x)) f(x)$, so $a_1(x) - a_2(x)$ divisible by $f(x)$.

$\Longrightarrow \overline{1}, \overline{x}, \overline{x^2} , \dots \overline{x^{n-1}}$ (bar denotes image of these elements in the quotient) span $F[x]/f(x)$, as vector space over $F$. \\
No proper subset of these elements also spans, hence elements give basis for $F[x]/(f(x))$.





\section{Categories; Category Theory}  

\subsection{Categories}

cf. 7.2 Categories of Rotman (2010) \cite{JRotman2010}

\subsubsection{Russell paradox, Russell set}  

\begin{definition}[Russell set]
Russell set  - set $S$ that's not a member of itself, i.e. $S\notin R$
\end{definition}

If $R$ is family of all Russell sets,  \\
Let $X\in R$.  Then $X\notin X$.  But $X\in R$.  $X\notin R$.  \\
Let $R\notin R$.  Then $R$ in family of Russell Sets.  $R\in R$.  Contradiction.  

Then consider \emph{class} as primitive term, instead of set.  

\begin{definition}[Category]
Category $\mathcal{C}$ (Rotman's notation) $\equiv \mathbf{C}$ (my notation), consists of class $\text{obj}(\mathcal{C})$ (Rotman's notation) $\equiv \text{Obj}(\mathbf{C}) \equiv \text{Obj}\mathbf{C}$ (my notation) of objects, set of  morphisms $\text{Hom}(A,B)$ $\forall \,  (A,B)$ of ordered tuples of objects, composition 
\[
\begin{gathered} 
	\text{Hom}(A,B)\times \text{Hom}(B ,C) \to \text{Hom}(A,C) \\
(f,g)\mapsto gf \end{gathered}
\], s.t.
\begin{enumerate}
\item $\exists \, \mathbf{1}$, $\forall \, f:A\to B$, $\exists \, \begin{aligned} & \quad \\ 
1_A : A \to A \\
1_B : B \to B \end{aligned}$, s.t. $1_B \cdot f = f= f\cdot 1_A$, and 
\item associativity, $\forall \, \begin{aligned} & \quad \\
& f : A\to B \\
& g: B\to C \\
& h: C\to D \end{aligned}$, then $h\circ (g\circ f) = (h\circ g) \circ f$ 
\end{enumerate}

In summary, 
\begin{equation}
	\mathbf{C} := (\text{Obj}(\mathbf{C}), \text{Mor}\mathbf{C}, \circ, \mathbf{1}) \equiv (\text{Obj}\mathbf{C}, \text{Mor}\mathbf{C}, \circ_{\mathbf{C}}, \mathbf{1}_{\mathbf{C}})
\end{equation}
s.t. 
\[
\text{Mor}\mathbf{C} = \bigcup_{A,B \in \text{Obj}\mathbf{C}} \text{Hom}(A,B)
\]
\end{definition}

Examples (7.25 of Rotman (2010)\cite{JRotman2010}): 
\begin{enumerate}
\item[(i)] $\mathbf{C} = \mathbf{\text{Sets}}$  
\item[(ii)] $\mathbf{C} = \mathbf{\text{Groups}} = \mathbf{\text{Grps}}$ 
\item[(iii)]  $\mathbf{C} = \mathbf{\text{CommRings}}$
\item[(iv)]  $\mathbf{C} = {}_R\textbf{Mod}$, if $R=\mathbb{Z}$, ${}_{\mathbb{Z}}\textbf{Mod} = \textbf{Ab}$, i.e. $\mathbb{Z}-$modules are just abelian groups.   
\item[(v)] $\mathbf{C} =\textbf{PO}(X)$, If partially ordered set $X$, regard $X$ as category, s.t. $\textbf{Obj}, \textbf{PO}(X) = \lbrace x | x\in X\rbrace$, $\forall \, \text{Hom}(x,y) \in \textbf{Mor}_{\textbf{PO}}(X)$, $\text{Hom}(x,y) = \begin{cases} \emptyset & \text{ if } x \npreceq y \\  \kappa_y^x & \text{ if } x \preceq y   \end{cases}$ where $\kappa_y^x \equiv $ unique element in $\text{Hom}$ set when $x \preceq y$) s.t. 
\[
\kappa_z^y \kappa_y^x  =\kappa_z^x
\]
Also, notice that 
\[
1_x = \kappa_x^x
\]
\end{enumerate}

\begin{definition}[isormorphisms or equivalences]
$f:A\to B$, $f\in \text{Hom}(A,B)$, if $\exists \, $ \textbf{inverse} $g:B\to A$, $g\in \text{Hom}(B,A)$, s.t. 
\[
\begin{aligned}
& gf = 1_A \\ 
& fg = 1_B
\end{aligned}
\]
and if $\mathbf{C} = \textbf{Top}$, equivalences (isomorphisms) are homeomorphisms.  
\end{definition}

Feature of category ${}_R\textbf{Mod}$ not shared by more general categories: \emph{Homomorphisms can be added.}

\begin{definition}[pre-additive Category]
category $\mathbf{C}$
\end{definition}  




%--------------------------------------------------------------------------------
% 20180202 
%-------------------------------------------------------------------------------

We can force 2 overlapping subsets $A,B$ to be disjoint by ``disjointifying'' them: e.g. consider $(A\cup B) \times \lbrace 1,2 \rbrace$, consider $\begin{aligned} & \quad \\
& A' = A\times \lbrace 1 \rbrace \\
& B' = B\times \lbrace 2 \rbrace \end{aligned}$.

\[
\Longrightarrow A' \cap B' = \emptyset 
\]
since $(a,1) \neq (b,2)$ \, $\forall \, a \in A$, $\forall \, b \in B$.

Let bijections $\begin{aligned} & \quad \\
& \alpha : A \to A' \\
& \beta : B \to B' \end{aligned}$, \qquad \, $\begin{aligned} & \quad \\
& \alpha : a \mapsto (a,1) \\
& \beta : b\mapsto (b,2) \end{aligned}$, denote $A'\bigcup B' \equiv A \coprod B$.

From Rotman (2010) \cite{JRotman2010}, pp. 447,
\begin{definition}
	\textbf{coproduct} $A \coprod B \equiv C \in \text{Obj}(\mathcal{C})$
\end{definition}

In my notation,

\textbf{coproduct}
\begin{equation}
\begin{aligned}
& (\mu_1 , A_1 \coprod A_2 ) \\ 
& (\mu_2 , A_1 \coprod A_2 ) 
\end{aligned}
\end{equation}
where injection (morphisms)
\begin{equation}
\begin{aligned}
& \mu_1 : A_1 \to A_1 \coprod A_2 \\ 
& \mu_2 : A_1 \to A_1 \coprod A_2 
\end{aligned}
\end{equation}
s.t.
\[
\forall \, A \in \text{Obj}\mathbf{A}, \, \forall \, f_1 ,f_2 \in \text{Mor}\mathbf{A} \text{ s.t. } \begin{aligned} & \quad \\
& f_1 : A_1 \to A \\
& f_2 : A_2 \to A \end{aligned}
\]
then
\begin{equation}
\begin{gathered}
\exists \, ! [ f_i ] \equiv [f_1, f_2 ] \in \text{Mor} \mathbf{A}, \, [f_1, f_2] : A_1 \coprod A_2 \to A \text{ s.t. } \\ 
\begin{aligned}
& [f_1,f_2] \mu_1 = f_1 \\ 
& [f_1,f_2] \mu_2 = f_2 \\
\end{aligned}
\end{gathered}
\end{equation}
i.e. 
\begin{equation}
\begin{gathered}
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=5em, column sep=4em, minimum width=3em]
{
	& A  \\ 
	A_1  &  A_1 \coprod A_2   \\
	A_2 & \\
};
\path[->]
(m-2-1) edge node [above] {$f_1$} (m-1-2)
edge node [above] {$\mu_1$} (m-2-2)
(m-3-1) edge node [right] {$f_2$} (m-1-2)
edge node [below] {$\mu_2$} (m-2-2)
;
\path[dashed,->]
(m-2-2) edge node [right] {$[f_1,f_2]$} (m-1-2)
;
\end{tikzpicture}
\end{gathered}
\end{equation}

So to generalized, for $i\in I$, (finite set $I$?)

\textbf{coproduct} $(\mu_j, \coprod_{i\in I} A_i)_{j\in I}$, where \\
(family of) injection (morphisms) $\mu_j : A_j \to \coprod_{i \in I } A_i$

s.t.

\[
\forall \, A \in \text{Obj}\mathbf{A}, \, \forall \, f_i \in \text{Mor}\mathbf{A}, \, i \in I, \, f_i : A_i \to A
\]
then
\begin{equation}
\begin{gathered}
\exists \, ! \, [f_i ] \equiv [f_i]_{i\in I} \in \text{Mor}\mathbf{A} , \, [f_i] : \coprod_{i\in I} A_i \to A \text{ s.t. } \\ 
[f_i] \mu_j = f_j \qquad \, \forall \, j \in I
\end{gathered}
\end{equation}
i.e.

\begin{equation}
\begin{gathered}
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=5em, column sep=4em, minimum width=3em]
{
	& A  \\ 
	A_j  & \coprod_{i\in I} A_i   \\
};
\path[->]
(m-2-1) edge node [above] {$f_j$} (m-1-2)
edge node [above] {$\mu_j$} (m-2-2)
;
\path[dashed,->]
(m-2-2) edge node [right] {$[f_i]$} (m-1-2)
;
\end{tikzpicture} 
\end{gathered}
\end{equation}



For notation purposes only, recall that it's denoted the sets $\text{Hom}(A,B)$ in ${}_R\textbf{Mod}$ by
\[
\text{Hom}_R(A,B)
\]
i.e., in my notation, for $A,B \in \text{Obj}{ {}_R \textbf{Mod}}$, $\text{Hom}(A,B) \subset \text{Mor}( {}_R\textbf{Mod})$, $\text{Hom}(A,B) \equiv \text{Hom}_R(A,B)$

\begin{definition}[pre-additive category] 
	category $\mathbf{C}$ is \textbf{pre-additive} if $\forall \,  \text{Hom}(A,B)$, $\text{Hom}(A,B)$ equipped with binary operation $+$ s.t. $\forall \, f,g  \in \text{Hom}(A,B)$, 
	\begin{enumerate}
		\item if $p: B\to B'$, then 
		\[
		p(f+g) = pf + pg \in \text{Hom}(A,B')
		\]
		\item if $q: A'\to A$, then 
		\[
		(f+g)q = fq + gq \in \text{Hom}(A',B)
		\]
		and 
		\[
		f+g= g+f \qquad \, \text{ (additive abelian) }
		\] 
	\end{enumerate}
\end{definition}

\subsubsection{Examples of extra assumptions on sets, ${}_R\textbf{Mod}$ we take for granted}

In Prop. 7.15(iii) Rotman (2010) \cite{JRotman2010}, \\
direct sum $M=A\oplus B$ if $\exists \, $ homomorphisms $\begin{aligned} & \quad \\
& p:M\to A \\
& q:M\to B \\
& i:A\to M \\
& j:B\to M \end{aligned}$ s.t. $\begin{aligned} & \quad \\
& pi = 1_A \\
& qj = 1_B \\ 
& pj = 0 \\ & qi = 0 \end{aligned}$, 
\[
ip + jq = 1_M
\]
direct sum $M = A\oplus B$ uses property that morphisms can be added ${}_R\textbf{Mod}$ has this property. $\textbf{Sets}$ don't.  

In Corollary 7.17, \\
direct sum in terms of arrows, \\
$\exists \, $ map $\rho:M \to S$ s.t. $\rho(s)=s$.  Moreover $\text{ker}\rho = \text{im}j$, $\text{im}\rho = \text{im}i$ and $\rho(s)=s$, \, $\forall \, s \in \text{im}\rho$.  

\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=5em, column sep=4em, minimum width=3em]
{
	S & M & T \\ 
};
\path[->]
(m-1-1) edge node [above] {$i$} (m-1-2)
(m-1-3) edge node [above] {$j$} (m-1-2)
;
\end{tikzpicture} 
and $M\simeq S \coprod T$, \\
where $\begin{aligned} & \quad \\
& i: s \mapsto s \\ 
& j : t \mapsto t \end{aligned}$ (i.e. inclusions)

This makes sense in $\textbf{Sets}$, but doesn't make sense in arbitrary categories because image of morphism may fail, e.g. $\text{Mor}(\mathcal{C}(G))$ are elements in $\text{Hom}(*,*) =G$, not functions.  

Categorically, object $S$ is (equivalent to) retract of object $M$, $S,M \in \text{Obj}\mathbf{C}$, if $\exists \, $ morphisms $i,p\in \text{Mor}(\mathbf{C})$, s.t. 
\[
\begin{aligned}
& i: S\to M \\
& p:M \to S 
\end{aligned}
\]
s.t. $pi=1_S$, $(ip)^2=ip$ (for modules, define $\rho = ip$)

\begin{definition}[free products]
	\textbf{free products} are coproducts in groups
\end{definition}

Prop. 7.26, Rotman (2010) \cite{JRotman2010}
\begin{proposition}[7.26, Rotman]
	If $A,B$ are $R$-modules, \\
	then their coproducts in ${}_R\textbf{Mod}$ exists, and it's the direct sum $C= A\coprod B$.  
\end{proposition}

\begin{proof}
	Define 
	\[
	\begin{gathered}
	\begin{aligned}
	& \mu : A \to C \\
	& \mu : a \mapsto (a,c)
	\end{aligned}
	\qquad \, 
	\begin{aligned}
	& \nu : B \to C \\
	& \nu : b \mapsto (0,b)
	\end{aligned} \qquad \, \text{ (Rotman's notation) } \begin{aligned}
	& \alpha : A \to C \\
	& \beta : B\to C 
	\end{aligned}
	\end{gathered}
	\]
	Let $X$ be a module, $f:A\to X$, $g:B\to X$ homomorphisms
\end{proof}

Define 
\[
\begin{aligned}
& \theta : C \to X \\ 
& \theta: (a,b) \mapsto f(a) + g(b)
\end{aligned}
\]
\[
\begin{aligned}
& \theta \mu (a) = \theta(a,0) = f(a) \\ 
&  \theta\nu (b) = \theta(0,b)  = g(b)
\end{aligned}
\]
so diagram commutes, i.e. 

\[
\begin{gathered}
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=5em, column sep=4em, minimum width=3em]
{
	& X  & \\ 
	A  & C & B   \\
};
\path[->]
(m-2-1) edge node [above] {$f$} (m-1-2)
edge node [above] {$\mu$} (m-2-2)
(m-2-3) edge node [above] {$g$} (m-1-2)
edge node [above] {$\nu$} (m-2-2)
;
\path[dashed,->]
(m-2-2) edge node [right] {$\theta$} (m-1-2)
;
\end{tikzpicture} 
\end{gathered}
\]

If $\psi: C\to X$ makes diagram commute, 
\[
\begin{aligned}
& \psi((a,0)) = f(a) \qquad \, \forall \, a\in A \\
& \psi((0,b)) = g(b) \qquad \, \forall \, b\in B \\
\end{aligned}
\]
and since $\psi$ is a homomorphism, $\psi((a,b)) = \psi((a,0)) + \psi((0,b)) = f(a) + g(b)  = \theta((a,b))$.  $\psi = \theta$.  

Prop. 7.27, Rotman (2010) \cite{JRotman2010}
\begin{proposition}[7.27, Rotman]
	If category $\mathcal{C} = \mathbf{C}$, and if $A,B \in \text{Obj}\mathbf{C}$, then $\forall \, $ 2 coproducts of $A,B$, if they $\exists \, $, are equivalent.  
\end{proposition}
\begin{proof}
	Suppose $C,D$ coproducts of $A,B$.  Suppose coproducts $\begin{aligned} & \quad \\ 
	& \mu_A : A \to C , \qquad \, & \nu_A: A\to D \\
	& \mu_B : B \to C , \qquad \, & \nu_B : B \to D \end{aligned}$  
	\[
	\begin{gathered}
	\begin{tikzpicture}
	\matrix (m) [matrix of math nodes, row sep=5em, column sep=4em, minimum width=3em]
	{
		& D  & \\ 
		A  & C & B   \\
	};
	\path[->]
	(m-2-1) edge node [above] {$\nu_A$} (m-1-2)
	edge node [above] {$\mu_A$} (m-2-2)
	(m-2-3) edge node [above] {$\nu_B$} (m-1-2)
	edge node [above] {$\mu_B$} (m-2-2)
	;
	\path[dashed,->]
	(m-2-2) edge node [right] {$\theta$} (m-1-2)
	;
	\end{tikzpicture} 
	\end{gathered}
	\]
	Just substitute $X=D$ in diagram above.  
	
	Then substitute again: 
	\[
	\begin{gathered}
	\begin{tikzpicture}
	\matrix (m) [matrix of math nodes, row sep=5em, column sep=4em, minimum width=3em]
	{
		& C  & \\ 
		A  & D & B   \\
	};
	\path[->]
	(m-2-1) edge node [above] {$\mu_A$} (m-1-2)
	edge node [above] {$\nu_A$} (m-2-2)
	(m-2-3) edge node [above] {$\mu_B$} (m-1-2)
	edge node [above] {$\nu_B$} (m-2-2)
	;
	\path[dashed,->]
	(m-2-2) edge node [right] {$\psi$} (m-1-2)
	;
	\end{tikzpicture} 
	\end{gathered}
	\]
	Then combine the 2 diagrams: $\psi \theta = 1_C$.  Likewise by label symmetry of $C,D$, $\theta \psi = 1_D$.  
	
	Then $C,D$ are equivalent.  
\end{proof}


Exer. 7.29 on pp. 459 of Rotman (2010) \cite{JRotman2010}

\begin{definition}
	If $A,B\in \text{Obj}\mathbf{C}$, then their \textbf{product}; $A\prod B = P \in \text{Obj}\mathbf{C}$, and morphisms $\begin{aligned} & \quad \\ 
	& p : P \to A \\ 
	& q : P \to B \end{aligned}$  s.t. $\forall \, X \in \text{Obj}\mathbf{C}$, \, $\forall \, \begin{aligned} & \quad \\ 
	& f : X \to A \in \text{Mor}\mathbf{C} \\ 
	& g : X \to B \in \text{Mor}\mathbf{C} \end{aligned}$, \\
	$\exists \, ! \, \theta:X \to P$, s.t. 
	
	\[
	\begin{gathered}
	\begin{tikzpicture}
	\matrix (m) [matrix of math nodes, row sep=5em, column sep=4em, minimum width=3em]
	{
		& X  & \\ 
		A  & A \prod B & B   \\
	};
	\path[->]
	(m-1-2) edge node [above] {$f$} (m-2-1)
	edge node [above] {$g$} (m-2-3)
	(m-2-2) edge node [above] {$p$} (m-2-1)
	edge node [above] {$q$} (m-2-3)
	;
	\path[dashed,->]
	(m-1-2) edge node [right] {$\theta$} (m-2-2)
	;
	\end{tikzpicture} 
	\end{gathered}
	\]
	
	In the notation of Kashiwara and Schapira (2006) \cite{KaSch2006}, 
	\[
	\begin{gathered}
	\begin{tikzpicture}
	\matrix (m) [matrix of math nodes, row sep=5em, column sep=4em, minimum width=3em]
	{
		& Y  & \\ 
		X_0  & X_0 \prod X_1 & X_1   \\
	};
	\path[->]
	(m-1-2) edge node [above] {$f_0$} (m-2-1)
	edge node [above] {$f_1$} (m-2-3)
	(m-2-2) edge node [above] {$p_0$} (m-2-1)
	edge node [above] {$p_1$} (m-2-3)
	;
	\path[dashed,->]
	(m-1-2) edge node [right] {$[f_0f_1]$} (m-2-2)
	;
	\end{tikzpicture} 
	\end{gathered}
	\]
	In general
	\[
	\begin{gathered}
	\begin{tikzpicture}
	\matrix (m) [matrix of math nodes, row sep=5em, column sep=4em, minimum width=3em]
	{
		& Y  \\ 
		X_j  & \prod_{i\in I} X_i   \\
	};
	\path[->]
	(m-1-2) edge node [above] {$f_j$} (m-2-1)
	(m-2-2) edge node [below] {$p_i$} (m-2-1)
	;
	\path[dashed,->]
	(m-1-2)        edge node [right] {$[f_i]_{i\in I}$} (m-2-2)
	;
	\end{tikzpicture}  
	\end{gathered}
	\]
	
	\textbf{product} of $X_i$'s, 
	\[ 
	\prod_i X_i \equiv \prod_{i\in I} X_i
	\]
	given by 
	\begin{equation}
	\prod_i X_i := \lim_{ \longleftarrow } \alpha 
	\end{equation}
	
	When $X_i = X$, $\forall \, i \in I$, denote product by $X^{ \prod I} \equiv X^I$.  	
\end{definition}

e.g. Cartesian product $P= A\times B$ of 2 sets $A,B$, $A,B \in \text{Obj}\textbf{Sets}$.  

Define 	
\[
\begin{gathered}
\begin{aligned}
& p:A\times B \to A \\
& p(a,b) \mapsto a 
\end{aligned} \qquad \, 
\begin{aligned}
& q:A\times B \to B \\
& q(a,b) \mapsto b 
\end{aligned}
\end{gathered}
\]
If $X \in \text{Obj}\textbf{Sets}$,  \\
if 
$	\begin{aligned} & \quad \\ 
& f: X \to A \\
& g : X  \to B 
\end{aligned}
$, then $\begin{aligned} & \quad \\ 
& \theta: X \to A\times B \\
& \theta : x \mapsto (f(x),g(x)) \in A\times B
\end{aligned}
$

\begin{proposition}[7.28 Rotman (2010); equivalence of products, if it exists]
	If $A,B \in \text{Obj}\mathbf{C}$, then $\forall \, $ 2 products of $A$ and $B$, should they exist, are equivalent. 
\end{proposition}

\begin{proof}
	Suppose $C,D$ products of $A,B$.  Suppose products $\begin{aligned} & \quad \\ 
	& p_A : C \to A , \qquad \, & q_A: D\to A \\
	& p_B : C \to B , \qquad \, & q_B : D \to B \end{aligned}$  
	\[
	\begin{gathered}
	\begin{tikzpicture}
	\matrix (m) [matrix of math nodes, row sep=5em, column sep=4em, minimum width=3em]
	{
		& D  & \\ 
		A  & C & B   \\
	};
	\path[->]
	(m-1-2) edge node [above] {$q_A$} (m-2-1)
	edge node [above] {$q_B$} (m-2-3)
	(m-2-2) edge node [above] {$p_A$} (m-2-1)
	edge node [above] {$p_B$} (m-2-3)
	;
	\path[dashed,->]
	(m-1-2) edge node [right] {$\theta$} (m-2-2)
	;
	\end{tikzpicture} 
	\end{gathered}
	\]
	Just substitute $X=D$ in diagram above.  
	
	Then substitute again: 
	\[
	\begin{gathered}
	\begin{tikzpicture}
	\matrix (m) [matrix of math nodes, row sep=5em, column sep=4em, minimum width=3em]
	{
		& C  & \\ 
		A  & D & B   \\
	};
	\path[-{>[scale=3.0]}]
	(m-1-2) edge node [above] {$p_A$} (m-2-1)
	edge node [above] {$p_B$} (m-2-3) 
	(m-2-2) edge node [above] {$q_A$} (m-2-1)
	edge node [above] {$q_B$} (m-2-3)
	;
	\path[dashed,->]
	(m-1-2) edge node [right] {$\psi$} (m-2-2)
	;
	\end{tikzpicture} 
	\end{gathered}
	\]
	Then combine the 2 diagrams: $\psi \theta = 1_C$.  Likewise by label symmetry of $C,D$, $\theta \psi = 1_D$.  
	
	Then $C,D$ are equivalent.  
	
	
\end{proof}

\subsubsection{Products of Modules and Sets}  

\begin{proposition}[7.29 Rotman (2010); products of R-modules are equivalent]
	If commutative ring $R$, \\
	R-modules $A,B$, \\
	then $\exists \, $ their (categorical) product $A\sqcup B$, in fact 
	\begin{equation}
	A \sqcap B \cong A\sqcup B
	\end{equation}
	
\end{proposition}

\begin{proof}
	If $A\sqcup B \cong M$, then 
	$\exists \, $ R-maps, $\begin{aligned} & \quad \\
	& i : S\to M \\ 
	& j : T \to M \end{aligned}$, \qquad \,  $\begin{aligned} & \quad \\
	& p : M\to S \\ 
	& q : M \to T \end{aligned}$
	s.t. $\begin{aligned} & \quad \\
	& pi = 1_A \\ 
	& qj = 1_B \end{aligned}$ \qquad \, and $\begin{aligned} & \quad \\
	& pj = 0 \\ 
	& qi = 0 \end{aligned}$, and $ip + jq = 1_M$, i.e.   
	
	\begin{tikzpicture}
	\matrix (m) [matrix of math nodes, row sep=5em, column sep=4em, minimum width=3em]
	{
		A & M & B \\ 
	};
	\path[->]
	($(m-1-2)+(0,-0.1)$) edge node [below] {$p$} ($(m-1-1.east)+(0,-0.1)$)
	edge node [below] {$q$} ($(m-1-3.west)+(0,-0.1)$) 
	($(m-1-1)+(0,0.1)$) edge node [above] {$i$} ($(m-1-2.west)+(0,0.1)$)
	($(m-1-3)+(0,0.1)$) edge node [above] {$j$} ($(m-1-2.east)+(0,0.1)$)
	;
	\end{tikzpicture} 
	
	If module $X$, since $\begin{aligned}
	& \quad \\ 
	& f: X \to A \\
	& g:X\to B
	\end{aligned}	$ 
	are homomorphisms, 
	
	define 
	$\begin{aligned}
	& \theta: X \to A \sqcup B \\
	& \theta(x) = if(x) + jg(x)
	\end{aligned}
	$
	so that 
	\[
	\begin{tikzpicture}
	\matrix (m) [matrix of math nodes, row sep=5em, column sep=4em, minimum width=3em]
	{
		& X  & \\ 
		A  & A\sqcup  & B   \\
	};
	\path[-{>[scale=4.0]}]
	(m-1-2) edge node [above] {$f$} (m-2-1)
	edge node [above] {$g$} (m-2-3) 
	(m-2-2) edge node [above] {$p$} (m-2-1)
	edge node [above] {$q$} (m-2-3)
	;
	\path[dashed,->]
	(m-1-2) edge node [right] {$\theta$} (m-2-2)
	;
	\end{tikzpicture} 
	\]
	since, $\forall \, x \in X$, 
	\[
	p\theta(x) = pif(x) + pjg(x) = pif(x) + 0 = f(x)
	\]
	since $ip + jq=1_{A\sqcup B}$  
	
	\[
	\psi = ip\psi + jq \psi = i f + jf = \theta
	\]
	so product is unique.  
\end{proof}

\begin{definition}
	Let $R$ be commutative ring, \\
	let $\lbrace A_i : i \in I \rbrace$ be indexed family of $R$-modules.  
	
	\textbf{direct product} $\prod_{i\in I} A_i$ is cartesian product (i.e. set of all $I$-tuples $(a_i)$ whose $i$th coordinate $a_i$ lies in $A_i \quad \, \forall \, i$) with coordinate wise addition and scalar multiplication: 
	\[
	\begin{gathered}
	(a_i) + (b_i) = (a_i + b_i) \\
	r(a_i) = (ra_i)
	\end{gathered}
	\]
	where $r\in R$, $a_i, b_i \in A_i$, \, $\forall \, i $  
\end{definition}




cf. Thm. 7.32 of Rotman (2010) \cite{JRotman2010}
\begin{theorem}[7.32, Rotman]
	Let commutative ring $R$.  \\
	$\forall \, R$-module $A$, $\forall \,$ family $\lbrace B_i | i \in I \rbrace$ of $R$-modules,
	\begin{equation}
	\begin{gathered}
	\text{Hom}_R(A, \coprod_{i\in I} B_i ) \simeq \coprod_{i \in I} \text{Hom}_R(A,B_i)
	\end{gathered}
	\end{equation}
	via $R$-isomorphism
	\[
	\varphi : f\mapsto (p_if)
	\]
	where $p_i $ are projections of product $\coprod_{i\in I }B_i$
\end{theorem}

\begin{proof}
	Let $a\in A$, $f,g \in \text{Hom}_R(A,\coprod_{i\in I} B_i)$.
	\[
	\varphi(f+g)(a) = (p_i(f+g))(a) = (p_i(f(a) + g(a))) = (p_if + p_ig)(a)
	\]
	$\varphi$ additive.
	
	$\forall \, i, \, \forall \, r \in R$, $p_i rf = rp_i f$ (since product of $R$-modules, $\coprod_{i\in I}B_i$ is also an $R$-module of $\text{Obj}{}_R\textbf{Mod}$, by def. of product).
	\[
	\varphi rf \mapsto (p_i rf) = (r p_i f) = r(p_i f) = r\varphi(f)
	\]
	So $\varphi$ is $R$-map.
	
	If $(f_i) \in \coprod_i \text{Hom}{}_R(A,B_i)$, then $f_i : A\to B_i$ \, $\forall \, i$
	
	By Rotman's Prop. 7.31 (If family of $R$-modules $\lbrace A_i | i \in I \rbrace$, then direct product $C = \coprod_{i\in I} A_i$ is their product in ${}_R \textbf{Mod}$), \\
	\phantom{ \qquad \, } By def. or product, $\exists \, ! \, R$-map , \, $\theta : A \to \coprod_{i\in I} B_i$ s.t. $p_i \theta = f_i$ \, $\forall \, i$
	
	\[
	\begin{gathered}
	\begin{tikzpicture}
	\matrix (m) [matrix of math nodes, row sep=5em, column sep=4em, minimum width=3em]
	{
		& A  \\ 
		B_i  & \prod_{i\in I} B_i   \\
	};
	\path[->]
	(m-1-2) edge node [above] {$f_i$} (m-2-1)
	(m-2-2) edge node [below] {$p_i$} (m-2-1)
	;
	\path[dashed,->]
	(m-1-2)        edge node [right] {$\theta$} (m-2-2)
	;
	\end{tikzpicture}  
	\end{gathered}
	\]
	
	
	
	
	Then 
	\[
	f_i = (p_i\theta) = \varphi(\theta)
	\]
	, and so $\varphi$ \emph{surjective}.
	
	Suppose $f\in \text{ker}\varphi$, so $\theta = \varphi(f) = (p_if)$.  Thus $p_i f=0$ \, $\forall \, i$
	
	\[
	\begin{gathered}
	\begin{tikzpicture}
	\matrix (m) [matrix of math nodes, row sep=5em, column sep=4em, minimum width=3em]
	{
		& A  \\ 
		B_i  & \prod_{i\in I} B_i   \\
	};
	\path[->]
	(m-1-2) edge node [above] {$0$} (m-2-1)
	edge node [right] {$f$} (m-2-2)
	(m-2-2) edge node [below] {$p_i$} (m-2-1)
	;
	\end{tikzpicture}  
	\end{gathered}
	\]
	
	But $0$-homomorphism also makes this diagram commute, so uniqueness of homomorphism $A \to \prod B_i$ gives $f=0$.  
	
	
	
	
\end{proof}



%--------------------------------------------------------------------------------
% END of 20180202 
%-------------------------------------------------------------------------------

\section{Applications of Category Theory: Finite State Machines (FSM)}

\begin{definition}[Finite State Machines $\equiv$ Finite State Automaton]
	A deterministic finite state machine or acceptor deterministic finite state machine is a quintuple ($\Sigma, S, s_0, \delta F$) where \\
	$\Sigma \equiv $ input alphabet (finite, non-empty set of symbols) \\
 	$S \equiv $ finite, non-empty set of states \\
 	$s_0 \equiv $ initial state, $s_0 \in S$ \\
 	$\delta \equiv $ state-transition function; $\delta : S \times \Sigma \to S$ (in a nondeterministic finite automaton, it would be $\delta : S \times \Sigma \to \mathcal{P}(S)$), i.e. $\delta$ would return a set of states; $\mathcal{P}(S) \equiv $ set of all subsets of $S$, including $\emptyset$ and $S \equiv$ power set. \\
 	$F \equiv $ set of final states, (possibly empty subset of $S$; $F\subseteq S$ or $F \subseteq S \cup \lbrace \emptyset \rbrace$)

	Finite State Machine (FSM) is also known as a Finite State Automaton.
\end{definition}
cf. \href{https://xlinux.nist.gov/dads/HTML/finiteStateMachine.html}{Black, Paul E (12 May 2008). "Finite State Machine". \emph{Dictionary of Algorithms and Data Structres}}. U.S. National Institute of Standards and Technology (NIST).

For both deterministic and non-deterministic FSMs, it's conventional to allow $\delta$ to be a partial function, i.e. 
$\delta(q,x)$ doesn't have to be defined for every combination of $q \in S$, $x \in \Sigma$

If FSM $M$ is in state $q$; the next symbol (input?) is $x$ and $\delta(q,x)$ not defined; then $M$ can announce an error (i.e. reject the input (???)). 


\begin{definition}[Alphabet]
	alphabet $:= $ nonempty set of symbols $\equiv \Sigma$ \\
	string $:=$ finite sequence of members (i.e. symbols) of an underlying base set (i.e. \textbf{alphabet}) \\
	$\Sigma^n \equiv $ set of all strings of length $n$.
\end{definition}

In Curino and Spivak (2011)\cite{SpCu2011}, on pp. 6, Sec. 4.2 "A new concept of state transformations", they say that "Legend has it that Eilenberg and MacLane spent the effort to invent category theory because they needed to formalize the concept now known as natural transformation." 

It goes and says "The definition of natural transformations between states naturally captures much of the semantics for what remains unchanged when performing an update."



\part{Category Theory}

\section{Note on notation}

From the section on ``Terminology'' of the Preface of Barr and Wells (1998) \cite{BW1998}:

\begin{quote}
	``In most scientific disciplines, notation and terminology are standardized, of- ten by an international nomenclature committee. (Would you recognize Einstein’s equation if it said $p = HU^2$?) We must warn the nonmathematician reader that such is not the case in mathematics. There is no standardization body and terminology and notation are individual and often idiosyncratic.''
\end{quote}

To try to bridge the difference choice of notation and through comparison, suggest the ``best'' notation that's easy to remember and easy to use, I'll present all the different types of notation that I come across as much as I can. My plan of attack is the following:
\begin{enumerate}
	\item I'll try to present different types of notation and reference the authors of the text when I can.
	\item I'll try to defer to the notation used in Wikipedia, first.
	\item I'll make a final decision of what notation works best (for me).
\end{enumerate}

\section{Category $\mathbf{A}$, (definition)}

\begin{definition}[Category $\mathbf{A}$]
\textbf{category} $\mathbf{A}$ is quadruple $\mathbf{A} = (\text{Obj}(\mathbf{A}), \text{Mor}\mathbf{A}, 1,\circ)$ 
\begin{equation}
\mathbf{A} = (\text{Obj}(\mathbf{A}), \text{Mor}\mathbf{A}, 1,\circ)
\end{equation}
s.t.
\begin{enumerate}
	\item $\text{Obj}{(\mathbf{A})}$ is a \emph{class}, whose elements, $A \in \text{Obj}(\mathbf{A})$, are called \emph{objects}
	\item $\text{Mor}\mathbf{A}$ is a \emph{class}.
	\begin{enumerate}
		\item From Ad\'{a}mek, Herrlich, and Strecker (2004) \cite{AHS2004}, Kashiwara and Schapira (2006) \cite{KaSch2006}, \\
		$\forall \, A, B \in \text{Obj}(\mathbf{A})$, $\exists \, \text{Hom}(A,B) \subseteq \text{Mor}(\mathbf{A})$. Therefore, 
		\begin{equation}
		\text{Mor}\mathbf{A} = \bigcup_{ A,B \in \text{Obj}(\mathbf{A}) } \text{Hom}(A,B)
		\end{equation}
		\item $\forall \, f \in \text{Hom}(A,B)$, $f: A \to B \in \text{Hom}(A,B)$ is a \emph{morphism}. Leinster (2014) \cite{Lein2014} also calls them on pp. 10 \textbf{maps} or \textbf{arrow} from $A$ to $B$.
	\[
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=3em, column sep=4em, minimum width=2em]
{
	A & B  \\
};
\path[->]
(m-1-1) edge node [above] {$f$} (m-1-2)
;
\end{tikzpicture}
\]
	\end{enumerate}
	\item $\forall \, A \in \text{Obj}(\mathbf{A})$, $\exists \, 1_A : A \to A$, i.e. $\exists \, \mathbf{1}_A \in \text{Hom}_{\mathbf{A}}(A,A) \equiv \text{Hom}(A,A)$, 
	\[
	\begin{tikzpicture}
	\matrix (m) [matrix of math nodes, row sep=3em, column sep=4em, minimum width=2em]
	{
		A & A  \\
	};
	\path[->]
	(m-1-1) edge node [above] {$1_A$} (m-1-2)
	;
	\end{tikzpicture} \text{ or } \begin{tikzpicture}
	\matrix (m) [matrix of math nodes, row sep=3em, column sep=4em, minimum width=2em]
	{
		A   \\
	};
	\path[->]
	(m-1-1) edge [loop left] node [above] {$\mathbf{1}_A$} (m-1-1)
	;
	\end{tikzpicture}
	\]
	\item \textbf{composition:} 
	$\forall \, A,B,C \in \text{Obj}\mathbf{A}$, define \textbf{composition} to be a map
	\begin{equation}
	\begin{aligned}
		\text{Hom}_{\mathbf{A}}(A, B) \times \text{Hom}_{\mathbf{A}}(B, C) & \to \text{Hom}_{\mathbf{A}}(A, C) \\
		 (f, g) & \mapsto g\circ f
 	\end{aligned}
\end{equation}, i.e.
	
	$\forall \, \begin{aligned} & \quad \\
	& f: A \to B \in \text{Hom}(A,B) \\
	& g:B\to C \in \text{Hom}(B,C) \end{aligned}$, i.e. $f,g \in \text{Mor}\mathbf{A}$, \\
	then $g\circ f : A \to C \in \text{Hom}(A,C)$, $g\circ f \in \text{Mor}\mathbf{A}$ i.e. 
	\[
	\begin{tikzpicture}
	\matrix (m) [matrix of math nodes, row sep=3em, column sep=4em, minimum width=2em]
	{
		A & B & C  \\
	};
	\path[->]
	(m-1-1) edge node [above] {$f$} (m-1-2)
	(m-1-2) edge node [above] {$g$} (m-1-3)
	(m-1-1) edge [bend right=30] node [below] {$g\circ f$} (m-1-3) 
	;
	\end{tikzpicture}
	\]
	s.t. 
	\begin{enumerate}
		\item \emph{associativity} $\forall \, \begin{aligned} & \quad \\
		& f: A \to B \\
		& g: B \to C \\
		& h: C \to D \end{aligned}$, $h\circ (g\circ f) = (h\circ g) \circ f $ i.e.
		
		\[
		\begin{tikzpicture}
		\matrix (m) [matrix of math nodes, row sep=3em, column sep=4em, minimum width=2em]
		{
			A & B & C  & D \\
		};
		\path[->]
		(m-1-1) edge node [above] {$f$} (m-1-2)
		(m-1-2) edge node [above] {$g$} (m-1-3)
		(m-1-3) edge node [above] {$h$} (m-1-4)
		(m-1-1) edge [bend right=30] node [below] {$g\circ f$} (m-1-3) 
		(m-1-2) edge [bend left=30] node [above] {$h\circ g$} (m-1-4) 
		;
		\path[-{>[scale=1.15]}, line width=0.5pt]
		(m-1-1) edge [bend left=45] node [above] {$(h \circ g)\circ f$} (m-1-4)
		edge [bend right=45] node [below] {$h \circ (g\circ f)$} (m-1-4);
		\end{tikzpicture}
		\]
		
		\item $\forall \, f:A \to B \in \text{Hom}(A,B)$, $1_B \circ f = f $ and $f\circ 1_A = f$ i.e.
		
		$\forall \, f \in \text{Hom}_{\mathbf{A}}(A,B)$,
		\[
		\begin{tikzpicture}
		\matrix (m) [matrix of math nodes, row sep=3em, column sep=4em, minimum width=2em]
		{
			A & B  \\
		};
		\path[->]
		(m-1-1) edge node [above] {$f$} (m-1-2)
		edge [loop left] node [left] {$1_A$} (m-1-1)
		(m-1-2) edge [loop right] node [right] {$1_B$} (m-1-2)
		;
		\end{tikzpicture}
		\]
		\item Ad\'{a}mek, Herrlich, and Strecker (2004) \cite{AHS2004} posited further that $\text{Hom}(A,B) \in \text{Mor}\mathbf{A}$ pairwise disjoint (i.e. $\text{Hom}(A,B) \bigcap \text{Hom}(C,D) \neq \emptyset$ if $C\neq A$ or $D\neq B$)
	\end{enumerate}
\end{enumerate}	
\end{definition}

\subsection{Examples of categories}

\begin{itemize}
	\item $\textbf{Set} = (\text{Obj}{(\textbf{Set})}, \text{Hom}{\textbf{Set}},\mathbf{1},\circ)$ where \\
	$\text{Obj}{(\textbf{Set})}$ is the class of all sets \\
	$\text{Hom}{\textbf{Set}}$ is the class of all functions on a set to another set
	\item $\textbf{Vec}$
	
	\[
	\begin{aligned}
	& \text{Obj}\textbf{Vec} & \equiv \text{ all real vector spaces } \\ 
	& \text{Mor}\textbf{Vec} & \equiv \text{ all linear transformations between them (between real vector spaces) }
	\end{aligned}
	\]
	\item \emph{preorder} cf. Ch. 1, Example 7, pp. 8, Awodey (2010) \cite{Awod2010}. \\
	\emph{preorder} $P$, set $P$ equipped with binary relation $p\leq q $, that's both \\
	reflexive: $a\leq a$, and \\
	transitive: if $a \leq b$ and $b \leq c$, then $a\leq c$. 
	
	\quad \\
	$\forall \, $ preorder $P$ can be regarded as a category: \\
	$\text{Obj}(P) = P$ \\
	$a \to b$ iff $a\leq b \in \text{Mor}P$. \\
	identity: $1 :a \to a$ since $a\leq a$ \\
	composition: $f:a\to b$, $g:b\to c$, $(g\circ f)a = g(b) = c$, $a\leq b$ and $b\leq c$, so $a\leq c$. 
	
	Going in the other direction, a category with at most 1 arrow between 2 objects determines a preorder.
	\item \textbf{Monoid}.  Consider a monoid as a triple $(M, \cdot, e)$.  \\
	Every semigroup $(M,\cdot)$ (recall that a \emph{semigroup} is a set $S$ with binary operation $\cdot $, i.e. s.t.
	
	\quad \,  $\begin{aligned} & \quad \\
	& S\times S \xrightarrow{\cdot } S \\ 
	& \forall \, a,b ,c \in S, \, (a\cdot b)\cdot c = a\cdot (b\cdot c) \quad \, \text{ (associativity) } \end{aligned}$ 
	
	\quad \, (but no inverse, necessarily!)) that also has a unit $e$ can be made into a category $\mathbf{C}$ 
	
	$\Longrightarrow \mathbf{C}(M,\cdot ,e) = (\text{Obj}(\mathbf{C}), \text{Hom}(\mathbf{C}), \mathbf{1}, \circ)$, a category $\mathbf{C}$ with only 1 object, i.e. $\text{Obj}(\mathbf{C}) = \lbrace M \rbrace$, so that \\
	$\text{Obj}(\mathbf{C}) = \lbrace M \rbrace$ \\
	$\text{Hom}(M,M) = M$ \\
	$\mathbf{1}_M = e$ \\
	$y \circ x = y \cdot x$
	
	cf. pp. 10, Example 12 of Awodey (2010) \cite{Awod2010}.

\subsubsection{Monoid as a category}

Recall the definition of a \emph{category} $\mathbf{A}$: category $\mathbf{A} = (\text{Obj}(\mathbf{A}), \text{Mor}{\mathbf{A}}, 1, \circ)$ s.t.\\
$A \in \text{Obj}\mathbf{A}$, \\
$\forall \, A, B \in \text{Obj}\mathbf{A}$, $\exists \, \text{Hom}(A,B) \subseteq \text{Mor}\mathbf{A}$, \\
$\forall \, f \in \text{Hom}(A,B)$, $f:A \to B$ is a morphism.\\
$\forall \, A \in \text{Obj}\mathbf{A}$, $\exists \, 1_A : A \to A$, i.e. $\exists \, 1_A \in \text{Hom}_{\mathbf{A}}(A,A)$. \\
$\forall \, A, B, C \in \text{Obj}\mathbf{A}$,  \\
\[
\begin{aligned} 
	& \text{Hom}_{\mathbf{A}}(A, B) \times \text{Hom}_{\mathbf{A}}(B,C) \to \text{Hom}_{\mathbf{A}}(A, C) \\ 
	& (f,g) \mapsto g\circ f \end{aligned} \] \\

Recall the definition of a \emph{monoid}:
monoid $(M, \cdot, e)$, set $M$, \\
$\cdot : M\times M \to M$, \\
$e \in M$ s.t. $\forall \, x \in M$, $e\cdot x = x \cdot e = x$ \\

$\Longrightarrow \mathbf{C}(M)$ (monoid as a category) \\
$\text{Obj}\mathbf{C}(M) = \lbrace M \rbrace$ \\
$\text{Hom}(M, M) = \text{Mor}\mathbf{C}(M)$ and $\forall \, f \in \text{Hom}(M, M)$, 
\[
f = m \in M
\]
i.e. the morphism \emph{is} an element in monoid $M$ (there's a 1-to-1 correspondence).

$\forall \, n \in M$, $f:n \mapsto m\cdot n \in M$. \\
$1_M : M \to M$ \\
$1_M : x \mapsto e\cdot x = x$ \\
$m\cdot n \cdot x = m\cdot (n\cdot x) = (m\cdot n) \cdot x$ (composition)


	
\subsubsection{Examples of monoids}
	Examples of monoids: $\mathbb{N}, \mathbb{Q}, \mathbb{R}$ under either addition and $e=0$, or multiplication and $e=1$. \\
	$\forall \, $ set $X$, set of functions from $X$ to $X$, $\text{Hom}_{\mathbf{Sets}}(X, X)$ is a monoid under composition. 
	
	In general, \\
	$\forall \, $ object $C \in \text{Obj}(\mathbf{C})$, $\forall \, $ category $\mathbf{C}$, $\text{Hom}_{\mathbf{C}}(C,C)$ is a monoid under composition of $\mathbf{C}$. 
	
	Since monoids are structured sets, $\exists \, $ category $\textbf{Mon}$, s.t. $\text{Obj}\mathbf{Mon} \ni $ monoids, $\text{Mor} \textbf{Mon} \ni $ functions that preserve monoid structure.
	
	In detail, homomorphism from monoid $M$ to monoid $N$ is function $h:M \to N$ s.t. $\forall \, m,n \in M$. 
	
	\[
	h(m \cdot_M n) = h(m) \cdot_N h(n)
	\]
	and
	\[
	h(e_M) =  e_N
	\]
	
	\quad \\ 
	Check: Consider functor $F: M \to N$. \\
	$F: \text{Hom}_M(a,b) \to \text{Hom}_N(F(a), F(b))$
	\[
	\begin{gathered}
	m\cdot a =b \qquad \, n \cdot_N F(a)  = F(b) \\
	F(m) \cdot_N F(a) = F(b) = F(m \cdot_M a) 
	\end{gathered}
	\]
	so functor $F$ is a monoid homomorphism, and so \\
	\emph{a monoid homomorphism from $M$ to $N$ is the same thing as a functor from $M$ regarded as a category to $N$ regarded as a category.}
	\item \textbf{Poset} cf. Ch. 1, pp. 6, Awodey (2010) \cite{Awod2010}. partially ordered set or poset is a set $A$, equipped with binary relation $a \leq_A b$ s.t. $\forall \, a, b, c \in A$, \\
	reflexivity: $a \leq_A a$ \\
	transitivity: if $a\leq_A b$, $b\leq_A c$, then $a\leq_A  c$ \\
	antisymmetry: if $a\leq_A b$, $b\leq_A a$, then $a=b$.
	
	An arrow from a poset $A$ to a poset $B$ is a function,
	\[
	m : A \to B
	\]
that is monotone, i.e. $\forall \, a, a' \in A$, 
\[
\text{ if } a \leq_A a', \text{ then } m(a) \leq_B m(a')
\]	
category $\textbf{Pos}$ of posets, and monotone functions, 
\[
\forall \, A \in \text{Obj}(\textbf{Pos}), \, \exists \, 1_A : A \to A, \text{ since } 
\]
since if $a \leq_A a'$, then $a\leq_A a'$, so $1_A$ monotone.

\quad \\ 
\emph{composition}: $\forall \, f:A \to B, \, g:B \to C$, \, $\forall \, A,B,C \in \text{Obj}(\textbf{Pos})$, $f,g$ monotone, \\
$\forall \, a \leq_A a'$, $f(a) \leq_B f(a')$, and since \\
$\forall \, b \leq_B b'$, $g(b) \leq_C g(b')$, then $g(f(a)) \leq_C g(f(a'))$, or $(g\circ f)(a) \leq_C (g\circ f)(a') \, \forall \, a\leq_A a'$, so $g\circ f : A \to C$ is monotone.

$\text{Mor}\textbf{Pos} = \bigcup_{A, B \in \text{Obj}(\textbf{Pos}) } \text{ monotone functions $A \to B$ }$  

\quad \\ 
A \emph{poset} is a \emph{preorder}, satisfying additional condition of antisymmetry:
if $a\leq b$, and $b\leq a$, $a=b$. \\
e.g. $\forall \, X$, power set $P(X)$ is a poset under inclusion $U\subseteq V$, $\forall \, $ subsets $U,V \subseteq X$.

\begin{itemize}
	\item cf. Ch. 1, Example 8, pp. 9, Awodey (2010) \cite{Awod2010}.
	$\textbf{Pos}$ categories and functors: functor $F: \mathbf{D} \to \mathbf{Q}$ between poset categories $\mathbf{P}, \mathbf{Q}$. \\
	They are the monotone functions.
	\begin{proof} 
	Consider 
	\[
	F : \text{Hom}_{\mathbf{P}}(A,B) \to \text{Hom}_{\mathbf{Q}}(F(A), F(B))
	\]
	$f\in \text{Hom}_{\mathbf{P}}(A,B)$ so if $a\leq_A a'$, $f(a) \leq_B f(a')$
	
	Let $g\in \text{Hom}_{\mathbf{Q}}(F(A), F(B))$, so if $c\leq_{F(A)} c'$, $g(c)\leq_{F(B)} g(c')$. \\
	
	$F(f) \in \text{Hom}_{\mathbf{Q}}(F(A), F(B))$ (by definition of a functor), so if $c\leq_{F(A)} c'$, $F(f)(c) \leq_{F(B)} F(f)(c')$ or $F(f(c)) \leq_{F(B)} F(f(c'))$. \\
	
	So $F$ itself is monotone.
	\end{proof}
\end{itemize}
\item cf. \emph{An example from computer science}, Example 10, pp. 9 of Awodey (2010) \cite{Awod2010}.
Given a functional programming language $L$, $\exists \, $ associated category, \\
$\text{Obj}\mathbf{L} \ni $ data types of $L$ \\
$\text{Mor}\mathbf{L} \ni $ computable functions of $L$ ("processes", "procedures", "programs") \\
composition (of 2 such programs) $X \xrightarrow{f} Y \xrightarrow{g} Z$ given by applying $g$ to output of $f$ \\
(notation note: $g\circ f = f; g$) \\
identity is the "do nothing" program. 

\quad \\
if $\mathbf{C}(L)$ is the category just defined, then \\
denotational semantics of language $L$ in category $\mathbf{D}$ of say Scott demands is simply functor
\[
S:\mathbf{C}(L) \to \mathbf{D} 
\]
since $S$ assigns domains to the types of $L$, \\
continuous functions to programs.

This example and Example 9, pp. 9, of Awodey (2010) \cite{Awod2010} are related to the notion of "Cartesian closed category."

From Barr and Wells (2012) \cite{BaWe2012}, a \emph{functional programming language} $L$ has
\begin{enumerate}
	\item primitive data types (built into the language) 
	\item constants of each type
	\item operations, which are functions between types
	\item constructors, which are applied to data types and operations, to produce derived data types and operations of the language.	
\end{enumerate}

	For a $\mathbf{C}(L)$ category corresponding to functional programming language $L$, \\
	
	$\mathbf{C}(L)$ category corresponding to functional programming language $L$, \\
	$\text{Obj}\mathbf{C}(L) = \lbrace \text{ types of $L$ } \rbrace$ \\
	$\text{Mor}\mathbf{C}(L) = \lbrace \text{ operations (functions; primitive and derived) of $L$ } \rbrace$ \\

identity: $\forall \, $ type $T \in \text{Obj}\mathbf{C}(L)$, $\exists \, 1_T :T \to T$ i.e. $1_T \in \text{Hom}(T,T)$. \\

composition: $\forall \, $ types $T,U,V \in \text{Obj}\mathbf{C}(L)$, defines composition 
\[
\begin{aligned}
\text{Hom}(T,U) \times \text{Hom}(U,V) & \to \text{Hom}(T,V) \\ 
(f,g) & \mapsto g \circ f
\end{aligned}
\]

Assume $L$ has a do nothing operation $1_T$, and composition constructor, $\text{Hom}(T,U) \times \text{Hom}(U,V) \to \text{Hom}(T, V)$. \\

Add additional type $1$ s.t. $\forall \, $ type $T \in \text{Obj}\mathbf{C}(L)$, $\exists \, !$ operation (function) to $1, T \to 1$ \\
Interpret each constant $c$ of type $A$ as arrow (morphism) $c:1\to A$.  \\

As a concrete example (cf. Example 2.2.5 of Barr and Wells (2012) \cite{BaWe2012}), suppose a simple language with 3 data types, \texttt{int}, \texttt{bool}, \texttt{char}. \\

For \texttt{int}, $\exists \, $ constant $0:1 \to \texttt{int}$, consider $\texttt{succ}:\texttt{int} \to \texttt{int} \in \text{Hom}(\texttt{int}, \texttt{int})$, \\
For \texttt{bool}, $\exists \, $ constants $\texttt{true} : 1 \to \texttt{bool}$, $\texttt{false} : 1 \to \texttt{bool}$; consider $\neg \in \text{Hom}(\texttt{bool}, \texttt{bool})$, s.t.
\[
\begin{aligned}
& \neg \circ \texttt{true} = \texttt{false} \\ 
& \neg \circ \texttt{false} = \texttt{true} 
\end{aligned}
\]

For \texttt{char}, $\exists \, $ constants $c:1 \to \texttt{char}$, \, $\forall \, \texttt{char} c$.

Since $\forall \, T,U \in \text{Obj}(\mathbf{C}(L))$, $\exists \, \text{Hom}(T,U) \subseteq \text{Mor}\mathbf{C}(L)$. So consider $\texttt{ord}:\texttt{char} \to \texttt{int}$, $\texttt{chr}: \texttt{int} \to \texttt{char}$, s.t. 
\[
\texttt{char} \circ \texttt{ord} = 1_{\texttt{char}}
\]

So $\text{Obj}\mathbf{C}(L) = \lbrace \texttt{int}, \texttt{bool}, \texttt{char}, 1 \rbrace$, \\
\phantom{So } $\text{Mor}\mathbf{C}(L)$ consists of all programs.

See 5.3.14 Record Types and 5.7.6, 14.2 for flow of control in Barr and Wells (2012) \cite{BaWe2012} to complete the programming language. For here, see section \ref{SubSubSect:RecordTypesProduct}

\item \textbf{Groups}, cf. pp. 11, Def. 1.4, Sec. 1.5 \textbf{Isomorphisms}, Awodey (2010) \cite{Awod2010}.

A \emph{group} $G$ is a monoid with inverse $g^{-1}$, $\forall \, g \in G$. \\
Thus, $G$ is a category with 1 object, $\forall \, f \in \text{Mor}G$ is an isomorphism.

$\forall \, $ set $X$, group $\text{Aut}(X)$ of automoprhisms (or "permutations") of $X$ i.e. $f:X\to X$ \\
$\text{Aut}(X)$ is closed under composition $\circ$ because a permutation of a permutation is another permutation.

Homomorphisms of groups $h: G\to H$ is just a homomorphism of monoids, preserving inverses.\\
Given $h$, then $h(gg') = h(g) h(g')$. \\
$G,H$ are monoids. Then $h$ monoid homomorphism.
\end{itemize}

Concrete categories: informally, categories which objects are sets, possibly equipped with some structure, and arrows are certain, possibly structure-preserving functions.

From pp. 10 of Mac Lane (1978) \cite{MacL1978}, Leinster (2014) \cite{Lein2014}, Examples 1.1.8 (Categories as mathematical structures), pp. 13, and Sec. 1.4 Examples of Categories, 5. Finite Categories, pp.7 of Awodey (2010) \cite{Awod2010}.

Category $\mathbf{1}$.  $\text{Obj}{\mathbf{1}} = \lbrace A \rbrace$ \\
$\text{Mor}{\mathbf{1}} = \lbrace 1_A \rbrace$; $1_A : A \to A$.  \\

The only composition to consider is $1_A \circ 1_A : A \to A$, and $1_A \circ 1_A \circ 1_A$, so on and so for.

Category $\mathbf{2}$.  $\text{Obj}{\mathbf{2}} = \lbrace A, B \rbrace$. \\
$\text{Hom}(A, B) = \lbrace f \rbrace$, $f:A\to B$. \\

The only "non-trivial" composition to consider is $1_B \circ f \circ 1_A : A \to B$. \\
 
Category $\mathbf{3}$. pp. 11, Sec. 2 Categories of Mac Lane (1978) \cite{MacL1978}, Example 5. "Finite Categories", Sec. 1.4, pp. 7 of Awodey (2010) \cite{Awod2010}. 

$\text{Obj}{\mathbf{3}} = \lbrace A, B, C \rbrace$ \\
$\text{Hom}{(A, B)} = \lbrace f \rbrace$ \\
$\text{Hom}{(A, C)} = \lbrace g \rbrace$ \\
$\text{Hom}{(B, C)} = \lbrace h \rbrace$ \\
$\text{Hom}{(C, \cdot)} = \emptyset $ \\
$\text{Hom}{(B, A)} = \emptyset$ \\

The only "non-trivial" compositions to consider are the following:
$1_C \circ h \circ f : A \to C$, \\
$1_C \circ g$, $1_C \circ h$ (and likewise) \\


\subsection{Duality, opposite category}

Given a category $\mathbf{A} = ( \text{Ob}, \text{hom}_{\mathbf{A}}, 1, \circ)$, 
\begin{definition}[dual opposite category]
	\textbf{dual} or \textbf{opposite} category of $\mathbf{A} = (\text{Obj}(\mathbf{A}), \text{Mor}\mathbf{A}, \mathbf{1}, \circ)$, denoted $\mathbf{A}^{\text{op}}$, is   
	\begin{equation}
	\mathbf{A}^{\text{op}}  =  (\text{Obj}(\mathbf{A}), \text{Mor}\mathbf{A}^{\text{op}}, \mathbf{1}, \circ^{\text{op}})
	\end{equation}
	s.t.
\begin{itemize}
	\item 
	\begin{equation}
	\text{Obj}(\mathbf{A}^{\text{op}}) = \text{Obj}(\mathbf{A})
	\end{equation}
	\item $\forall \, A, B \in \text{Obj}(\mathbf{A}^{\text{op}})$, $\text{Hom}_{\mathbf{A}^{\text{op}}}(A,B) \subseteq \text{Mor}\mathbf{A}^{\text{op}}$, 
		\begin{equation}
\text{Hom}_{\mathbf{A}^{\text{op}}}(A,B) = \text{Hom}_{\mathbf{A}}(B,A) \subseteq \text{Mor}\mathbf{A}
		\end{equation}
		\item \emph{Define} the new composition 
		\begin{equation}
\begin{gathered}
		f \circ^{\text{op}} g \text{ of } \begin{aligned} & \quad \\
		& g \in \text{Hom}_{\mathbf{A}^{\text{op}}}(C,B) \\
		& f \in \text{Hom}_{\mathbf{A}^{\text{op}}}(B,A) 
		\end{aligned}		 \\
		\text{ then } \\
		f \circ^{\text{op}} g = g\circ f
\end{gathered}
		\end{equation}
\[
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=3em, column sep=4em, minimum width=2em]
{
	A & B & C \\
};
\path[->]
(m-1-1) edge node [above] {$f$} (m-1-2)
(m-1-2) edge node [above] {$g$} (m-1-3);
		\path[-{>[scale=1.15]}, line width=0.5pt]
(m-1-1) edge[bend right=45] node [below] {$g\circ f$} (m-1-3);
\end{tikzpicture} \qquad \qquad \, \, \text{ dual :} \begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=3em, column sep=4em, minimum width=2em]
{
	A & B & C \\
};
\path[->]
(m-1-3) edge node [above] {$g$} (m-1-2)
(m-1-2) edge node [above] {$f$} (m-1-1);
		\path[-{>[scale=1.15]}, line width=0.5pt]
(m-1-3) edge[bend left=45] node [below] {$f\circ^{\text{op}} g$} (m-1-1);
\end{tikzpicture}
\]		
or, equivalently (notation-wise)
\[
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=3em, column sep=4em, minimum width=2em]
{
	A & B & C \\
};
\path[->]
(m-1-3) edge node [above] {$g$} (m-1-2)
(m-1-2) edge node [above] {$f$} (m-1-1);
		\path[-{>[scale=1.15]}, line width=0.5pt]
(m-1-3) edge[bend left=45] node [below] {$f \circ g$} (m-1-1);
\end{tikzpicture}
\qquad \qquad \, \, \text{ dual :} 
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=3em, column sep=4em, minimum width=2em]
{
	A & B & C \\
};
\path[->]
(m-1-1) edge node [above] {$f$} (m-1-2)
(m-1-2) edge node [above] {$g$} (m-1-3);
		\path[-{>[scale=1.15]}, line width=0.5pt]
(m-1-1) edge[bend right=45] node [below] {$g\circ^{\text{op}} f$} (m-1-3);
\end{tikzpicture} 
\]		
in that 
\[
\begin{gathered}
g \circ^{\text{op}} f \text{ of } \begin{aligned} & \quad \\
& f \in \text{Hom}_{\mathbf{A}^{\text{op}}}(A,B) \\
& g \in \text{Hom}_{\mathbf{A}^{\text{op}}}(B,C) 
\end{aligned}		 \\
\text{ then } \\
g \circ^{\text{op}} f = f\circ g
\end{gathered}
\]
\end{itemize}
\end{definition}

i.e. (in summary) $\mathbf{C}^{\text{op}}$ s.t. $\text{Obj}\mathbf{C}^{\text{op}} = \text{Obj}\mathbf{C}$, \\
Denote $\forall \, \overline{C} \in \text{Obj}\mathbf{C}^{\text{op}}$, $\overline{C} = C \in \text{Obj}\mathbf{C}$. \\
$\text{Hom}_{\mathbf{C}^{\text{op}}}(\overline{A}, \overline{B}) \ni \overline{f} : \overline{C} \to \overline{D}$, in $\mathbf{C}^{\text{op}}$, for $f:D\to C$ in $\mathbf{C}$.  \\

\[
\begin{gathered}
1_{\overline{C}} = 1_C \\
	\overline{f} \circ \overline{g} \equiv \overline{f} \circ_{\text{op}} \overline{g} = g\circ f 
\end{gathered}
\]

Diagram in $\mathbf{C}$:

\[
\begin{tikzpicture}
\matrix(m)[matrix of math nodes, row sep=4em, column sep=4em]
{
	A   &  B \\
	  & C  \\
};
\path[->]
(m-1-1) edge node[above]{$f$} (m-1-2)
edge node[left]{$g\circ f$} (m-2-2) 
(m-1-2) edge node[right]{$g$} (m-2-2);
\end{tikzpicture} 
\]

Diagram in $\mathbf{C}^{\text{op}}$:

\[
\begin{tikzpicture}
\matrix(m)[matrix of math nodes, row sep=4em, column sep=4em]
{
	\overline{A}   &  \overline{B} \\
	& \overline{C}  \\
};
\path[->]
(m-1-2) edge node[above]{$\overline{f}$} (m-1-1)
(m-2-2) edge node[left]{$\overline{f}\circ \overline{g}$} (m-1-1)
edge node[right]{$\overline{g}$} (m-1-2);
\end{tikzpicture} 
\]

e.g. $\mathbf{Sets}$ is dual to category of complete, atomic Boolean algebras.

e.g. if $\mathbf{A} = (M,\cdot, e)$ monoid, then $\mathbf{A}^{\text{op}} = (M, \widehat{\cdot},e)$ where $a\widehat{\cdot} b = b\cdot a$


\subsubsection{Example}

\begin{itemize}
	\item $\text{Vec}^{\text{op}}$
	\[
	\textbf{Vec}^{\text{op}} = (\text{Obj}(\textbf{Vec}), \text{Hom}_{\textbf{Vec}^{\text{op}}}, 1, \circ^{\text{op}})
	\]
	s.t.
	\[
	\text{Hom}_{\textbf{Vec}^{\text{op}} }(W,V) = \text{Hom}_{\textbf{Vec}}(V,W)
	\]
\[	
	\begin{tikzpicture}
	\matrix (m) [matrix of math nodes, row sep=3em, column sep=4em, minimum width=2em]
	{
		U & V & W \\
	};
	\path[->]
	(m-1-1) edge node [above] {$f$} (m-1-2)
	(m-1-2) edge node [above] {$g$} (m-1-3);
		\path[-{>[scale=1.15]}, line width=0.5pt]
	(m-1-1) edge[bend right=45] node [below] {$g\circ f$} (m-1-3);
	\end{tikzpicture} \qquad \, \begin{tikzpicture}
	\matrix (m) [matrix of math nodes, row sep=3em, column sep=4em, minimum width=2em]
	{
		U & V & W \\
	};
	\path[->]
	(m-1-3) edge node [above] {$g$} (m-1-2)
	(m-1-2) edge node [above] {$f$} (m-1-1);
		\path[-{>[scale=1.15]}, line width=0.5pt]
(m-1-3) 	edge[bend left=45] node [below] {$f\circ^{\text{op}} g$} (m-1-1);
	\end{tikzpicture}
\]
\end{itemize}

\subsection{Kinds of morphisms}

cf. pp. 11, Definition 1.3 of Awodey (2010) \cite{Awod2010}
\begin{definition}[isomorphism]
	\textbf{isomorphism} - $\forall \, $ category $\mathbf{C}$, $\text{Mor}\mathbf{C} \ni $ morphism $f:A \to B$ is an isomorphism if $\exists \, g : B \to A$ s.t. $f\circ g = 1_B$, $g\circ f = 1_A$, $g$ unique. $g$ called inverse of $f,f^{-1}$
	\[
	\begin{gathered}
	\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=3em, column sep=4em, minimum width=2em]
{
	A & B \\
};
\path[->]
(m-1-1) edge node [above] {$f$} (m-1-2)
		edge [loop left] node [left] {$1_A$} (m-1-1);
		\path[-{>[scale=1.15]}, line width=0.5pt]
(m-1-2) edge[bend left=45] node [below] {$g$} (m-1-1);
\end{tikzpicture}	\qquad \, 
	\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=3em, column sep=4em, minimum width=2em]
{
	B & A \\
};
\path[->]
(m-1-1) edge node [above] {$g$} (m-1-2)
		edge [loop left] node [left] {$1_B$} (m-1-1);
\path[-{>[scale=1.15]}, line width=0.5pt]
(m-1-2) edge[bend left=45] node [below] {$f$} (m-1-1);
\end{tikzpicture}	
	\end{gathered}	
	\]
\end{definition}

\begin{theorem}[Cayley]
cf. pp. 11, Sec. 1.5. \textbf{Isomorphisms}, Awodey (2010) \cite{Awod2010}

$\forall \, $ group $G$, 
\[
G \cong \text{ group of permutations }
\]
(isomorphic $\equiv \cong$)

\end{theorem} 

\begin{proof}
	Define Cayley representation $\overline{G}$ of $G$ to be following group of permutations: \\
	underlying set of $\overline{G}$ is just $G$, \\
	$\forall \, g\in G$, we have permutation $\overline{g}$, defined $\forall \, h \in G$, 
	\[
	\overline{g}(h) = g\cdot h
	\]
	Let $\overline{g} = \overline{h}$. \\
	$\forall \, g' \in G$, \\
	$\begin{aligned}
	& \overline{g}(g') = gg' \\ 
	& \overline{h}(g') = hg'
	\end{aligned}$ \\
	$g' \in G$, so $\exists \, (g')^{-1}$ s.t. $g'(g')^{-1} =e$, so $gg'(g')^{-1}= g=h$.
	
	\quad \\
	Define homomorphisms $\begin{aligned} & \quad \\ 
	& i : G \to \overline{G} \\
	& i(g) = \overline{g}
	\end{aligned}$, \qquad \, $\begin{aligned} & \quad \\ 
	& j : \overline{G} \to G \\
	& j(\overline{g}) =  g
	\end{aligned}$
	
	\[
	\begin{gathered} 
	i(gg') = \overline{(gg')} \\
	\begin{aligned}
	& \overline{(gg')} = h = gg' h = g(g'h) = g(\overline{g}'(h)) = \overline{g}(\overline{g}'(h)) = i(g) = i(g') h \\ 
	& \Longrightarrow i(gg') = i(g) \circ i(g') \\
	& j(\overline{g}) = j(\overline{g}') h = j(\overline{g}) (g'h) = gg'h = j(\overline{gg'})h = j(\overline{g} \cdot \overline{g}') h \\
	& j(\overline{g}) \cdot j(\overline{g}') = j(\overline{g} \cdot \overline{g}')
	\end{aligned} \\
	\begin{aligned}
	& i\circ j = 1_{\overline{G}}, \, j \circ i = 1_G \text{ since } \\
	& i \circ j (\overline{g}) = i\circ g = \overline{g} \\
	& j\circ i (g) = j(\overline{g}) = g
	\end{aligned}
\end{gathered} 	
	\]
	$i,j$ are isomorphisms between $G,\overline{G}$, which is in category $\textbf{Groups}$ of groups and group homomorphisms. \\
	permutations $\overline{g} \in \overline{G}$ are themselves isomorphisms in $\textbf{Sets}$. \\
	Cayley's Thm. says that any abstract group can be represented as a "concrete" one, i.e. group of permutations of a set.
\end{proof}

Example 1.1.5 (Leinster (2014) \cite{Lein2014}) isomorphisms in $\textbf{Set}$ are exactly bijections. \\
$\Longrightarrow $ function has 2-sided inverse iff function is injective and surjective (this is not trivial)

Example 1.1.7 Leinster (2014) \cite{Lein2014} isomorphisms in $\textbf{Top}$ are exactly homeomorphisms. \\
bijective map in $\textbf{Top}$ is not necessarily an isomorphism:
\[
\begin{aligned}
	[0, 1) & \to \lbrace z \in \mathbb{C} | |z| = 1 \rbrace \\
	t & \mapsto e^{2\pi i t}
\end{aligned}
\]
is a continuous bijection but not a homeomorphism (cont. bijection with cont. $f^{-1}$). 
\[
\ln{ \left( \frac{w}{2\pi i} \right) } = f^{-1}(w)
\]

Example 1.1.8 Leinster (2014) \cite{Lein2014} (Categories as mathematical structures) (b) \textbf{Discrete} categories contain no maps at all apart from identities. Just a class of objects.

\exercisehead{1.1.13 pp. 16, Leinster (2014) \cite{Lein2014}}

Suppose for morphism $f: A \to B$, $\exists \,$ inverse $g$, s.t. $f\circ g = 1_B$, $g\circ f = 1_A$ \\
Now $f^{-1} \circ f = 1_A$, $f\circ f^{-1} = 1_B$ \\
\phantom{Now} $f^{-1} \circ f \circ g = f^{-1} \circ 1_B = 1_A \circ g = f^{-1} \circ 1_B \Longrightarrow g= f^{_1}$ 


\begin{definition}[endomorphism]
	\textbf{endomorphism} - morphism with same source and target, that is, morphism $f:A \to A$
\end{definition}

\begin{definition}[automorphism]
\textbf{automorphism} - endomorphism which is an isomorphism
\end{definition}

\begin{definition}[parallel]
	\textbf{parallel} - 2 morphisms $f,g$ are parallel if they have same source and same target:
	\[
	\begin{aligned}
	& f:A \to B \\
	& g:A \to B
	\end{aligned}
	\]
\end{definition}

\begin{definition}[monomorphism]
	\text{monomorphism} - morphism $f: A \to B$ is a monomorphism if $\forall \, $ pair of parallel $\begin{aligned}
	& \quad \\
	& g_1: C \to A \\
	& g_2:C \to A
	\end{aligned}$, 
	\begin{equation}
	f\circ g_1 = f\circ g_2 \text{ implies } g_1 = g_2
	\end{equation}
	i.e.
	\[
	\begin{tikzpicture}
	\matrix (m) [matrix of math nodes, row sep=3em, column sep=4em, minimum width=2em]
	{
		C & B \\
	};
	\path[->]
	(m-1-1) edge node [above] {$f \circ g_1$} (m-1-2);
	\path[-{>[scale=1.15]}, line width=0.5pt]
	(m-1-2) edge[bend left=45] node [below] {$f\circ g_2$} (m-1-1);
	\end{tikzpicture} \text{ implies } C \xrightarrow{ g_1 = g_2 } A	
	\]
\end{definition}

\begin{definition}[epimorphism]
\textbf{epimorphism} - morphism $f:A \to B$ is an epimorphism if $f^{\text{op}} : B^{\text{op}} \to A^{\text{op}}$ is a monomorphism in $\mathbf{A}^{\text{op}}$. \\
Hence $f$ epimorphism iff $\forall \, $ parallel morphisms $\begin{aligned} & \quad \\ 
	& g_1 : B \to C \\
	& g_2 : B\to C\end{aligned}$, $g_1 \circ f = g_2 \circ f $ \\
	 implies $g_1 = g_2$
\end{definition}

\begin{proposition}[monomorphism, epimorphism iff injective]
	$f$ monomorphism iff $f \circ : \text{Hom}_{\mathbf{A}}(C,A) \to \text{Hom}_{\mathbf{A}}(C,B)$ injective \, $\forall \, C \in \text{Obj}(\mathbf{A})$, i.e.
	\begin{equation}
	\begin{gathered}
\begin{gathered} 
	\text{Hom}_{\mathbf{A}}(C, A) \xrightarrow{f \circ } \text{Hom}_{\mathbf{A}}(C,B) \\
 g_1 , g_2 \xmapsto{f \circ} f\circ g_1 , f\circ g_2
\end{gathered}, \\ \text{ then } \\
f \circ \text{ is injective if } \\
	f \circ g_1 = f \circ g_2 \Longrightarrow g_1 = g_2
\end{gathered} 
	\end{equation}
$f$ epimorphism iff map $\circ f : \text{Hom}_{\mathbf{A}}(B,C) \to \text{Hom}_{\mathbf{A}}(A,C)$ injective $\forall \, C \in \text{Obj}(\mathbf{A})$
\begin{equation}
\begin{gathered}
\begin{gathered} 
\text{Hom}_{\mathbf{A}}(B, C) \xrightarrow{\circ f} \text{Hom}_{\mathbf{A}}(A,C) \\
g_1 , g_2  \xmapsto{ \circ f} g_1\circ f , g_2 \circ f
\end{gathered}, \\ \text{ then } \\
\circ f \text{ is injective if } \\ 
g_1 \circ f = g_2 \circ f \Longrightarrow g_1 = g_2
\end{gathered}
\end{equation}
\end{proposition}

\begin{definition}[inverses]
	$\forall \, $ 2 morphisms, $f:X\to Y$, $g: Y \to X$ s.t. $f\circ g= 1_Y$,\\
	$f$ is called left inverse of $g$, $g$ is called right inverse of $f$.
	
	We also say, $g$ is a section of $f$, or $f$ is a cosection of $g$. \\
	$f$ is an epimorphism, $g$ is a monomorphism.
\end{definition}

\subsection{More definitions with categories}

\begin{definition}[subcategory]
category $\mathbf{A}'$, $\mathbf{A}' \subset \mathbf{A}$, if $\text{Obj}(\mathbf{A}') \subset \text{Obj}(\mathbf{A})$, $\text{Hom}_{\mathbf{A}'}(A,B) \subset \text{Hom}_{\mathbf{A}}(A,B)$, $\forall \, A, B \in \mathbf{A}'$.

Composition in $\mathbf{A}'$ is induced by composition in $\mathbf{A}$.\\
identity morphisms in $\mathbf{A}'$ are identity morphisms in $\mathbf{A}$
\end{definition}

\begin{definition}[full subcategory]
	subcategory $\mathbf{A}'$ of $\mathbf{A}$ is full if $\text{Hom}_{\mathbf{A}'}(A,B) = \text{Hom}_{\mathbf{A}}(A,B)$, $\forall \, A, B \in \mathbf{A}'$	
\end{definition}

\begin{definition}[saturated subcategory]
full subcategory $\mathbf{A}'$ of $\mathbf{A}$ saturated if $A \in \mathbf{A}$ belongs to $\mathbf{A}'$ whenever $A$ is isomorphic to object of $\mathbf{A}'$	
\end{definition}

\begin{definition}[discrete category]
	\textbf{discrete} - discrete category if all morphisms are identity morphisms.
\end{definition}

\begin{definition}[nonempty category]
	\textbf{nonempty} - nonempty category if $\text{Obj}(\mathbf{A})$ is nonempty
\end{definition}

\begin{definition}[groupoid]
\textbf{groupoid} - category $\mathbf{A}$ is a \textbf{groupoid} if all morphisms are isomorphisms.
\end{definition}

\begin{definition}[finite category]
	finite - finite category if set of all morphisms in $\mathbf{A}$ (hence, in particular, set of objects) is a finite set
\end{definition}

\begin{definition}[connected]
	connected category $\mathbf{A}$ if it's nonempty, and $\forall \, A,B \in \text{Obj}\mathbf{A}$, $\exists \, $ finite sequence of objects $(A_0 \dots A_n)$, $A_0 = A$, $A_n = B$, s.t. at least 1 of the sets $\text{Hom}_{\mathbf{A}}(A_j, A_{j+1})$ or $\text{Hom}_{\mathbf{A}}(A_{j+1}, A_j)$ is nonempty $\forall \, j \in \mathbb{N}$, with $0\leq j \leq n-1$
\end{definition}

\begin{definition}[monoid $M$]
	\textbf{monoid} $M$ (set endowed with internal product with associative and unital law) is nothing but a category with only 1 object (to $M$, associate category $\mathbf{M}$, with single object $A$, and morphisms $\text{Hom}_{\mathbf{M}}(A,A) = M$)
\end{definition}

cf. Def. 1.2.5 of Kashiwara and Schapira (2006) \cite{KaSch2006}.

\begin{definition}[Morphisms as a category]
	Let category $\mathcal{C} \equiv \mathbf{A}$.
	
	$\text{Mor}(\mathbf{A})$ is a category.
	
	$\text{Obj}(\text{Mor}(\mathbf{A})) = \text{Mor}\mathbf{A}$ (objects of category $\text{Mor}(\mathbf{A})$ are morphisms in $\mathbf{A}$).
	
	Let $\begin{aligned} & \quad \\ 
	& f:X \to Y \\
	& g: X' \to Y'\end{aligned}$, $f,g \in \text{Mor}(\mathbf{A})$ (i.e. $\begin{aligned} & \quad \\ 
	& f \in \text{Hom}(X,Y) \\ 
	&g \in \text{Hom}(X', Y') \end{aligned}$, for $X, Y, X', Y' \in \text{Obj}(\mathbf{A})$)
	
	Then
	\[
	\text{Hom}_{\text{Mor}(\mathbf{A})}(f,g) = \lbrace u :X \to X', v: Y \to Y'; g \circ u = v \circ f \rbrace
	\]
	Composition and identity in $\text{Mor}(\mathbf{A})$ are the obvious ones.
	
	So 
	\[
	\begin{gathered} 
	\text{Obj}(\text{Mor}(\mathbf{A})) = \text{Mor}(\mathbf{A}) \\
	\text{Mor}(\text{Mor}(\mathbf{A})) = \bigcup_{f,g \in \text{Mor}(\mathbf{A})} \text{Hom}(f,g) = \bigcup_{f,g \in \text{Mor}(\mathbf{A}) } \lbrace u : X\to X', v: Y \to Y' ; g \circ u = v \circ f \rbrace 
	\end{gathered} 
	\]
\[
	\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=5em, column sep=5em, minimum width=2em]
{
	X & Y \\
	X' & Y' \\
};
\path[->]
(m-1-1) edge node [above] {$f$} (m-1-2)
edge node [auto] {$u$} (m-2-1)
(m-1-2) edge node [auto] {$v$} (m-2-2)
(m-2-1) edge node [auto] {$g$} (m-2-2);
\end{tikzpicture}
\]
\end{definition}

cf. Def. 1.2.6 of Kashiwara and Schapira (2006) \cite{KaSch2006}.

\begin{definition}
	\begin{enumerate}
		\item object $P \in \mathcal{C} \equiv \mathbf{A}$ is called \emph{initial} if $\forall \, X \in \mathbf{A}$, ($\equiv \forall \, x \in \text{Obj}(\mathbf{A})$), $\text{Hom}_{\mathbf{A}}(P, X) \simeq \lbrace \text{pt} \rbrace$. \\
		(Denote by $\emptyset_{\mathbf{A}}$ an \emph{initial object} in $\mathbf{A}$). \\
		(Note that if $P_1$ and $P_2$ are initial, then $\exists \, !$ isomorphism $P_1 \simeq P_2$)
		\item $P$ is terminal in $\mathbf{A}$ if $P$ is initial in $\mathbf{A}^{\text{op}}$, i.e. 
		
		$\forall \, X \in \mathbf{A}$, $\text{Hom}_{\mathbf{A}}(X, P) \simeq \lbrace \text{pt} \rbrace$. 
		
		Denote $\text{pt}_{\mathbf{A}}$ a terminal object in $\mathbf{A}$. 
		\item $P$ is zero ($0$) object if it's both initial and terminal. 
		
		Such a $P$ is denoted by $0$.
		
		If $\mathbf{A}$ has a zero object, $\forall \, $ object $X, Y \in \mathbf{A} \equiv \text{Obj}\mathbf{A}$, the morphism obtained as composition $X\to 0 \to Y$ is still denoted by $0: X\to Y$.
		
		(Note that composition of $0:X \to Y$, and any morphism $f:Y \to Z$ is $0:X \to Z$)
	\end{enumerate}
\end{definition}

cf. Example 1.2.7 of Kashiwara and Schapira (2006) \cite{KaSch2006}. 
Example 
\begin{enumerate}
	\item[(i)] In category $\mathbf{Set}$, $\emptyset$ initial, $\lbrace \text{pt} \rbrace$ terminal. 
	\item[(ii)] Zero module $0$ is zero object in $\text{Mod}(R)$.
\end{enumerate}

Notation 1.2.8 of Kashiwara and Schapira (2006) \cite{KaSch2006}:
\begin{enumerate}
	\item $\mathbf{Pt} \equiv $ category with a single object and a single morphism (the identity of this object)
	\item $\emptyset \equiv $ empty category with no objects (hence, no morphisms)
	\item $\bullet \to \bullet \equiv$ category which consists of 2 objects, say $a,b$, and 1 morphism, $a\to b$, other than $\text{id}_a, \text{id}_b \equiv 1_a, 1_b$. Denote this category by $\mathbf{Arr}$.  
\end{enumerate}

cf. Example 1.2.9 of Kashiwara and Schapira (2006) \cite{KaSch2006}. 

Let $R$ be a ring. Let $N\in \text{Mod}(R^{\text{op}})$, $M\in \text{Mod}(R)$.

Category $\mathbf{C}$: 

$\text{Obj}\mathbf{C} \ni (f, L)$, where $L\in \text{Mod}(\mathbb{Z})$, $f$ bilinear map $f: N \times M \to L$ (i.e. it's $\mathbb{Z}$-bilinear and satisfies
\[
f(na, m) = f(n,am), \quad \, \forall \, a \in R
\])

Morphism from $f:N \times M \to L$ to $g: N\times M$ is a linear map $h:L\to K$ s.t. $h\circ f =g$. 

Since any bilinear map $f: N\times M \to L$ (i.e. any object of $\mathbf{C}$) factorizes uniquely through
\[
u  : N\times M \to N \otimes_R M
\]
object $(u, N \otimes_R M)$ is initial in $\mathbf{C}$

\section{Functors}

cf. Def. 1.2.10 of Kashiwara and Schapira (2006) \cite{KaSch2006}, with terminology from pp. 13, Sec. 3. "Functors" from Mac Lane (1978) \cite{MacL1978}

\begin{definition}[(covariant) Functor]\label{Def:Functor}
\begin{enumerate}
	\item (covariant functor) Let categories $\mathbf{C}$, $\mathbf{D}$. \\
(covariant) \textbf{functor} $F: \mathbf{C} \to \mathbf{D}$ consists of (Mac Lane (1978) \cite{MacL1978} says 2 suitably related functions)
\begin{itemize}
	\item map $F: \text{Obj}(\mathbf{C}) \to \text{Obj}(\mathbf{D})$ (i.e. $\forall \, C \in \text{Obj}(\mathbf{C})$, $F(C) \in \text{Obj}(\mathbf{D})$), \\
	(Mac Lane (1978) \cite{MacL1978} calls this the \emph{object function} $T$ or $F$ in our notation; we'll call it the \emph{object map}) and 
	\item maps $F: \text{Hom}_{\mathbf{C}}(X,Y) \to \text{Hom}_{\mathbf{D}}(F(X), F(Y))$, so that 
		\[	
			F(f) : F(X) \to F(Y) \text{ or } F(f)(F(X)) = F(f(X)) 
		\] \, $\forall \, X,Y \in \text{Obj}(\mathbf{C})$ s.t.
	\begin{equation}
	\begin{gathered}
	F(1_X) = 1_{F(X)} \qquad \, \forall \, X \in \mathbf{C} \\
	F(g\circ f) = F(g) \circ F(f) \qquad \, \forall \, \begin{aligned} & \quad \\ 
	& f: X \to Y \\
	& g: Y \to Z \end{aligned}, \qquad \, X,Y,Z \in \text{Obj}(\mathbf{C})
	\end{gathered}
	\end{equation}
	Mac Lane (1978) \cite{MacL1978} calls this the \emph{arrow function} (also written as $T$ for Mac Lane's notation; $F$ for our notation); we'll call $F$ to be the \emph{morphism map}. 
\end{itemize}
\item (composition law for functors) \\
For categories $\mathbf{A} , \mathbf{B}, \mathbf{C}$, functors $F: \mathbf{A} \to \mathbf{B}$, $G: \mathbf{B} \to \mathbf{C}$, \\
Composition $G\circ F : \mathbf{A} \to \mathbf{C}$, is a functor defined by 
\begin{equation}
\begin{aligned}
& (G\circ F)(X) = G(F(X)) \qquad \, \forall \, X \in \text{Obj}\mathbf{A}, \text{ and } \\
& (G\circ F)(f) = G(F(f)), \qquad \, \forall \, \text{ morphism } f \in \text{Mor}(\mathbf{C})
\end{aligned}
\end{equation}
\end{enumerate}
\end{definition}
Diagrammatically,

\[
\begin{gathered}
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=1.8em, column sep=1.8em, minimum width=1.2em]
{
	X & Y \\
};
\path[->]
(m-1-1) edge node [above] {$f$} (m-1-2);
\end{tikzpicture} \quad \xrightarrow{F} \quad
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=1.8em, column sep=1.8em, minimum width=1.2em]
{
	F(X) & F(Y) \\
};
\path[->]
(m-1-1) edge node [above] {$F(f)$} (m-1-2);
\end{tikzpicture} \\
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=1.8em, column sep=1.8em, minimum width=1.2em]
{
	X & Y & Z \\
};
\path[->]
(m-1-1) edge node [above] {$f$} (m-1-2)
edge[bend right=45] node [below] {$g\circ f$} (m-1-3)
(m-1-2) edge node [above] {$g$} (m-1-3)
;
\end{tikzpicture} 
\quad \xrightarrow{F} \quad \begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=1.8em, column sep=1.8em, minimum width=1.2em]
{
	F(X) & F(Y) & F(Z) \\
};
\path[->]
(m-1-1) edge node [above] {$F(f)$} (m-1-2)
edge[bend right=45] node [below] {$F(g\circ f)$} (m-1-3)
(m-1-2) edge node [above] {$F(g)$} (m-1-3)
;
\end{tikzpicture} 
\end{gathered}
\]
i.e.
\[
\begin{gathered} 
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=3.8em, column sep=4.8em, minimum width=2.2em]
{
	X & Y \\
	F(X) & F(Y) \\
};
\path[->]
(m-1-1) edge node [above] {$f$} (m-1-2)
edge node [auto]  {$F$} (m-2-1)
(m-1-2) edge node [auto]  {$F$} (m-2-2)
(m-2-1) edge node [above] {$F(f)$} (m-2-2)        
;
\end{tikzpicture} \text{ and } 
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=3.8em, column sep=4.8em, minimum width=2.2em]
{
	X & Y & Z \\
	F(X) & F(Y) & F(Z) \\ 
};
\path[->]
(m-1-1) edge node [above] {$f$} (m-1-2)
edge[bend left=45] node [above] {$g\circ f$} (m-1-3)
edge node [auto] {$F$} (m-2-1)
(m-1-2) edge node [above] {$g$} (m-1-3)
edge node [auto] {$F$} (m-2-2)
(m-1-3) edge node [auto] {$F$} (m-2-3)
(m-2-1) edge node [above] {$F(f)$} (m-2-2)
edge[bend right=45] node [below] {$F(g\circ f) = F(g) \circ F(f)$} (m-2-3)
(m-2-2) edge node [above] {$F(g)$} (m-2-3)  
;
\end{tikzpicture} 
\end{gathered}
\]

\subsection{Examples of Functors}

cf. pp. 13, 3. Functors, Maclane (1978) \cite{MacL1978}

\emph{Power Set Functor}. 
\[
\begin{gathered}
	\begin{aligned}
		& P : \textbf{Set} \to \textbf{Set} \\
		& P:\text{Obj}\textbf{Set} \to \text{Obj}(\textbf{Set}) \\
		& P: X \in \text{Obj}\textbf{Set} \mapsto 2^X \in \text{Obj}\textbf{Set}, \text{ i.e. } \\
		& P:X \mapsto 2^X = \lbrace S | S \subseteq X \rbrace 
	\end{aligned} \\
P : \text{Hom}_{\textbf{Set}}(X,Y) \to \text{Hom}_{\textbf{Set}}(P(X), P(Y)) \\
\begin{aligned} 
& P(f): P(X) \to P(Y) \text{ or } P(f)(P(X)) = P(f(X)) \\
& P(f): S \in 2^X \mapsto f(S) \in 2^Y \text{ or } f(S) \subseteq Y 
\end{aligned} 
\end{gathered}
\]
\[
\begin{gathered}
P(1_X) = 1_{PX} \text{ and } P(g\circ f) = P(g) P(f), \text{ so $P$ defines a functor }
\end{gathered}
\]

Algebraic topology; singular homology in a given dim. $n$ ($n \in \mathbb{N}$) Maclane (1978) \cite{MacL1978}

$\forall \, $ topological space $X$, assign $X \mapsto $ abelian group $H_n(X) \equiv n$th homology group of $X$, also \\
$\forall \, $ cont. $f:X \to Y$ of spaces corresponding group homomorphism. 
\[
\begin{gathered}
H_n(f) : H_n(X) \to H_n(Y) \\
\begin{aligned}
& H_n: \text{Obj}(\mathbf{Top}) \to \text{Obj}(\textbf{Ab}) \\
& H_n: X \mapsto H_n(X) 
\end{aligned} \\
H_n(f)(H_n(X)) = H_n(f(X))
\end{gathered}
\]
$\Longrightarrow H_n: \textbf{Top} \to \textbf{Ab}$.

e.g. if $X=Y = S^1$, $H_1(S^1) = \mathbb{Z}$

So group homomorphism $H_1(f): \mathbb{Z} \to \mathbb{Z}$ determined by integer $d\in \mathbb{Z}$ (image of 1) \\
$d$ is usual "degree" of cont. map $f:S^1 \to S^1$. 

In this case, and in general, homotopic maps $f,g : X \to Y$ \\
Then $\exists \,$ homotopy $H:X \times [0,1] \to Y$ s.t. $H(x,0) = f(x)$; $H(x,1) = g(x) \, \forall \, x \in X$




Example 1.2.3 (forgetful functors) Leinster (2014) \cite{Lein2014}, pp. 18

\begin{enumerate}
	\item[(a)] $U : \textbf{Grp} \to \textbf{Set}$ \\
	if group $G$ then $U(G)$ is underlying set of $G$. \\
	If group homomorphism $f:G \to H$, \\
	$U(f)$ is function $f$ itself. \\
	So $U$ forgets group structure of groups and forgets group homomorphisms are homomorphisms.
	\item[(c)] $\textbf{Ab} \equiv $ category of abelian groups \\
	$\textbf{Ring} \to \textbf{Ab}$ forgets multiplicative structure. \\
	$U:\textbf{Ring} \to \textbf{Mon}$ forgets additive structure; $\textbf{Mon} \equiv $ category of monoids
\end{enumerate}




\begin{itemize}
	\item (monoid) homomorphism $h: M \to N$, $\forall \, $ monoid $M, N$ s.t. $\forall \, m,n \in M$, \\
	$h(m\cdot n) \equiv h(m\cdot_M n) = h(m) \cdot h(n) \equiv h(m) \cdot_N h(n)$ and \\
	$h(e_M) = e_N$. \\
	
	$h:m \mapsto h(m)$ so $h: \text{Obj}\mathbf{C}(M) \to \text{Obj}\mathbf{C}(N)$. \\
	Let $m\cdot n \equiv f_m(n)$, $f_m \in \text{Hom}\mathbf{C}(M)$
	\[
	\begin{aligned}
		& h(m) \cdot h(n) \equiv f_{h(m)}(h(n)), \, f_{h(m)} \in \text{Hom}\mathbf{C}(N) \\
 		& h(f_m) = h(m) \\
		& h(f_m)(h(n)) = h(m)\cdot h(n) = h(m\cdot n) = h(f_m\cdot n)
	\end{aligned}
	\]
	Compare the last statement with $F(f)(F(X)) = F(f(X))$.
	\item poset $P, Q$ (set $P$, equipped with $\leq$), poset as category $\mathbf{P}, \mathbf{Q}$, $\text{Obj}\mathbf{P} = P$, $\text{Obj}\mathbf{Q} = Q$ \\
	$\text{Hom}\mathbf{P} \ni m$ s.t. $m:x \mapsto y$ iff $x\leq y$. \\
	
	Let functor $F: \mathbf{P} \to \mathbf{Q}$ s.t. 
	\[
	\begin{aligned} 
		& F: \text{Obj}\mathbf{P} \to \text{Obj}\mathbf{Q} \\  
		&	F: x \mapsto F(x)
	\end{aligned} 
	\]
	\[
	\begin{aligned}
		& F: \text{Hom}\mathbf{P} \to \text{Hom}\mathbf{Q} \\ 
		& F: m \mapsto F(m)
	\end{aligned}
	\]
	s.t. for $m(x) =y$ and $x\leq y$, \\
	$F(m): F(x) \mapsto F(y)$ and $F(x) \leq F(y)$ (so that $F(m)$ is also monotone), i.e.
	\[
	F(m)(F(X)) = F(m(X)) = F(y)
	\]
\end{itemize}

Kleene closure itself is a functor from $\mathbf{Set}$ to $\textbf{Set}$, from $A$ to $A^*$, from $f$ to $f^*$. \\
It's the composition of $U\circ F$ of underlying functor $U:\textbf{Mon} \to \textbf{Set}$ and free functor $F:\textbf{Set} \to \textbf{Mon}$. 

\begin{itemize}
	\item \emph{arrow category} $\mathbf{C}^{\rightarrow}$ of category $\mathbf{C}$:
\[
\text{Obj}\mathbf{C}^{\rightarrow} = \text{Mor}\mathbf{C}
\]

Given $f:A \to B$, $f':A' \to B'$, morphism (arrow) $g: f \mapsto f'$ is a "commutative square", i.e. $g: \text{Hom}_{\mathbf{C}}(A\to B) \to \text{Hom}_{\mathbf{C}}(A' \to B')$

\[
\begin{gathered} 
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=3.8em, column sep=4.8em, minimum width=2.2em]
{
	A & A' \\
	B & B' \\
};
\path[->]
(m-1-1) edge node [above] {$g_1$} (m-1-2)
edge node [auto]  {$f$} (m-2-1)
(m-1-2) edge node [auto]  {$f'$} (m-2-2)
(m-2-1) edge node [above] {$g_2$} (m-2-2)        
;
\end{tikzpicture} 
\end{gathered}
\]
where $g_1, g_2 \in \text{Mor}\mathbf{C}$, \\
i.e. such a morphism (arrow) is a pair of morphisms (arrows) $g=(g_1,g_2)$ in $\mathbf{C}$ s.t.
\[
g_2 \circ f = f'\circ g
\]

identity morphism (arrow) $1_f$ on object $f:A\to B$ is pair $(1_A, 1_B)$.

Composition of arrows is done componentwise:
\[
(h_1,h_2) \circ (g_1, g_2) = (h_1 \circ g_1, h_2\circ g_2)
\]

\[
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=3.8em, column sep=4.8em, minimum width=2.2em]
{
	A & A' & A'' \\
	B & B' & B'' \\ 
};
\path[->]
(m-1-1) edge node [above] {$g_1$} (m-1-2)
edge[bend left=45] node [above] {$h_1\circ g_1$} (m-1-3)
edge node [auto] {$f$} (m-2-1)
(m-1-2) edge node [above] {$h_1$} (m-1-3)
edge node [auto] {$f'$} (m-2-2)
(m-1-3) edge node [auto] {$f''$} (m-2-3)
(m-2-1) edge node [above] {$g_2$} (m-2-2)
edge[bend right=45] node [below] {$h_2\circ g_2$} (m-2-3)
(m-2-2) edge node [above] {$h_2$} (m-2-3)  
;
\end{tikzpicture} 
\]

Observe that there are 2 functors:

\[
\begin{gathered} 
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=3.8em, column sep=4.8em, minimum width=2.2em]
{
	\mathbf{C} & \mathbf{C}^{\rightarrow} & \mathbf{C} \\
};
\path[->]
(m-1-2) edge node [above] {$\textbf{dom}$} (m-1-1)
edge node [auto]  {$\textbf{cod}$} (m-1-3)
;
\end{tikzpicture} 
\end{gathered}
\]

\item \emph{algebra} cf. pp. 14, Sec. 3, "Functors" of Mac Lane (1978) \cite{MacL1978}.

$\forall \, $ commutative ring $K$, set of all non-singular $n\times n$ matrices with entries in $K = $ general linear group $GL_n(K)$. \\
$\forall \, $ homomorphism $f: K \to K'$ of rings produces \\
homomorphism $GL_n f : GL_n(K) \to GL_n(K)$ of groups.  \\

$\forall \, n \in \mathbb{N}$ (natural numbers), defined functor $GL_n: \textbf{CRng} \to \textbf{Grp} \equiv GL_n \textbf{CommRing} \to \textbf{Grp}$.  \\


$\forall \, $ group $G$, set of all products of commutators $xyx^{-1} y^{-1}$ ($x,y \in G$) is a normal subgroup $[G, G]$ of $G$ called commutator subgroup. \\

Since $\forall \, $ homomorphism $G \to H$ of groups carries commutators to commutators.  \\
$G \mapsto [G, G]$ defines evident functor $\textbf{Grp} \to \textbf{Grp}$, \\
while $G \mapsto G/[G, G]$ define functor $\textbf{Grp} \to \textbf{Ab}$, factor-commutator functor. \\
TODO - understand the previous commutators.

\end{itemize} 

\subsubsection{Endofunctor}

\begin{definition}[Endofunctor]\label{Def:Endofunctor}
Consider \textbf{endofunctor} $T : \mathbf{C} \to \mathbf{C}$. This implies that, for the \\

object map $\begin{aligned} & \quad \\ 
	& T : \text{Obj}{\mathbf{C}} \to \text{Obj}{\mathbf{C}} \\ 
	& T : X \to Y \end{aligned}$, \\
	
	object map $T$ acts like a morphism, in $\text{Mor}\mathbf{C}$ (!!!). In this case $T$ acts like $T\in \text{Hom}_{\mathbf{C}}(X, Y)$.  \\
	
	morphism map $T: \text{Hom}_{\mathbf{C}}(X, Y) \to \text{Hom}_{\mathbf{C}}(F(X), F(Y))$ s.t. 
	\begin{equation}
	\begin{gathered} 
		T(f) \equiv Tf:T(X) \to T(Y) \text{ so that } Tf \in \text{Hom}_{\mathbf{C}}(T(X), T(Y))  \\
		T(1_X) = 1_{T(X)} \in \text{Hom}_{\mathbf{C}}(T(X), T(Y)) (\text{implied from Kashiwara and Schapira (2006) \cite{KaSch2006} in that} \, 1_X \in \text{Hom}(X,X)) \\
		T(g\circ f) = T(g) \circ T(f), \, \forall \, f:X \to Y, \, g:Y \to Z, \, X,Y,Z\in \text{Obj}{\mathbf{C}}
	\end{gathered} 
	\end{equation} 
	So $T(f) \equiv Tf$ is indeed a morphism map.

\end{definition}

\subsubsection{Hom functors}

Let $\mathbf{C}$ locally-small category (i.e. category s.t. hom-classes are actually sets and not proper classes).

$\forall \, A, B \in \text{Obj}\mathbf{C}$, 

\begin{definition}[covariant Hom functor]
	\textbf{covariant Hom functor} $\text{Hom}(A, -): \mathbf{C} \to \mathbf{Set}$
	\begin{equation}
	\begin{aligned}
	& \text{Hom}(A, - ) : \text{Obj}\mathbf{C} \to  2^{\text{Mor}(\mathbf{C})} \\ 
	& \text{Hom}(A, - ) : X \mapsto \text{Hom}(A,X) \\ 
	& \text{Hom}(A, - ) : \text{Mor}\mathbf{C} \to (\text{Mor}(\mathbf{C}) \to \text{Mor}(\mathbf{C})) \\
	& \text{Hom}(A, - ) : \text{Hom}(X,Y) \to (\text{Hom}(A,X) \to \text{Hom}(A,Y)) \\
	& \text{Hom}(A, - ) : f \mapsto \text{Hom}(A,f) \text{ where } \\
	& \begin{aligned} \text{Hom}(A,f) : & \text{Hom}(A,X) \to \text{Hom}(A,Y) \\ 
	& g\mapsto f\circ g \quad \, \forall \, g \in \text{Hom}(A,X) 
	\end{aligned} 
	\end{aligned}
	\end{equation}
\end{definition}

\begin{claim}
$\text{Hom}(A, -)$ is a functor.
\end{claim}

\begin{proof}
	\begin{itemize}
		\item \emph{identity}: $\text{Hom}(A,-) : 1_X \mapsto \text{Hom}(A, 1_X) \text{ where }$ 
		\[
		\begin{aligned}
			\text{Hom}(A, 1_X) : & \text{Hom}(A,X) \to \text{Hom}(A,X) \\ 
			& g\mapsto 1_X \cdot g = g , \quad \, \forall \, g\in \text{Hom}(A,X)
		\end{aligned}
		\]
		Hence
		\[
		\text{Hom}(A, -)(1_X) = 1_{\text{Hom}(A,X)} \in (\text{Hom}(A,X) \to \text{Hom}(A,X))
		\]
		\item \text{composition}: Let 
		\[
		\begin{aligned}
		& f \in \text{Hom}(X,Y) \\ 
		& g \in \text{Hom}(Y,Z) \\ 
		& k \in \text{Hom}(A,X) 
		\end{aligned}
		\]
		\[
		\text{Hom}(A, g) \circ \text{Hom}(A,f)(k) = \text{Hom}(A,g)(f\circ k) = g\circ f \circ k = (g\circ f)(k) = \text{Hom}(A, g\circ f)(k)
		\]
	\end{itemize}
\end{proof}

\begin{definition}[contravariant Hom functor]
	\textbf{contravariant Hom functor} $\text{Hom}(-, B): \mathbf{C} \to \mathbf{Set}$
	\begin{equation}
	\begin{aligned}
	& \text{Hom}(-, B ) : \text{Obj}\mathbf{C} \to  2^{\text{Mor}(\mathbf{C})} \\ 
	& \text{Hom}(-, B ) : X \mapsto \text{Hom}(X,A) \\ 
	& \text{Hom}(-, B ) : \text{Mor}\mathbf{C} \to (\text{Mor}(\mathbf{C}) \to \text{Mor}(\mathbf{C})) \\
	& \text{Hom}(-, B ) : \text{Hom}(X,Y) \to (\text{Hom}(Y,B) \to \text{Hom}(X,B)) \\
	& \text{Hom}(-, B ) : h \mapsto \text{Hom}(h,B) \text{ where } \\
	& \begin{aligned} \text{Hom}(h,B) : & \text{Hom}(Y,B) \to \text{Hom}(X,B) \\ 
	& g\mapsto g\circ h \quad \, \forall \, g \in \text{Hom}(Y,B) 
	\end{aligned} 
	\end{aligned}
	\end{equation}
\end{definition}

$\text{Hom}(A,-)$, $\text{Hom}(-,B)$ are related in a natural manner: for
\[
\begin{gathered}
\begin{aligned}
& f : B\to B', \, f\in \text{Hom}(B,B') \\ 
& g:A \to A', \, g\in \text{Hom}(A,A')
\end{aligned} \\
\begin{aligned}
& \text{Hom}(A,f) : \text{Hom}(A, B) \to \text{Hom}(A,B') \\ 
& \text{Hom}(g, B) : \text{Hom}(A,B) \to \text{Hom}(A', B)
\end{aligned}
\end{gathered}
\]

\[
\begin{gathered}
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=4.8em, column sep=4.8em, minimum width=4.2em]
{
	\text{Hom}(A,B) & \text{Hom}(A',B) \\
	\text{Hom}(A,B') & \text{Hom}(A',B') \\
};
\path[->]
(m-1-1) edge node [above] {$\text{Hom}(g,B)$} (m-1-2)
 edge node [left] {$\text{Hom}(A,f)$} (m-2-1)
(m-1-2) edge node [right] {$\text{Hom}(A',f)$} (m-2-2)
(m-2-1) edge node [above] {$\text{Hom}(g,B')$} (m-2-2)
;
\end{tikzpicture}
\end{gathered}
\]

\begin{definition}[2-variable Hom functor]
	2-variable Hom functor $\text{Hom}(-,-)$ is a bifunctor.
	\[
	\text{Hom}(-,-) : \mathbf{C}^{\text{op}} \times \mathbf{C} \to \textbf{Set} 
	\]
	
\[
\begin{gathered}
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=4.8em, column sep=4.8em, minimum width=4.2em]
{
	& D \\
	C & B \\
	A &  \\
};
\path[->]
(m-2-1) edge node [left] {$f\circ g \circ h$} (m-1-2)
edge node [above] {$ g \circ h$} (m-2-2)
edge node [left] {$  h$} (m-3-1)
(m-2-2) edge node [right] {$f$} (m-1-2)
(m-3-1) edge node [right] {$g$} (m-2-2)
;
\end{tikzpicture}
\end{gathered}
\]

$\text{Hom}(-,-)$ is a functor such that:
\[
\begin{gathered}
\begin{aligned} 
& \text{Hom}(h, f)(g) = f\circ g \circ h \\
& \text{Hom}(h, f) : \text{Hom}(A, B) \to \text{Hom}(C, D) 
\end{aligned} \\
\begin{aligned}
& h : C \to A, \, h \in \text{Hom}(C,A) \\ 
& f: B\dot D, \, f \in \text{Hom}(B,D)
\end{aligned} \\
(h,f) \in \text{Hom}(C,A) \times \text{Hom}(B,D) \mapsto \text{Hom}(h,f) \in (\text{Hom}(A,B) \to \text{Hom}(C,D)) \\
\text{Hom}(-,-) : \text{Hom}(C,A) \times \text{Hom}(B,D) \to (\text{Hom}(A,B) \to \text{Hom}(C,D) )
\end{gathered}
\]
and 
\[
\begin{aligned}
& \text{Hom}(-,-) : \text{Obj}\mathbf{C}^{\text{op}} \times \mathbf{C} \\ 
& \text{Hom}(-,-) : (C,D) \mapsto \text{Hom}(C,D)
\end{aligned}
\]
\end{definition}


\section{Construction of Categories}

\subsection{Slice category}

cf. Construction 4 of Awodey (2010) \cite{Awod2010}, pp. 15.

\textbf{Slice category} $\mathbf{C}/C$, of category $\mathbf{C}$ over object $C \in \text{Obj}\mathbf{C}$, \\
$\text{Obj}\mathbf{C}/C \ni f \in \text{Mor}\mathbf{C}$ s.t. $\text{cod}(f) = C$ \\
$\text{Mor}\mathbf{C}/C \ni g$ from $f:X \to C$ to $f':X' \to C$ is a morphism (arrow) \, $g: X\to X'$ in $\mathbf{C}$ s.t. $f'\circ g = f$

\begin{equation}
\begin{gathered}
	\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=5em, column sep=5em, minimum width=2em]
{
	X & & X' \\
	& C &  \\
};
\path[->]
(m-1-1) edge node [above] {$g$} (m-1-3)
(m-1-1) edge node [below] {$f$} (m-2-2)
(m-1-3) edge node [below] {$f'$} (m-2-2);
\end{tikzpicture} \qquad \, 
	\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=5em, column sep=5em, minimum width=2em]
{
	X  \\
	C  \\
};
\path[->]
(m-1-1) edge node [left] {$f$} (m-2-2)
edge [loop right] node [right] {$1_{\mathbf{C}/C}$} (m-1-1);
\end{tikzpicture} \qquad \, 
	\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=5em, column sep=5em, minimum width=2em]
{
	X & X' & X'' \\
	& C &  \\
};
\path[->]
(m-1-1) edge node [above] {$g$} (m-1-2)
	edge node [left] {$f$} (m-2-1)
(m-1-2) edge node [above] {$h$} (m-1-3)
edge node [left] {$f'$} (m-2-2)
(m-1-3) edge node [right] {$f''$} (m-2-2);
\end{tikzpicture}
\end{gathered}
\end{equation}

If $\mathbf{C} = \mathbf{P}$ poset category, $p\in \mathbf{P}$ (i.e. $p \in \text{Obj}(\mathbf{P})$), then
\[
\mathbf{P} / p \simeq \downarrow (p)
\]
Slice category $\mathbf{P} / p$ is just the "principal ideal" $\downarrow(p)$ of elements $q\in \mathbf{P}$ with $q \leq p$.

\subsubsection{$S$-indexed set $X$ and indexed functions as morphisms of slice category $\mathbf{Set}/S$}

\begin{definition}[typed set]
	$S$-indexed set is set $X$ together with function $\tau : X \to S$. \\
	
	If $x\in X$, $\tau(x) = s$, then $x$ is of \textbf{type} $s$, so $X$ is a \textbf{typed set}. \\
	
	$\lbrace \tau^{-1}(s) | s \in S \rbrace$, $\tau^{-1}(s) \subset X \equiv $ family of sets indexed by $S$. \\
	
\end{definition} 
cf. 2.6.11 of Barr and Wells (2012) \cite{BaWe2012}

\begin{definition}
	set $X$ typed by $S \to $ set $X'$ typed by $S$ that preserves typing (element of type $s\mapsto $ element of type $s$), is exactly an arrow (morphism) of slice category $\mathbf{Set}/S$, called \textbf{indexed function} or \textbf{typed function}.
\end{definition}

cf. 2.6.13 Indexed functions of Barr and Wells (2012) \cite{BaWe2012}

\subsubsection{Underlying functor of the slice $F$}

Let $f: A\to C$, $f\in \text{Hom}(A,C) \subset \text{Mor}\mathbf{C}$ and $f\in \text{Obj}\mathbf{C}/C$.  \\

Let $f,g \in \text{Obj}\mathbf{C}/C$, s.t. $f\in \text{Hom}(A,C)$, $g\in \text{Hom}(B,C)$ \\
$h\in \text{Hom}(f,g) \subseteq \text{Mor}\mathbf{C}/C$ in that \\
$h : f\to g$ s.t. $h:A \to B$, so that $g\circ h = f$. \\

\textbf{underlying functor of the slice $F$} (notation $U$ in Barr and Wells (2012) \cite{BaWe2012}):

\begin{equation}
\begin{aligned}
& F: \mathbf{C} /C \to \mathbf{C} \\ 
& F:\text{Obj}\mathbf{C}/C \to \text{Obj}\mathbf{C} \\ 
& F:f\mapsto F(f) = A \\ 
& F:\text{Mor}\mathbf{C}/C \to \text{Mor}\mathbf{C} \\ 
& F: h \mapsto h 
\end{aligned} 
\end{equation}

Special case: $\mathbf{C} = \textbf{Set}$, $C = S \ni \text{Obj}\textbf{Set}$, i.e. $S$ is a set.

For $f\in \text{Obj}\textbf{Set}/S$, $f: T \to S$, where $T$ is a set, object $f$ is an $S$-indexed set. (e.g. $x(i) \in T \subset \mathbb{R}$, where for some $y\in T \subset \mathbb{R}$, $\exists \, i \in \mathbb{Z}$ s.t. $y\mapsto i$).

\[
\begin{aligned}
& F:\textbf{Set}/S \to \textbf{Set} \\ 
&  F:f \mapsto T
\end{aligned}
\]

The underlying functor $F$ forgets the $S$-indexing.

\subsubsection{Coslice category}

\[
	\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=5em, column sep=5em, minimum width=2em]
{
	X & & X' \\
	& C &  \\
};
\path[->]
(m-1-3) edge node [above] {$\overline{g}$} (m-1-1)
(m-2-2) edge node [below] {$\overline{f}$} (m-1-1)
 edge node [below] {$\overline{f'}$} (m-1-3);
\end{tikzpicture} 
\]

Coslice category $C/\mathbf{C}$ of category $\mathbf{C}$ under object $C \in \text{Obj}\mathbf{C}$: \\
$\text{Obj}(C/\mathbf{C}) = \overline{f} \in \text{Mor}\mathbf{C}$ s.t. $\text{dom}\overline{f} = \overline{C} = C$, \\
$\text{Mor}(C/\mathbf{C}) \ni \begin{aligned} & \quad \\ & \overline{g} : \overline{X}' \to \overline{X} \text{s.t. } \\
& \overline{g} \circ \overline{f'} = \overline{f} \end{aligned}$ 

cf. Example 1.8 of Awodey (2010) \cite{Awod2010}, pp. 15. \emph{pointed sets}

$\textbf{Sets}_*$ of pointed sets consisting of sets $A$ and distinguished element $a\in A$, and, i.e. \\
$\text{Obj}\textbf{Set}_* \ni $ set $A$ with distinguished element $a\in A$, \\
$\text{Mor}\textbf{Set}_* \ni f : (A, a) \to (B, b)$, function $f:A\to B$ preserves the "points" $f(a) = b$.

\[
\textbf{Sets}_* = \textbf{Set}_* \simeq 1 / \textbf{Sets}
\]
i.e. $\textbf{Sets}_*$ isomorphic to coslice category of sets "under" any singleton $1 = \lbrace * \rbrace$

\quad \\ 
functions $a: 1 \to A$ correspond uniquely to elements \\
\phantom{functions} $a(*) = a \in A$ \\
morphisms (arrows) $f:(A, a) \to (B, b)$ correspond exactly to 
\[
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=5em, column sep=4em, minimum width=3em]
{
	1 & A \\ 
	&  B   \\
};
\path[->]
(m-1-1) edge node [above] {$a$} (m-1-2)
edge node [left] {$b$} (m-2-2)
(m-1-2) edge node [auto] {$f$} (m-2-2)
;
\end{tikzpicture} 
\]

\subsection{Free monoid}

Given set $S$, e.g. $S = $ "alphabet" $A$, \\
\emph{free monoid} $S^*$ is set $S^*$. \\

$S^* = $ set of all lists (finite sequences) of elements of $S$, \\
e.g. set of all \emph{words} (finite sequence of letters) \emph{over $A$ } $= A^*$. \\

\emph{Concatenation}: $* : \, \forall \, w , w^* \in A^*$, $w * w' = ww'$ \\
empty list (e.g. empty word "-"), $()$, $*$, or $\epsilon$ is a unit. Or we'll use this notation: \texttt{""}

\[
\Longrightarrow (S^*, *, \texttt{""}) \text{is a monoid. }
\]

monoid $M$ is \textbf{freely generated} by subset $A$ of $M$, if 
\begin{enumerate}
	\item "no junk": $\forall \, m \in M$, $m$ can be written as product of elements of $A$,
	\[
	m = a_1 \dots a_n, \, a_i \in A 
	\]
	\item "no noise": no "nontrivial" relations hold in $M$, i.e. if $a_1 \dots a_j = a_1' \dots a_k'$, then this is required by the axioms for monoid.
\end{enumerate}

$A^* = $ Kleene closure.

\subsubsection{Free monoid functor: underlying functor}

\[
\begin{aligned}
& F: \textbf{Set} \to \textbf{Mon} \\
& F: A \in \text{Obj}\textbf{Set} \mapsto \text{ free monoid } F(A) = \text{ Kleene closure } A^* 
\end{aligned}
\]
For $f:A \to B$, $f\in \text{Hom}_{\textbf{Set}}(A, B)$, 
\[
\begin{aligned}
& F: f\mapsto F(f) \text{ s.t. } \\
& F(f)(w) = F(f)(a_1 \dots a_m) = (f(a_1), \dots f(a_m)) = w' \in B^*, \text{ i.e. } \\
& F(f) = f^* : F(A) \to F(B)
\end{aligned}
\]


\section{Universal mapping property}

\subsection{Examples of Universal mapping property}

cf. Ch. 0 "Introduction" of Leinster (2014) \cite{Lein2014}.

Example 0.1. Let $\lbrace 1 \rbrace$ denote set with 1 element. \\
Then $\forall \, $ sets $X \in \textbf{Set}$, $\exists \, ! $ map $X \to \lbrace 1 \rbrace$
\[
X \xrightarrow{ f} \lbrace 1 \rbrace 
\]

\begin{proof}
$\exists \, X \to \lbrace 1 \rbrace$, $\forall \, X$ because define $f: X \to \lbrace 1 \rbrace$ s.t. $f(x) = 1$, $\forall \, x \in X$. \\
(!) if for $X \to \lbrace 1 \rbrace$, then $x\mapsto 1$, so map is equal to $f$.
\end{proof} 

Example 0.2. $\forall \, $ rings $R$ with multiplicative identity $1$, $\exists \, !$ homomorphism $\mathbb{Z} \to R$. \label{Example:integerringhomomorphism}

Define $\phi : \mathbb{Z} \to R$ by 
\[
\phi(n) = \begin{cases}  \sum_{i=1}^n 1 & \text{ if } n > 0 \\ 
0 & \text{ if } n = 0 \\
-\phi(-n) & \text{if } n < 0 \end{cases} 
\]

Check that $\phi$ homomorphism. (TODO)\\

(!) $\psi(1)= 1$ (homomorphisms preserve multiplicative identities) \\
homomorphisms preserve addition:
\[
\psi(n) = \psi(\sum_{i=1}^n 1) = \sum_{i=1}^n \psi(1) = \sum_{i = 1}^n 1 = \phi(n)
\]

homomorphisms preserve zero: $\psi(0) = 0 = \phi(0)$

homomorphisms preserve negatives: $\psi(n) = -\psi(-n) = -\sum_{i=1}^{-n} 1 = -\phi(-n) = \phi(n)$.

\begin{lemma}[0.3 Leinster (2014) \cite{Lein2014}]
	Let ring $A$ s.t. $\forall \,$ rings $R, \exists \, !$ homomorphism $A \to R$ (i.e. $A$ is "initial"). Then $A \cong \mathbb{Z}$ (isomorphic). 	
\end{lemma}

\begin{proof}
		$A$ initial, so $\exists \, !$ homomorphism $\phi:A \to \mathbb{Z}$. \\
		$\mathbb{Z}$ initial from Ex. \ref{Example:integerringhomomorphism}. $\exists \, !$ homomorphism $\phi' : \mathbb{Z} \to A$. \\
		
		$\phi' \circ \phi : A \to A$, $1_A : A \to A$ are homomorphisms. \\
		Since $A$ initial, $\phi' \circ \phi = 1_A$. \\
		$\phi \circ \phi' : \mathbb{Z}\to \mathbb{Z}$.  Since $\mathbb{Z}$ initial, $1_{\mathbb{Z}} : \mathbb{Z} \to \mathbb{Z} \Longrightarrow \phi \circ \phi' = 1_{\mathbb{Z}}$. 
		\[
		\Longrightarrow A \cong \mathbb{Z} \text{ (isomorphic) }
		\]
\end{proof}

Example 0.4. pp. 3 Leinster (2014) \cite{Lein2014} Let vector space $V$ with basis $(v_s)_{s \in S}$ (.e.g if $V$ finite-dim., e.g. $S = \lbrace 1, 2 \dots , n \rbrace$).  \\
Thus $\forall \, $ vector space $W$, $\exists \, $ natural 1-to-1 correspondence between linear maps $\lbrace V \to W \rbrace$ and functions $S \to W$. \\
i.e. define $\begin{aligned} & \quad \\ 
& i : S \to V \\
& i(s) = v_s \quad \, (s \in S)\end{aligned}$ 

Then universal mapping property (given $i, f, \exists \, ! \overline{f}$)
\[
\begin{gathered} 
	\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=5em, column sep=4em, minimum width=3em]
{
	S & V  \\ 
	  & W   \\
};
\path[->]
(m-1-1) edge node [above] {$i$} (m-1-2)
 edge node [below] {$f$} (m-2-2)
;
\path[dashed,->]
(m-1-2)        edge node [right] {$\overline{f}$} (m-2-2)
;
\end{tikzpicture} \text{ or } \begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=5em, column sep=4em, minimum width=3em]
{
	V & W  \\ 
	S &    \\
};
\path[dashed,->]
(m-1-1) edge node [above] {$\overline{f}$} (m-1-2)
;
\path[->]
(m-2-1) edge node [left] {$i$} (m-1-1)
edge node [below] {$f$} (m-1-2)
;
\end{tikzpicture}
\end{gathered} 
\]

\[
\begin{gathered}
\begin{aligned}
\lbrace S \to W \rbrace & \to \lbrace \text{ linear } V \to W \rbrace \\
\overline{f} \circ i & \mapsto \overline{f} 
\end{aligned} \quad \, \text{ bijective }
\end{gathered}
\]

Example 0.5. pp. 4 Leinster (2014) \cite{Lein2014}. Given set $S$, topological space $D(S)$; equip $D(S)$ with discrete topology (all subsets open). \\
$\Longrightarrow \forall \, $ map $S \to $ space $X$ is cont. 

i.e. 
\[
\begin{gathered}
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=5em, column sep=4em, minimum width=3em]
{
	D(S) & X  \\ 
	S &    \\
};
\path[dashed,->]
(m-1-1) edge node [above] {$\overline{f}$} (m-1-2)
;
\path[->]
(m-2-1) edge node [left] {$i$} (m-1-1)
edge node [below] {$f$} (m-1-2)
;
\end{tikzpicture}
\end{gathered}
\]

$\forall \, $ topological space $X$, $\forall \, f : S \to X$, $\exists \, !$ cont. $\overline{f} : D(S) \to X$ s.t. $\overline{f} \circ i = f$. \\
If $D(S)$ equipped with indiscrete topology (open $S = \lbrace \phi, S \rbrace$), then property is false.

Example 0.6. pp. 4 Leinster (2014) \cite{Lein2014}. Given vector space $U, V, W$, bilinear map $f: U\times V \to W$ is linear. 
\[
\begin{gathered}
f(u, v_1 + \lambda v_2) = f(u, v_1) + \lambda f(u, v_2) \\
f(u_1 + \lambda u_2, v) = f(u_1, v) + \lambda f(u_2, v)
\end{gathered}
\]
$\forall \, u, u_1, u_2 \in U$, $v, v_1,v_2 \in V$, scalars $\lambda$. \\
e.g. scalar product (dot product) $\mathbf{u}\cdot \mathbf{v}$ bilniear, cross product bilinear. \\

$\exists \, $ "universal bilinear map out of $U\times V$", i.e. \\
$\exists \, $ vector space $T$, $\exists \, $ bilinear map $b:U\times V \to T$

\[
\begin{gathered}
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=5em, column sep=4em, minimum width=3em]
{
	T & W  \\ 
	U \times V &    \\
};
\path[dashed,->]
(m-1-1) edge node [above] {$\overline{f}$} (m-1-2)
;
\path[->]
(m-2-1) edge node [left] {$b$} (m-1-1)
edge node [below] {$f$} (m-1-2)
;
\end{tikzpicture}
\end{gathered}
\]
i.e. $\forall \, $ bilinear $f$, given $b$, $\exists \, !$ linear $\overline{f}$, s.t. $\overline{f} \circ b = f$

\begin{lemma}[0.7, pp. 5 Leinster (2014) \cite{Lein2014}]\label{Lemma:UniveralMappingVectorSpaceProducts}
	Let vector spaces $U, V$. Suppose $\begin{aligned} & \quad \\ 
	& b : U \times V \to T \\
	& b' : U\times V \to T'\end{aligned}$ \quad , both universal bilinear maps. 
	
	Then $T \cong T'$, i.e. $\exists \, !$ isomorphism $j: T \to T'$ s.t. $j\circ b = b'$
\end{lemma}

\begin{proof}
	Take $b': U\times V \to T' \Longrightarrow \exists \, b$, $\exists \, !$ linear map $j: T \to T'$ s.t. $j\circ b = b'$. 
	
	Take $b:U \times V \to T$. $\exists \, b'$, $\exists \, !$ linear map $j':T' \to T$ s.t. $j'\circ b' = b$
	

\[
\begin{gathered}
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=5em, column sep=4em, minimum width=3em]
{
	T & T'  \\ 
	U \times V & T   \\
};
\path[dashed,->]
(m-1-1) edge node [above] {$j$} (m-1-2)
(m-1-2) edge node [above] {$j'$} (m-2-2)
;
\path[->]
(m-2-1) edge node [left] {$b$} (m-1-1)
edge node [below] {$b'$} (m-1-2)
edge node [below] {$b$} (m-2-2)
;
\end{tikzpicture}
\end{gathered}
\]
Now linear $j'\circ j : T\to T$, s.t. $(j'\circ j) \circ b = b$. 

But also $1_T : T\to T$ linear and $1_T \circ b = b$

\[
\Longrightarrow j' \circ j = 1_T
\]
i.e. 
\[
\begin{gathered}
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=5em, column sep=4em, minimum width=3em]
{
	T & T  \\ 
	U \times V &    \\
};
\path[dashed,->]
(m-1-1) edge node [above] {$j'\circ j$} (m-1-2)
;
\path[->]
(m-2-1) edge node [left] {$b$} (m-1-1)
edge node [below] {$b$} (m-1-2)
;
\end{tikzpicture}
\qquad \, \text{ but so is } \begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=5em, column sep=4em, minimum width=3em]
{
	T & T  \\ 
	U \times V &    \\
};
\path[dashed,->]
(m-1-1) edge node [above] {$1_T$} (m-1-2)
;
\path[->]
(m-2-1) edge node [left] {$b$} (m-1-1)
edge node [below] {$b$} (m-1-2)
;
\end{tikzpicture}
\end{gathered}
\]

Similarly for $j\circ j' = 1_{T'}$. 

So $j$ is an isomorphism.

\end{proof} 

By Lemma \ref{Lemma:UniveralMappingVectorSpaceProducts}, $\exists \, !$ tensor product $U\otimes V$, not "a" tensor product.

Example 0.8 of Leinster (2014) \cite{Lein2014}. Let $\theta : G \to H$ be homomorphism of groups.

\[
\begin{tikzcd}
\text{ker}{(\theta)} \arrow[r, hook, "i"] & G \arrow[r, shift left, "\theta"] \arrow[r, shift right, "\epsilon"]& H \\
\end{tikzcd}
\]

where $i$ inclusion, $\epsilon$ trivial homomorphism, i.e.$i(x) = x \, \forall \, x \in \text{ker}(\theta)$, $\epsilon(g) = 1$ \, $\forall \, g \in G$.

map $i$ into $G$ s.t. $\theta \circ i = \epsilon \circ i$ and is universal (Ex. 0.11)

Example 0.9 of Leinster (2014) \cite{Lein2014}. Let topological space $X = U \cup V$ be covered by 2 open subsets $U, V$.

\[
\begin{tikzcd}[sep=large] 
	U \cap V \arrow[r, hook, "i"] \arrow[d, hook, "j"] & U \arrow[d, hook, "j'"] \\
	V \arrow[r, hook, "i'"] & X
\end{tikzcd}
\]
has universal property
\[
\begin{tikzcd}[sep=large] 
U \cap V \arrow[r, hook, "i"] \arrow[d, hook, "j"] & U \arrow[d, hook, "j'"] \arrow[ddr, "f"] & \\
V \arrow[r, hook, "i'"] \arrow[drr, "g"] & X \arrow[dr, dotted, "h"] & \\
& & Y 
\end{tikzcd}
\]
$\forall \, g, Y, f$ s.t. $f\circ i = g\circ j$, $\exists ! \, $ cont. $h: X\to Y$ s.t. $h\circ j' = f$, $h\circ i' = g$.

Under favorable conditions, induced diagram of fundamental groups.

\[
\begin{tikzcd}[sep=large] 
\pi_1(U \cup V) \arrow[r, "i_*"] \arrow[d, "j_*"] & \pi_1(U) \arrow[d, "j'_*"] \\
\pi_1(V) \arrow[r, "i'_*"] & \pi_1(X)
\end{tikzcd}
\]
has same universal property: Van Kampen's thm.

\[
\begin{aligned}
& \theta : G \to H \\ 
& \epsilon : G \to H
\end{aligned}
\]

$\theta, \epsilon$ have common domain and codomain.

$i: \text{ker}(\theta) \to G$ is s.t. $\theta \circ i = \epsilon \circ i$

\[
\begin{tikzcd}
\text{ker}{(\theta)} \arrow[r, hook, "i"] & G \arrow[r, shift left, "\theta"] \arrow[r, shift right, "\epsilon"]& H \\
J \arrow[u, dotted, "u"] \arrow[ur, "a"] & & \\
\end{tikzcd}
\]
$\forall \, a : J \to G$ s.t. $\theta \circ a = \epsilon \circ a$, then $\exists \, ! \, u : J \to \text{ker}{\theta}$ s.t. 
\[
a = i \circ u 
\]

\subsubsection{Free monoid $A^*$ on set $A$}

$\exists \, i : A \to A^*$, given any monoid $N$, any $f: A \to |N|$ (where $|N|$ is the underlying set of monoid $N$), \\
$\exists \, ! $ monoid homomorphism $\overline{f}: A^* \to N$ s.t. $|\overline{f}| \circ i = f$.


\[
\begin{aligned}
\textbf{Mon} : & 
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=5em, column sep=5em, minimum width=2em]
{
	A^* &  N \\
};
\path[->]
(m-1-1) edge [dotted] node [above] {$\overline{f}$} (m-1-2);
\end{tikzpicture}  \\
\quad \\ 
\textbf{Sets} : & \begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=5em, column sep=5em, minimum width=2em]
{
	\lvert A^* \rvert &  \lvert N \rvert \\
	A & \\
};
\path[->]
(m-1-1) edge [dotted] node [above] {$|\overline{f}|$} (m-1-2)
(m-2-1) edge node [left] {$i$} (m-1-1)
edge node [right] {$f$} (m-1-2);
\end{tikzpicture}  
\end{aligned} 
\]

\begin{proposition}[Proposition 1.9, Awoday (2010) \cite{Awod2010}]] $A^*$ has universal mapping property of free monoid on $A$.
	\end{proposition} 
\begin{proof}
	Givne $f: A \to |N|$, define $\overline{f} : A^* \to N$, by 
	\[
	\begin{aligned}
	& \overline{f}("") = e_N \\ 
	& \overline{f}(a_1 \dots a_n) = f(a_1) \dots f(a_n) 
	\end{aligned}
	\]	
	$\overline{f}$ is thus a homomorphism with $\overline{f}(a) = f(a)$ \quad \, $\forall \, a \in A$. \\
	
	If $g: A^* \to N$ s.t. $g(a) =f(a)$ \quad \, $\forall \, a \in A$, then $\forall \, (a_1, \dots a_n) \in A^*$, 
	\[
	\overline{f}(a_1 \dots a_n) = \overline{f}(a_1) \dots \overline{f}(a_n) = f(a_1) \dots f(a_n) = g(a_1) \dots g(a_n) = g(a_1 \dots a_n)
	\]
	since $\overline{f} = g$, $\overline{f}$ unique.
\end{proof} 

Existence part of UMP is "no noise." \\
Unique part of UMP is "no junk."

TODO Prop. 1.10, Awodey.






\exercisehead{1} cf. 3.1.23 Exercises of Barr and Wells (2012) \cite{BaWe2012}

Given semigroup $S$, construct monoid $M = S \cup \lbrace e \rbrace$, $e\notin S$. \\
Let $e=\lbrace S \rbrace$. \\
Multiplication in $M$ defined as 
\begin{enumerate}
	\item $xy \in S$ if $x,y \in S$ 
	\item $xe=ex = x \quad \, \forall \, x \in M$
\end{enumerate}
$M \equiv S^1$ in semigroup literature.

\begin{enumerate}
	\item $S^1$ is a monoid (Show). \\
	If $a,b,c \in S \subset M$, then $(ab)c = a(bc)$ (associative holds by definition of semigroup). \\
	$\forall \, a \in S$, $ae = ea =a$, by how we defined multiplication. \\
	$ee = ee =e $ by either definition, or that multiplication in semigroup $S$ is closed.
	\[
	\lbrace S \rbrace \lbrace S \rbrace = \lbrace S \rbrace \lbrace S \rbrace = \lbrace S \rbrace
	\]
	
	If for $a,b,c \in M$, any of $a,b$ or $c=e$, use multiplication to show equality for $(ab)c = a(bc)$; e.g.
	\[
	\begin{aligned}
	& (eb) c = (b)\cdot c = bc = e(bc) = bc \\ 
	& (ae) c = a\cdot c =a \cdot (ec) = a(ec)
	\end{aligned}
	\]
	$S^1$ is a monoid.
	\item 
\end{enumerate}

\section{Actions, Finite State Machines}

\begin{definition}
Let monoid $M$ with identity $1$, and a set $S$. \\
\textbf{action} of $M$ on $S$, $\alpha$, \\
\begin{equation}
\begin{aligned}
& \alpha : M \times S \to S \text{ s.t. } \\  
& \alpha(1,s) = s \quad \, \forall \, s \in S \\
& \alpha(mn, s) = \alpha(m, \alpha(n, s)) \quad \, \forall \, m,n \in M, \, s\in S
\end{aligned}
\end{equation}

Write $ms \equiv \alpha(m, s)$ then 
\[
\begin{gathered} 
1s = s \\
(mn) s = m (ns) \quad \, \forall \, m, n \in M, \, s \in S
\end{gathered}
\]
\end{definition}

\begin{definition}[equivariant map]
	Let monoid $M$ with actions on sets $S,T$. \\
	\textbf{equivariant map} $\phi:S \to T$ s.t. $m\phi(s) = \phi(ms)$
\end{definition}

Suppose 2 equivariant maps $\phi_{TS}$, $\phi_{UT}$, sets $S,T,U$ s.t. monoid $M$ has actions on $S,T,U$: 
\[
\begin{aligned}
& \phi_{TS} : S \to T \\ 
& \phi_{UT} : T \to U
\end{aligned}
\]

\[
m\phi_{UT} \circ \phi_{TS}(s) = m \phi_{UT}(\phi_{TS}(s)) = \phi_{UT}(m\phi_{TS}(s)) = \phi_{UT} \phi_{TS} (ms) 
\]

Let $\phi_{UT} \circ \phi_{TS} \equiv \phi_{US}$. $\phi_{US}$ equivariant.

Associativity: given equivariant maps 
\[
\begin{aligned}
& \phi_{TS} : S \to T \\ 
& \phi_{UT} : T \to U \\ 
& \phi_{VU} : U \to V 
\end{aligned}
\]

\[
m \phi_{VU} \phi_{UT} \phi_{TS}(s) = m \phi_{VU} (\phi_{UT} \phi_{TS}(s)) = \phi_{VU} (m \phi_{UT} \phi_{TS}(s)) = (\phi_{VU} \phi_{UT}) (\phi_{TS}(ms))
\]

Thus, equivariant maps obey associativity on $\forall \, S \in \text{Obj}(M-\mathbf{Act})$, (set $S$ that $M$ has action on) \\
category $M-\mathbf{Act}$, $\text{Obj}(M-\mathbf{Act}) = \lbrace \text{ sets that monoid $M$ has action on }\rbrace$ \\
\phantom{category $M-\mathbf{Act}$,} $\text{Mor}(M-\mathbf{Act}) = \lbrace \text{ equivariant maps $\phi$ s.t. } \forall \, m \in M, \, m\phi(s) = \phi(ms) \rbrace$.

\subsection{Actions as functors}

Let $\alpha$ action of monoid $M$ on set $S$. \\

Consider $\mathbf{C}(M)$ (monoid as a category; i.e. $\text{Obj}\mathbf{C}(M) = \lbrace M \rbrace, \, \text{Mor}\mathbf{C}(M) = M$). \\
action $\alpha$ determines function $F_{\alpha} : \mathbf{C}(M) \to \mathbf{Set}$, 
\begin{enumerate}
	\item $F_{\alpha}(*) = S \equiv F_{\alpha}(\lbrace M \rbrace ) = S$
	\item  $F_{\alpha}(m) = s \mapsto \alpha(m, s) \, \forall \, m \in M, s \in S$
\end{enumerate}
i.e.

\[
\begin{gathered}
\begin{aligned}
& F_{\alpha} : \text{Obj}\mathbf{C}(M) \to \text{Obj}\mathbf{Set} \\ 
& F_{\alpha} : \lbrace M \rbrace \mapsto S 
\end{aligned} \\
\begin{aligned}
& F_{\alpha} : \text{Mor}\mathbf{C}(M) \to \text{Mor}\textbf{Set} \\ 
& F_{\alpha} : m \mapsto (s\mapsto \alpha(m,s)) \in \text{Hom}(S,S)
\end{aligned}
\end{gathered}
\]

Barr and Wells (1998) \cite{BW1998} uses this notation: $\mathcal{M} = (A, S, s_0, \phi)$ for a "machine." Compare this to the notation used in these notes:
\[
\text{FSM} = (\Sigma, S, s_0, \delta)
\]

Take note that the finite set or input alphabet $A \equiv \Sigma$ is \textbf{not} a monoid. \\

$\forall \, $ string $\equiv $ finite sequence $\equiv $ "word" induces sequence of transitions in FSM starting at $s_0$, and ending on some final state; precisely, define
\[
\begin{aligned}
& \delta^* : \Sigma^* \times S \to S \\ 
& \delta^*("", s) = s \quad \, \forall \in s \in S \\ 
& \delta^*((a)w, s) = \delta(a, \delta^*(w,s)) \quad \, \forall \, s \in S, \, w\in \Sigma^*, \, a\in A
\end{aligned}
\]

Recall free monoid $\Sigma^*$, $(\Sigma^*, *, "")$ where $\Sigma^* \in \text{Obj}\mathbf{Set}$ is a set. \\

\begin{proposition}
	$\delta^*$ is an action of $\Sigma^*$ on $S$.
\end{proposition}

\begin{proof}
	Assume
	\[
	\delta^*(wv, s) = \delta^*(w, \delta^*(v,s))
	\]	
	then
	\[
	\begin{gathered}
		\delta^*((a)wv, s) = \delta(a, \delta^*(wv, s)) = \delta(a, \delta^*(w, \delta^*(v,s))) = \delta^*(aw, \delta^*(v,s)) 
	\end{gathered}
	\]
1st., 3rd. equalities from $\delta^*((a)w, s) = \delta(a, \delta^*(w,s))$ (definition of $\delta^*$). \\
2nd. equality is from inductive hypothesis.
\end{proof}

\textbf{recognizer} - subset $L\subseteq A^*$ of strings which drive FSM from $s_0$ (start state) to acceptor state, is then set of strings, or language, which is \textbf{recognized} by machine FSM, this is the machine as \textbf{recognizer}.

\textbf{transducer} - FSM outputs string of symbols (not necessarily in same alphabet) $\forall \, $ state it enters, or each transition it undergoes.

\subsection{Set-valued functors as actions}

cf. 3.2.6 of Barr and Wells (2012) \cite{BaWe2012}. 


\section{Products, Coproducts}

\subsection{Sources}

It appears Ad\'{a}mek, Herrlich, and Strecker (2004) \cite{AHS2004} defines \emph{sources} to simply give a name and formalize a tuple.  

\begin{definition}[source]
	\textbf{source} is a tuple: $(a, (f_i)_{i\in I})$, $f_i:A\to A_i$
\end{definition}

\subsection{Products}

\begin{definition}[Products]\label{Def:Products}
	
	(in Turi's notation \cite{Turi2001})
	
	Given objects $C_1,C_2$ of category $\mathbb{C}$, \textbf{product} (if exists) consists of object $C_1 \times C_2$ of $\mathbb{C}$ and $\begin{aligned} & \quad \\
	& \pi_1 : C_1 \times C_2 \to C_1 \\
	& \pi_2: C_1 \times C_2 \to C_2 \end{aligned}$ s.t. \\
	$\forall \, $ object $A$ of $\mathbb{C}$, \, $\forall \, \begin{aligned} & \quad \\
	& f : A \to C_1 \\
	& g : A \to C_2 \end{aligned}$ \quad \, $\exists \, ! \quad \, \langle f,g \rangle : A \to C_1 \times C_2$ s.t. $\begin{aligned} & \quad \\
	& f = \pi_1 \circ \langle f,g \rangle \\
	& g = \pi_2 \circ \langle f,g \rangle \end{aligned}$, i.e. 
	
	\begin{tikzpicture}
	\matrix (m) [matrix of math nodes, row sep=5em, column sep=4em, minimum width=3em]
	{
		& A & \\ 
		C_1  & C_1 \times C_2  &  C_2  \\
	};
	\path[->]
	(m-1-2) edge node [above] {$f$} (m-2-1)
	edge node [above] {$g$} (m-2-3)
	(m-2-2) edge node [below] {$\pi_1$} (m-2-1)
	edge node [below] {$\pi_2$} (m-2-3)
	;
	\path[dashed] 
	(m-1-2) edge node [right] {$\langle f,g\rangle$} (m-2-2)
	;
	\end{tikzpicture} 
	
	(compare with Leinster (2014) \cite{Lein2014})
	
	Let category $\mathcal{A}$, $X,Y \in \mathcal{A}$, \textbf{product} of $X,Y$ consists of object $P$ and maps
	
	(compare this definition with Ad\'{a}mek, Herrlich, and Strecker (2004) \cite{AHS2004} and their notation)
	
	\textbf{product} consisting of 
	\[
	\begin{aligned}
	C_1 \times C_2 \times \dots \times C_{\mathcal{N}} \in \text{Obj}\mathbf{C} \\
	\pi_1 : C_1 \times C_2 \times \dots \times C_{\mathcal{N}} \to C_1 \\ 
	\pi_2 : C_1 \times C_2 \times \dots \times C_{\mathcal{N}} \to C_2 \\ 
	\vdots \\
	\pi_{\mathcal{N}} : C_1 \times C_2 \times \dots \times C_{\mathcal{N}} \to C_{\mathcal{N}} \\ 
	\end{aligned}
	\]
	
	is s.t. 
	
	$\forall \, \begin{aligned}  \quad \\ 
	A \in \text{Obj}\mathbf{C} \\
	f_1 : A \to C_1 \\
	f_2 : A \to C_2 \\
	\vdots \\
	f_{\mathcal{N}} : A \to C_{\mathcal{N}} \end{aligned}$, 
	
	$\exists \, ! \langle f_1 ,f_2 , \dots , f_{\mathcal{N}} \rangle : A \to C_1 \times C_2 \times \dots \times C_{\mathcal{N}}$ s.t.
	\[
	\begin{aligned}
	f_1 = \pi_1 \circ \langle f_1 , f_2 , \dots f_{\mathcal{N}} \rangle \\ 
	f_2 = \pi_2 \circ \langle f_1 , f_2 , \dots f_{\mathcal{N}} \rangle \\ 
	\vdots  \\ 
	f_{\mathcal{N}} = \pi_{\mathcal{N}} \circ \langle f_1 , f_2 , \dots f_{\mathcal{N}} \rangle 
	\end{aligned}
	\]
\end{definition}

Let's use the notation of Ad\'{a}mek, Herrlich, and Strecker (2004) \cite{AHS2004}. Also note that these references \emph{assume} the \emph{universal mapping property} in the definition of a \textbf{product}.

\begin{definition}[Product (assuming univeral mapping property)]
	\begin{equation}
\begin{gathered}
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=4em, column sep=4em, minimum width=3em]
{
	& & A \\
	P & A_i & \\
	& A_{i'} & \\
};
\path[->]
(m-2-1) edge node [above] {$p_i$} (m-2-2)
edge node [above] {$p_{i'}$} (m-3-2)
(m-1-3) edge node [above] {$f_i$} (m-2-2)
edge node [above] {$f_{i'}$} (m-3-2)
;
\path[dashed,->]
(m-1-3) edge node [above] {$f$} (m-2-1)
;
\end{tikzpicture} 
\end{gathered}
\end{equation}
For the case of only 2 objects associated with $I$, 
	\begin{equation}
\begin{gathered}
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=5em, column sep=4em, minimum width=3em]
{
	& A  & \\ 
	A_1  & P  & A_2   \\
};
\path[->]
(m-1-2) edge node [above] {$f_1$} (m-2-1)
edge node [above] {$f_2$} (m-2-3)
(m-2-2) edge node [above] {$p_1$} (m-2-1)
edge node [above] {$p_2$} (m-2-3)
;
\path[dashed,->]
(m-1-2) edge node [right] {$f$} (m-2-2)
;
\end{tikzpicture} 
\end{gathered}
\end{equation}


\textbf{product} $P, \lbrace p_i, A_i \rbrace_{i\in I}$ s.t. $\forall \, A, \lbrace f_i, A_i \rbrace_{i \in I}$, $\exists \, !$ morphism $f:A \to P$ s.t. $f_i = p_i \circ f$, $i\in I$.
\end{definition}
This definition is the same one used in pp. 35, Def. 2.16, of Awodey (2010) \cite{Awod2010}.

Consider the definition that doesn't use the universal mapping property from Pareigis (2004) \cite{Pare2004}. 

\begin{definition}[Product without universal property]
	Given objects $A, B \in \text{Obj}\mathbf{C}$, category $\mathbf{C}$. 
	
	Object $A\times B$, morphisms $p_A, p_B$, $\begin{aligned} & \quad \\ 
		& p_A : A \times B \to A \\ 
		& p_B : A\times B \to B
		\end{aligned}$ is called a (not the) (categorical) product of $A, B$, projections $p_A, p_B$. 
		
		If $\forall \, $ object $T\in \text{Obj}\mathbf{C}$, $\exists \, $ isomorphism

		\begin{equation}
			\text{Mor}_{\mathbf{C}}(T, A \times B)  \cong \text{Mor}_{\mathbf{C}}(T, A) \times \text{Mor}_{\mathbf{C}}(T,B)		
		\end{equation}
(where $\text{Mor}_{\mathbf{C}}$ is the Cartesian product) s.t.

\begin{equation}\label{Eq:ProductDefinitionWithoutUniversalPropertyDiagram}
\begin{gathered}
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=5em, column sep=5em, minimum width=4em]
{
	& \text{Mor}_{\mathbf{C}}(T, A\times B)  & \\ 
	\text{Mor}_{\mathbf{C}}(T, A)  & \text{Mor}_{\mathbf{C}}(T, A) \times \text{Mor}_{\mathbf{C}}(T, B)  & \text{Mor}_{\mathbf{C}}(T, B)   \\
};
\path[->]
(m-1-2) edge node [left] {$\text{Mor}_{\mathbf{C}}(T,p_A)$} (m-2-1)
edge node [right] {$\text{Mor}_{\mathbf{C}}(T,p_B)$} (m-2-3)
(m-2-2) edge node [above] {$p_{\text{Mor}_{\mathbf{C}}(T, A)}$} (m-2-1)
edge node [above] {$p_{\text{Mor}_{\mathbf{C}}(T, B)}$} (m-2-3)
;
\path[dashed,->]
(m-1-2) edge node [right] {$h$} (m-2-2)
;
\end{tikzpicture} \\
\quad \\ 
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=5em, column sep=5em, minimum width=4em]
{
	& u  & \\ 
	f  & h(u) = (f,g)  & g   \\
};
\path[|->]
(m-1-2) edge node [left] {$\text{Mor}_{\mathbf{C}}(T,p_A)$} (m-2-1)
edge node [right] {$\text{Mor}_{\mathbf{C}}(T,p_B)$} (m-2-3)
(m-2-2) edge node [above] {$p_{\text{Mor}_{\mathbf{C}}(T, A)}$} (m-2-1)
edge node [above] {$p_{\text{Mor}_{\mathbf{C}}(T, B)}$} (m-2-3)
;
\path[dashed,|->]
(m-1-2) edge node [right] {$h$} (m-2-2)
;
\end{tikzpicture} 
\end{gathered}
\end{equation}
where $\begin{aligned} & \quad \\ 
& \text{Mor}_{\mathbf{C}}(T, p_A)(u) = f = p_{\text{Mor}_{\mathbf{C}}(T, A)} h(u) \\
& \text{Mor}_{\mathbf{C}}(T, p_B)(u) = g = p_{\text{Mor}_{\mathbf{C}}(T, B)} h(u) \end{aligned}$
\end{definition}

\begin{proposition}[Equivalent definition of product by universal mapping property]
Given objects $A, B \in \text{Obj}\mathbf{C}$, category $\mathbf{C}$, object $A\times B$, morphisms $\begin{aligned} & \quad \\ 
	p_A: A\times B \to A \\
	p_B: A\times B \to B \end{aligned}$ is a (categorical) product, \\
	
iff $\forall \, $ object $T \in \text{Obj}\mathbf{C}$, $\forall \, \begin{aligned} & \quad \\ 
& f: T\to A \\
& g: T \to B \end{aligned}$, $\exists \, !$ morphism $(f,g) : T \to A\times B$, s.t. 

\begin{equation}
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=5em, column sep=4em, minimum width=3em]
{
	& T  & \\ 
	A  & A\times B  & B   \\
};
\path[->]
(m-1-2) edge node [left] {$f$} (m-2-1)
edge node [right] {$g$} (m-2-3)
(m-2-2) edge node [above] {$p_A$} (m-2-1)
edge node [above] {$p_B$} (m-2-3)
;
\path[dashed,->]
(m-1-2) edge node [left] {$(f,g)$} (m-2-2)
;
\end{tikzpicture} 
\end{equation}	
\end{proposition}
cf. Proposition "Characterization of products by universal mapping property", 2.7.4 in Pareigis (2004) \cite{Pare2004}.

\begin{proof}
$\Longleftarrow$ : \\

	Let $(A\times B, p_A, p_B)$ be a "product" of $A\times B$, obeying the universal (mapping) property. Let $T\in \text{Obj}\mathbf{C}$. Let $u\in \text{Mor}_{\mathbf{C}}(T, A\times B)$. \\
	
	Define $\begin{aligned} & \quad  \\
	& f:= p_A \circ u : T \to A \\ 
	& g:= p_b \circ u : T \to B\end{aligned}$  \\
	Then $(f,g) \in \text{Mor}_{\mathbf{C}}(T,A) \times \text{Mor}_{\mathbf{C}}(T,B)$. \\
	
	Define $h(u):= (f,g) \in \text{Mor}_{\mathbf{C}}(T,A) \times \text{Mor}_{\mathbf{C}}(T,B)$. \\
	Then, 
	\[
	\begin{aligned}
		& \text{Mor}_{\mathbf{C}}(T,p_A)(u) = p_A \circ u = f = p_{\text{Mor}_{\mathbf{C}}(T,A)} \circ h(u) \\	
		& \text{Mor}_{\mathbf{C}}(T,p_B)(u) = p_B \circ u = g = p_{\text{Mor}_{\mathbf{C}}(T,B)} \circ h(u) \\	
	\end{aligned}	
	\]
	(so Diagram \ref{Eq:ProductDefinitionWithoutUniversalPropertyDiagram} commutes). \\
	
	Show: $h$ bijective. \\
	Construct inverse map $k$:
	\[
	\begin{aligned}
		& k : \text{Mor}_{\mathbf{C}}(T,A) \times \text{Mor}_{\mathbf{C}}(T,B) \to \text{Mor}_{\mathbf{C}}(T,A\times B) \\
		& k((f,g))  := u
	\end{aligned}
	\]
	where $(f,g) \in \text{Mor}_{\mathbf{C}}(T,A) \times \text{Mor}_{\mathbf{C}}(T,B)$
	
	By universal (mapping) property, $\exists \, ! \, u :T\to A\times B$ s.t. $\begin{aligned} & \quad \\ 
	& p_A \circ u=f \\
	& p_B \circ u = g \end{aligned}$.
	
	Let $(f,g) \in \text{Mor}_{\mathbf{C}}(T,A) \times \text{Mor}_{\mathbf{C}}(T,B)$. \\
	Then $(h\circ k)((f\circ g)) = h(u) = (p_A\circ u, p_B \circ u) = (f,g)$. Hence $h\circ k =1$ or i.e. $h\circ k 1_{\text{Mor}_{\mathbf{C}}(T,A) \times \text{Mor}_{\mathbf{C}}(T,B)}$. \\
	
	Let $u\in \text{Mor}_{\mathbf{C}}(T,A\times B)$. \\
	Then $(k\circ h)(u) = k((f, g)) = k((p_A \circ u, p_B \circ u))= u'$ where $u':T\to A\times B$ and \\
	\[
	\begin{aligned} 
	& p_A \circ u' = p_A \circ k((p_A \circ u, p_B \circ u)) = p_A \circ k ((f,g)) = p_A \circ u \quad \, (\text{since $k((f,g)) := u$}) \\
	& p_B \circ u' = p_B \circ k((p_A \circ u, p_B \circ u)) = p_B \circ k ((f,g)) = p_B \circ u \quad \, (\text{since $k((f,g)) := u$}) 
	\end{aligned} 
	\]
	2nd. equality is by universal (mapping) property.

$\Longrightarrow u= u'$ (by component-wise equality), and \\
$k\circ h = 1_{\text{Mor}_{\mathbf{C}}(T,A\times B)}$. \\
$\Longrightarrow h$ isomorphic. \\

$\Longrightarrow$ : \\

Given morphisms
\[
\begin{aligned}
& f:T \to A \\ 
& g:T \to B
\end{aligned}
\]
then $(f, g) \in \text{Mor}_{\mathbf{C}}(T, A) \times \text{Mor}_{\mathbf{C}}(T,B)$.

$\forall \, $ object $T\in \text{Obj}\mathbf{C}$, $\exists \, $ isomorphism $h$ s.t. $\text{Mor}_{\mathbf{C}}(T, A\times B) \cong \text{Mor}_{\mathbf{C}}(T,A) \times \text{Mor}_{\mathbf{C}}(T,B)$, \\
Then $u:=h^{-1}((f, g))$ is a unique morphism, $u\in \text{Mor}_{\mathbf{C}}(T, A\times B)$. \\
Also, by Diagram \ref{Eq:ProductDefinitionWithoutUniversalPropertyDiagram}, 
\[
\begin{aligned}
& \text{Mor}_{\mathbf{C}}(T,p_A)(u) = f = p_{\text{Mor}_{\mathbf{C}}(T,A)} \circ h(u) \\ 
& \text{Mor}_{\mathbf{C}}(T,p_B)(u) = f = p_{\text{Mor}_{\mathbf{C}}(T,B)} \circ h(u) 
\end{aligned}
\]

Now
\[
\begin{aligned}
& \text{Mor}_{\mathbf{C}}(T, p_A)(u) = p_A \circ u \\
& \text{Mor}_{\mathbf{C}}(T, p_B)(u) = p_B \circ u \\
\end{aligned}
\]
(by definition).

So
\[
\begin{aligned} 
& f = p_A \circ u \\ 
& g = p_B \circ u
\end{aligned} 
\]
So universal mapping property is satisfied.
\end{proof}

Thus,

\begin{definition}[Product, generalized, assuming universal property]
	Give $A_i \in \text{Obj}\mathbf{C}$, $i\in I$, category $\mathbf{C}$, \\
	\textbf{product} is object $\prod_{i \in I} A_i \in \text{Obj}\mathbf{C}$, morphisms $p_j : \prod_{i\in I} A_i \to A_j$, $j\in I$, \\
	s.t. $\forall \, $ object $A\in \in \text{Obj}\mathbf{C}$, \\
	$\exists \, !$ morphism $\langle f_i \rangle : A \to \prod_{i\in I} A_i$, \\
	s.t. 
\begin{equation}\label{Eq:GeneralizedProductDiagram}
	\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=5em, column sep=4em, minimum width=3em]
{
	& A  \\ 
	A_j  & \prod_{i\in I} A_i   \\
};
\path[->]
(m-1-2) edge node [left] {$f_j$} (m-2-1)
(m-2-2) edge node [below] {$p_j$} (m-2-1)
;
\path[dashed,->]
(m-1-2)        edge node [right] {$\langle f_i \rangle$} (m-2-2)
;
\end{tikzpicture}  
\end{equation} 	
i.e. $\pi_j \circ \langle f_i \rangle = f_j \, \forall \, i,j \in I$
\end{definition}

\subsubsection{Example: Set always has products}

$\forall \, $ sets $X,Y \in \text{Obj}(\text{Set})$, $\exists \, $ product $X\times Y \in \text{Obj}(\text{Set})$.  

Let $A \in \text{Obj}(\text{Set})$, $\begin{aligned} & \quad \\
& f_1 : A \to X \\
& f_2 : A \to Y \end{aligned}$ \qquad \, Define $\begin{aligned} & \langle f_1, f_2 \rangle : A \to X \times Y  \\
& \langle f_1 ,f_2 \rangle (a) = (f_1(a), f_2(a)) \end{aligned}$

Then $\begin{aligned} & \quad \\
& \pi_1 \circ \langle f_1 , f_2 \rangle (a) = f_1(a) \\
& \pi_2 \circ \langle f_1, f_2 \rangle (a) = f_2(a) \end{aligned}$ \qquad \, $\Longrightarrow \begin{aligned}  & \quad \\
& \pi_1 \circ \langle f_1 , f_2 \rangle = f_1 \\
& \pi_2 \circ \langle f_1,f_2 \rangle = f_2 \end{aligned}$

Suppose $f': A \to X\times Y$ s.t. $\begin{aligned} & \quad \\
& \pi_1 \circ f' = f_1 \\
& \pi_2 \circ f' = f_2 \end{aligned}$

Write $f'(a) = (x,y)$
\[
\begin{aligned}
& f_1(a) = \pi_1 \circ f'(a) = \pi_1(x,y) =x \\ 
& f_2(a) = \pi_2 \circ f'(a) = \pi_2(x,y) =y \\ 
\end{aligned} \qquad \, \Longrightarrow f'(a) = (f_1(a), f_2(a)) = \langle f_1, f_2 \rangle (a)
\]
$\langle f_1, f_2 \rangle $ unique.  

\subsubsection{Example: "Record Types", classes (in computer science, C++, Python)}\label{SubSubSec:RecordTypesProduct}

cf. pp. 174, 5.3.14 "Record Types" Barr and Wells (1998) \cite{BW1998}.

Look at Diagram \ref{Eq:GeneralizedProductDiagram} again.

To allow operations depending on several variables in a functional programming language $L$, \\
e.g. assume $\forall \,$ types $A_j$, $\forall \, j \in I$, language $L$ has record type $\prod_{i\in I} A_i$, and field selectors $p_j$
\[
p_j : \prod_{i\in I} A_i \to A_j
\]
Insist that any data in $\prod_{i\in I} A_i$ be determined completely by those fields $A_j$, $j\in I$, \\
then $\forall \, $ operations $f_j$, $f_j : A \to A_j$, \, $\forall \, j \in I$, \\
there ought to be an unique operation $\lbrace f_i \rangle : A \to \coprod_{i\in I} A_i$ s.t. 
\[
p_j\langle f_i \rangle = f_j, \quad \, \forall \, i, j \in I
\]
This would make $\prod_{i\in I} A_i$ the product of $A_i$'s, with selectors as product projections.

Thus, to say that one can always construct record types in a functional programming language $L$ to say that the corresponding category $C(L)$ has finite products. 


\begin{proposition}
	If product $(A_1 \times \dots \times A_{\mathcal{N}} \xrightarrow{ \pi_i } A_i )_{i\in I}$, if $\exists \,  i_0 \in I$ s.t. $\text{Hom}(A_{i_0}, A_i) \neq \emptyset$, \, $\forall \, i \in I$, \\
	then $\pi_{i_0}$ \emph{retraction }
\end{proposition}

\begin{proof}
	$\forall \, i \in I$, choose $f_i \in \text{Hom}(A_{i_0}, A_i)$ with $f_{i_0} = 1_{A_{i_0}}$.  
	
	Then $\langle f_i \rangle : A_{i_0} \to A_1 \times \dots \times A_{\mathcal{N}}$ is a morphism s.t. 
	\[
	\pi_{i_0} \circ \langle f_i \rangle = f_{i_0} = 1_{A_{i_0}}
	\]
\end{proof}


Ad\'{a}mek, Herrlich, and Strecker (2004) \cite{AHS2004} and their notation) calls a \textbf{sink} what Leinster (2014) \cite{Lein2014} calls a \textbf{cocone}.  
\begin{definition}
	\textbf{sink} $((f_i)_{i\in I}, A) \equiv (f_i , A)_I \equiv (A_i \xrightarrow{ f_i } A)_I$, object $A$, family of morphisms $f_i : A_i \to A$
\end{definition}

For the \emph{coproduct}, consider this enlightening comparision:
\[
\begin{aligned}
\begin{gathered}
\text{ product } ( \prod_{i\in I } A_i, \pi_j )_{j \in I} \\ 
\text{ projection } \pi_j : \prod_{i\in I} A_i \to A_j  \\
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=5em, column sep=4em, minimum width=3em]
{
	& A  \\ 
	A_j  & \prod_{i\in I} A_i   \\
};
\path[->]
(m-1-2) edge node [above] {$f_j$} (m-2-1)
edge node [right] {$\langle f_i \rangle$} (m-2-2)
(m-2-2) edge node [below] {$\pi_j$} (m-2-1)
;
\end{tikzpicture}  \\
C\xrightarrow{ \langle f, g \rangle } A\times B \\
\prod_{i \in I } f_i  \, , \text{ or if } i = \lbrace 1,2 \rbrace, \, f\times g
\end{gathered} & \qquad \, 
\begin{gathered}
\text{ coproduct } ( \mu_j, \coprod_{i\in I } A_i  )_{j \in I} \\ 
\text{ injection } \mu_j : A_j \to \coprod_{i\in I} A_i  \\
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=5em, column sep=4em, minimum width=3em]
{
	& A  \\ 
	A_j  & \coprod_{i\in I} A_i   \\
};
\path[->]
(m-2-1) edge node [above] {$f_j$} (m-1-2)
edge node [above] {$\mu_j$} (m-2-2)
(m-2-2) edge node [right] {$[f_i]$} (m-1-2)
;
\end{tikzpicture}  \\
C\xleftarrow{ [ f, g ] } A +  B \\
\coprod_{i \in I } f_i  \, , \text{ or if } i = \lbrace 1,2 \rbrace, \, f +  g
\end{gathered}
\end{aligned}
\]

\subsubsection{Examples (of coproducts)} 

\begin{itemize}
	\item if $(A_i)_I$ pairwise-disjoint family of sets, then $(\mu_j, \bigcup_{i\in I} A_i)_{j\in I}$ is coproduct in $\text{Set}$.  \\
	If $(A_i)_I$ arbitrary set-indexed family of sets, then it can be ``made disjoint'' by pairing each $A_i$ with index $i$, i.e. by working with $A_i \times \lbrace i \rbrace$ rather than $A_i$.  
	
	So $\bigcup_{i\in I } (A_i \times \lbrace i \rbrace)$ disjoint.  Consider 
	\[
	\begin{aligned}
	&  \mu_j : A_j \to \bigcup_{i \in I} A_i \times \lbrace i \rbrace \\ 
	&  \mu_i(a) = (a,j)
	\end{aligned}
	\]
	$(\mu_j, \bigcup_{i\in I} A_i \times \lbrace i \rbrace )_{j\in I}$ is a coproduct in $\text{Set}$.  
	
	Indeed, given $\begin{aligned} & \quad \\
	& f_j:A_j \to A \\
	& f_j(a) \in A \end{aligned}$, 
	\[
	\begin{aligned}
	& [f_i] : \coprod_{i\in I} A_i \times \lbrace i \rbrace \to A \\ 
	& [f_i]\circ \mu_j = f_j 
	\end{aligned}
	\]
	where
	\[
	f_j(a) = [f_i]\circ \mu_j(a) = [f_i](a,j) = f_j(a)
	\]
	\item  $\text{Top}$ coproducts are ``topological sums''; they're ``concrete'' coproducts (Ad\'{a}mek, Herrlich, and Strecker (2004) \cite{AHS2004})
	\item $\text{Vec}$ (nonconcrete) coproducts called \emph{direct sums}
	
	direct sum $\bigoplus_{i\in I} A_i$ of vector spaces $A_i$ is subspace of direct product $\prod_{i\in I} A_i$ \\
	consisting of all elements $(a_i)_{i\in I}$ with finite carrier (i.e. $\lbrace i \in I | a_i \neq 0 \rbrace$ is finite), \\
	\qquad injections \[
	\begin{aligned} & \quad \\
	& \mu_j : A_j \to \bigoplus_{i\in I } A_i  \\
	& \mu_j(a) = (a_i)_{i\in I} \text { with } a_i = \begin{cases} a & \text{ if } i = j  \\ 0 & \text{ if } i \neq j \end{cases}
	\end{aligned}
	\]
	
	\item $\text{Grp}$ has nonconcrete coproducts, ``free products''
\end{itemize}

\section{Naturality; Natural transformations}

\begin{definition}[Natural Transformation]\label{Def:NaturalTransformation}
	If functors $F,G$, categories $\mathbf{C}, \mathbf{D}$, 
	\[
	\begin{aligned}
	& F:\mathbf{C} \to \mathbf{D} \\ 
	& G:\mathbf{C} \to \mathbf{D} 
	\end{aligned}
	\]
	the \textbf{natural transformation} $\eta$ from $F$ to $G$ is a family of morphisms s.t. \\
	
	\begin{enumerate} 
		\item $\forall \, X \in \text{Obj}\mathbf{C}$, $\eta_X : F(X) \to G(X)$ s.t. $F(X), G(X) \in \text{Obj}\mathbf{D}$. morphisms $\eta_X \in \text{Hom}_{\mathbf{D}}(F(X), G(X)) \subset \text{Mor}\mathbf{D}$ is called \textbf{component} of $\eta$ at $X$.
		\item components must be s.t. $\forall \, $ morphism $f: X \to Y$ in $\mathbf{C}$, i.e. $f\in \text{Hom}_{\mathbf{C}}(X, Y) \in \text{Mor}\mathbf{C}$, 
		\begin{equation}
		\eta_Y \circ F(f) = G(f) \circ \eta_X
		\end{equation} 
		i.e. 
		\[
		       \begin{tikzpicture}
		\matrix (m) [matrix of math nodes, row sep=5em, column sep=5em, minimum width=2em]
		{
			       F(X) & F(Y) \\
			       G(X) & G(Y) \\
			};
		\path[->]
		(m-1-1) edge node [above] {$F(f)$} (m-1-2)
		edge node [auto] {$\eta_X$} (m-2-1)
		(m-1-2) edge node [auto] {$\eta_Y$} (m-2-2)
		(m-2-1) edge node [auto] {$G(f)$} (m-2-2);
		\end{tikzpicture}
		\]
		
		If both $F,G$ contravariant, 
		\[
		\begin{tikzpicture}
		\matrix (m) [matrix of math nodes, row sep=5em, column sep=5em, minimum width=2em]
		{
			       F(X) & F(Y) \\
			       G(X) & G(Y) \\
			};
		\path[->]
		(m-1-2) edge node [above] {$F(f)$} (m-1-1)
		(m-1-1) edge node [auto] {$\eta_X$} (m-2-1)
		(m-1-2) edge node [auto] {$\eta_Y$} (m-2-2)
		(m-2-2) edge node [auto] {$G(f)$} (m-2-1);
		\end{tikzpicture}
		\]
		\end{enumerate} 
	\end{definition}
cf. \href{https://en.wikipedia.org/wiki/Natural_transformation}{Wikipedia, "Natural transformation"}

Notation: natural transformation from $F$ to $G$, $\eta:F \to G$, i.e. family of morphisms $\eta_X : F(X) \to G(X)$ is natural in $X$.

cf. Ad\'{a}mek, Herrlich, and Strecker (2004) \cite{AHS2004}.  \\

From pp. 16, Sec. 14 "Natural Transformations", Mac Lane (1978) \cite{MacL1978}, \\

$\forall \,$ arrow $f: C \to C'$ in $C$, i.e. notation: $\forall \, $ morphism $f:X \to Y$ in $\mathbf{C}$, 

Mac Lane's notation:
\[
\begin{gathered}
\begin{tikzcd} 
c \arrow{d}{f} \\
c'
\end{tikzcd} \qquad \, 
\begin{tikzcd}
Sc \arrow{d}{Sf} \arrow{r}{\tau c} & Tc \arrow{d}{Tf} \\
Sc' \arrow{r}{\tau c'} & Tc'
\end{tikzcd}
\end{gathered}
\]

My notation:
\[
\begin{gathered}
\begin{tikzcd} 
X \arrow{d}{f} \\
Y
\end{tikzcd} \qquad \,
\begin{tikzcd}
FX \arrow{d}{Ff} \arrow{r}{\eta_X} & GX \arrow{d}{Gf} \\
FY \arrow{r}{\eta_Y} & GY
\end{tikzcd}
\end{gathered}
\]

We say that $\tau_c : Sc \to Tc$ is natural in $C$; $\eta_X : FX \to GX$ is natural in $X$. \\

If we think of functor $S$ as giving a picture in $B$ of (all the objects, arrows of) $C$, then \\
natural transformation $\tau$ is set of arrow $s$ mapping (or, translating) the picture $S$ to picture $T$, with all squares (and parallelograms!) like that above commutative:

Mac Lane's notation:
\[
\begin{gathered}
\begin{tikzcd}
a \arrow{dr}{f} \arrow{dd}{h} & \\
& b \arrow{dl}{g} \\ 
c & 
\end{tikzcd} \qquad \, 
\begin{tikzcd}
Sa \arrow{dr}{Sf} \arrow{dd}{Sh} \arrow{rr}{\tau a} & & Ta \arrow[dd, crossing over]{} \arrow{dr}{Tf} &  \\
& Sb \arrow{dl}{Sg} \arrow{rr}[swap, pos=0.2]{\tau b} & & Tb \arrow{dl}{Tg} \\ 
Sc \arrow{rr}{\tau c} & & Tc & 
\end{tikzcd} 
\end{gathered}
\]

My notation:
\[
\begin{gathered}
\begin{tikzcd}
X \arrow{dr}{f} \arrow{dd}{g} & \\
& Y \arrow{dl}{h} \\ 
Z & 
\end{tikzcd} \qquad \,
\begin{tikzcd}
FX \arrow{dr}{Ff} \arrow{dd}{Fg} \arrow{rr}{\eta_X} & & GX \arrow[dd, crossing over]{} \arrow{dr}{Gf} &  \\
& FY \arrow{dl}{Fh} \arrow{rr}[swap, pos=0.2]{\eta_Y} & & GY \arrow{dl}{Gh} \\ 
FZ \arrow{rr}{\eta_Z} & & GZ & 
\end{tikzcd} 
\end{gathered}
\]

\emph{natural equivalence} or i.e. natural isomorphism - natural transformation $\tau$ with $\forall \, $ component $\tau c$ invertible in $B$, $\tau : S \cong T$.  \\
notation: $\eta$ with $\forall \, $ component $\eta_X$ invertible in $\mathbf{D}$; $\eta : F \cong G$. \\
$\Longrightarrow $ inverses $(\tau c)^{-1}$ in $B$ are components of natural isomorphism $\tau^{-1} :T \to S$. \\
notation: inverses $(\eta_X)^{-1}$ in $\mathbf{D}$ are components of natural isomorphism $\eta^{-1}: G\to F$. 


\subsection{Examples of Natural transformations}

e.g. Hurewicz homomorphism $\pi_n(X) \to H_n(X)$ $\forall \, $ topological space $X$ is a natural transformation from $n$th homology functor. \\
$\pi_n : \textbf{Top} \to \mathbf{Grp}$ to $n$th homology functor $H_n : \textbf{Top} \to \textbf{Grp}$.

e.g. \textbf{determinant} $\det$ is a natural transformation (cf. Mac Lane (1978) \cite{MacL1978}). \\
Let $\det_KM = $ determinant of $n\times n$ matrix $M$, with entries in commutative ring $K$, while \\
$K^* \equiv $ group of units (invertible elements) of $K$ \\

Thus $M$ non-singular when $\det_KM$ is a unit, and $\det_K$ is a morphism $GL_nK \to K^*$ of groups. \\
Because $\det$ is defined by same formula $\forall \,$ ring $K$, each morphism $f: K \to K'$ of commutative rings leads to 
\[
\begin{tikzcd}
GL_nK \arrow{d}{GL_nf} \arrow{r}{\det_K} & K^* \arrow{d}{f^*} \\
GL_nK' \arrow{r}{\det_{K'}} & (K')^*
\end{tikzcd}
\]

$\Longrightarrow \det : GL_n \to ()^*$ is natural between 2 functors $\textbf{CRng} \to \textbf{Grp}$

TODO: Work out examples of natural transformations involving group commutators on pp. 17 of Mac Lane (1978) \cite{MacL1978}.

e.g. category $\textbf{Finord} = $ all finite ordinal numbers $n$ \\
category $\textbf{Set}_f = $ all finite sets (in some universe $U$) \\ 
$\forall \, $ ordinal $n = \lbrace 0 , 1 , \dots n-1 \rbrace$ is a finite set, so inclusion $S$ is a functor $S: \textbf{FinOrd} \to \textbf{Set}_f$ \\
$\forall \, $ finite set $X$ determines ordinal number $n = \# X$, number of elements in $X$ \\
$\forall \, X$, choose bijection $\theta_X:X \to \# X$ \\
$\forall \, $ function $f:X \to Y$, $X,Y$ finite sets, \\
Choose corresponding function $\# f : \# X \to \# Y$ between ordinals by $\# f = \theta_Y f \theta_X^{-1}$, so that 
\begin{equation}\label{Eq:NaturalIsomorphismOrdinalNumbersFiniteSets}
\begin{tikzcd}
X \arrow{d}{f} \arrow{r}{\theta_X} & \# X \arrow{d}{\# f} \\
Y \arrow{r}{\theta_Y} & \# Y
\end{tikzcd}
\end{equation}

$\Longrightarrow \# $ a functor $\# : \textbf{Set}_f \to \textbf{FinOrd}$ \\
If $X$ itself an ordinal number, take $\theta_X$ to be an identity. \\
$\Longrightarrow \# \circ S$ is identity functor $I'$ of $\textbf{FinOrd}$ \\
$S \circ \#$ is not identity functor $I : \textbf{Set}_f \to \textbf{Set}_f$ because \\
$S \circ \#$ sends each finite set $X$ to a special finite set - ordinal number $n$ with same number of elements as $X$. \\
However $\theta: I \to S \#$ is a natural isomorphism by square diagram above (Eq. \ref{Eq:NaturalIsomorphismOrdinalNumbersFiniteSets}).  
\[
I \cong S\circ \# , \quad \, I' = \# \circ S 
\]

equivalence between categories $\mathbf{C}, \mathbf{D} =$ \\
pair of functors $\begin{aligned} & \quad \\ 
& S : \mathbf{C} \to \mathbf{D} \\ 
& T : \mathbf{C} \to \mathbf{D} \end{aligned}$ and \\
natural isomorphisms $I_C \cong T \circ S$, $I_D \cong S \circ T$. 





\section{Limits}

\subsection{Pullback}

\begin{definition}
	For some category $\mathbf{A}$, and for 
	
	\begin{tikzpicture}
	\matrix (m) [matrix of math nodes, row sep=5em, column sep=5em, minimum width=2em]
	{
		& Y \\
		X & Z \\
	};
	\path[->]
	(m-1-2) edge node [right] {$t$} (m-2-2)
	(m-2-1) edge node [below] {$s$} (m-2-2);
	\end{tikzpicture}
	
	$X,Y,Z \in \text{Obj}\mathbf{A}$.  
	
	$\begin{aligned} & \quad \\
	& s : X \to Z \\
	& t: Y \to Z \end{aligned}$ ; \qquad \, $s,t \in \text{Mor}\mathbf{A}$
	
	Then the \textbf{pullback} or ``pullback square'' consists of $P \in \text{Obj}\mathbf{A}$, $\begin{aligned} & \quad \\
	& \pi_1 : P \to X \\
	& \pi_2: P \to Y \end{aligned}$ s.t. 
	
	\begin{tikzpicture}
	\matrix (m) [matrix of math nodes, row sep=5em, column sep=5em, minimum width=2em]
	{
		P & Y \\
		X & Z \\
	};
	\path[->]
	(m-1-1) edge node [above] {$\pi_2$} (m-1-2)
	edge node [auto] {$\pi_1$} (m-2-1)
	(m-1-2) edge node [auto] {$t$} (m-2-2)
	(m-2-1) edge node [auto] {$s$} (m-2-2);
	\end{tikzpicture}
	
	commutes and s.t. $\forall \, $ commutative square in $\mathbf{A}$ 
	
	\begin{tikzpicture}
	\matrix (m) [matrix of math nodes, row sep=5em, column sep=5em, minimum width=2em]
	{
		A & Y \\
		X & Z \\
	};
	\path[->]
	(m-1-1) edge node [above] {$f_2$} (m-1-2)
	edge node [auto] {$f_1$} (m-2-1)
	(m-1-2) edge node [auto] {$t$} (m-2-2)
	(m-2-1) edge node [auto] {$s$} (m-2-2);
	\end{tikzpicture}
	
	then $\exists \, ! \, f: A \to P$ s.t. 
	
	\begin{tikzpicture}
	\matrix (m) [matrix of math nodes, row sep=5em, column sep=5em, minimum width=2em]
	{
		A &   & \\ 
		& P & Y \\
		& X & Z \\
	};
	\path[->]
	(m-2-2) edge node [above] {$\pi_2$} (m-2-3)
	edge node [auto] {$\pi_1$} (m-3-2)
	(m-2-3) edge node [auto] {$t$} (m-3-3)
	(m-3-2) edge node [auto] {$s$} (m-3-3)
	(m-1-1) edge node [above] {$f_2$} (m-2-3)
	edge node [above] {$f$} (m-2-2)
	edge node [below] {$f_1$} (m-3-2);
	\end{tikzpicture}
	
	
\end{definition}

Simmons (2011) \cite{Simm2011}

cf. 3.3 \emph{Some less simple functors}, pp. 79, of Simmons (2011) \cite{Simm2011}

\section{Monads}

cf. Ch. 6, Monads and Algebras, starting on pp. 137 of Mac Lane (1971) \cite{MacL1978}.

\subsection{Monads in a Category}

\subsubsection{Development of a Monad}

Let's follow the development of a Monad according to Mac Lane (1971) \cite{MacL1978} starting on pp. 137 in Sec. 1. "Monads in a Category."

$\forall \, $ endofunctor $T: X \to X$, $T$ has composites $T^2 = T\circ T : X \to X$, $T^3 = T^2 \circ T:X \to X$ in Mac Lane's notation, $X$ is a category. In our notation, $\mathbf{C}$ denotes the category. And so for endofunctor $T: \mathbf{C} \to \mathbf{C}$, $T^2 = T\circ T: \mathbf{C} \to \mathbf{C}$, $T^3 = T^2 \circ T: \mathbf{C} \to \mathbf{C}$. 

Recall from Def. \ref{Def:Endofunctor}, that for endofunctor $T:\mathbf{C} \to \mathbf{C}$, the \emph{object map} $T: \text{Obj}{\mathbf{C}} \to \text{Obj}{\mathbf{C}}$ acts just like a morphism in $\text{Mor}{\mathbf{C}}$! So $T: X \to T(X)$ for $X, T(X) \in \text{Obj}{\mathbf{C}}$. Also, recall that the \emph{morphism map} $T: \text{Mor}_{\mathbf{C}} \to \text{Mor}_{\mathbf{C}}$ acts like the usual morphism map, such that $Tf : T(X) \to T(Y)$ if $f:X\to Y$, for $X,Y \in \text{Obj}{\mathbf{C}}$. \\

If $\mu:T^2 \to T$ is a \emph{natural transformation}, then recall the definition of the natural transformation, Def. \ref{Def:NaturalTransformation}, and apply that onto $\mu$. \\

$\forall \, X \in \text{Obj}{\mathbf{C}}$, $\mu_X: T^2(X) \to T(X)$ with $T^2(X), T(X) \in \text{Obj}{\mathbf{C}}$. $\mu_X$ is a morphism $\in \text{Hom}_{\mathbf{C}}(T^2(X), T(X))$ (!!), as well as being a component of $\mu$ at $X$. \\

$\forall \,$ morphism $f: X\to Z$ in $\mathbf{C}$, $X, Z \in \text{Obj}{\mathbf{C}}$ (the notation of using $Z$ to emphasize that $f$ can map $X$ to \emph{any} arbitrary object in $\text{Obj}{\mathbf{C}}$), 
\[
\mu_Z \circ T^2f = Tf \circ \mu_X 
\]
i.e. 
\[
\begin{tikzcd}
	T^2(X) \arrow{d}{T^2f} \arrow{r}{\mu_X} & T(X) \arrow{d}{Tf} \\
	T^2(Z) \arrow{r}{\mu_Z} & T(Z)
\end{tikzcd}
\]

Let $T\mu : T^3 \to T^2$ \emph{denote} a natural transformation with components $(T\mu)_X = T(\mu_X) : T^3(X) \to T^2(X)$, \\
while $\mu T: T^3\to T^2$ denotes another natural transformation with components $(\mu T)_X  = \mu_{T(X)}$.  

$T\mu$, $\mu T$ are "horizontal" composites in the sense of Sec. II. 5, "The Category of All Categories". (TODO: Understand what Mac Lane (1971) \cite{MacL1978} means when he says this on pp. 137). \\

Let's jump the gun and consider what natural transformation $\eta : 1_{\mathbf{C}} \to T$ means with respect to the definition of a natural transformation, Def. \ref{Def:NaturalTransformation}. $1_{\mathbf{C}}$ is the identity functor, mapping everything to itself. \\

$\forall \, X \in \text{Obj}{\mathbf{C}}$, $\eta_X: 1_{\mathbf{C}}(X) \to T(X)$ with $1_{\mathbf{C}}(X) = X, T(X) \in \text{Obj}{\mathbf{C}}$. $\eta_X$ is a morphism $\in \text{Hom}_{\mathbf{C}}(1_{\mathbf{C}}(X), T(X)) = \text{Hom}_{\mathbf{C}}(X, T(X))$ (!!!), as well as being a component of $\eta$ at $X$. Not only that, it applies $T$ onto $X$! \\

$\forall \,$ morphism $f: X\to Z$ in $\mathbf{C}$, $X, Z \in \text{Obj}{\mathbf{C}}$, 
\[
\eta_Z \circ 1_{\mathbf{C}}f = \eta_Z \circ f = Tf \circ \eta_X 
\]
i.e. 
\[
\begin{tikzcd}
1_{\mathbf{C}}(X) \arrow{d}{1_{\mathbf{C}}f} \arrow{r}{\eta_X} & T(X) \arrow{d}{Tf} \\
1_{\mathbf{C}}(Z) \arrow{r}{\eta_Z} & T(Z)
\end{tikzcd} \Longrightarrow 
\begin{tikzcd}
X \arrow{d}{f} \arrow{r}{\eta_X} & T(X) \arrow{d}{Tf} \\
Z \arrow{r}{\eta_Z} & T(Z)
\end{tikzcd}
\]

\subsubsection{Definitions and Properties of a Monad}

\begin{definition}[Monad]\label{Def:Monad}
\textbf{monad} $T = \langle T, \eta, \mu \rangle$ in category $\mathbf{C}$ consists of functor $T: \mathbf{C} \to \mathbf{C}$ and 2 natural transformations
\begin{equation}
\begin{aligned}
& \eta : 1_{\mathbf{C}} \to T \\ 
& \mu : T^2 \to T
\end{aligned}
\end{equation}	
s.t. 
\begin{equation}\label{Eq:MonadAssociativeDiagram}
\begin{tikzcd}
T^3 \arrow{d}{\mu T} \arrow{r}{T\mu} & T^2 \arrow{d}{\mu} \\
T^2 \arrow{r}{\mu} & T
\end{tikzcd}
\end{equation}
being like an "associative" diagram, and 
\begin{equation}\label{Eq:MonadLeftRightUnitLawsDiagram}
\begin{tikzcd}
	1T \arrow[equal]{d} \arrow{r}{\eta T} & T^2 \arrow{d}{\mu} & T1 \arrow{l}[swap]{T \eta} \arrow[equal]{d} \\
	T \arrow[equal]{r} & T & T \arrow[equal]{l}
\end{tikzcd}
\end{equation}
being a diagram that could be said to express the left and right unit laws.
\end{definition} 

Formally, the monad definition is like that of a monoid $M$ in $\mathbf{Sets}$: \\
set $M$ of elements of monad \quad $\to $ \, replaced by endofunctor $T : X \to X$ \\
Cartesian product $\times$ of 2 sets \quad $\to $ \, composite of 2 functors \\
binary operation $\mu : M \times M \to M$ of multiplication \quad $\to $ \, transformation $\mu : T^2 \to T$ and \\
unit (identity) element $\eta:1 \to M$ \quad $\to $ \, $\eta : 1_{\mathbf{C}} \to T$. \\

Thus, call \\
$\eta$ the \textbf{unit} of monad $T$. The first commutative diagram, Eq. \ref{Eq:MonadAssociativeDiagram}, is the associative law for a monad, and \\
$\mu$ the \textbf{multiplication} of monad $T$. The 2nd. and 3rd. diagrams, Eq. \ref{Eq:MonadLeftRightUnitLawsDiagram} expresses the left and right \emph{unit laws}.

\begin{proposition}[Coherence conditions]\label{Prop:MonadCoherenceConditions}
	\begin{equation}
	\begin{aligned}
	& \mu \circ T \mu = \mu \circ \mu T \quad (\text{as natural transformations $T^3 \to T$, $\mu \circ T\mu$ and $\mu \circ \mu T$, that is}) \\ 
	& \mu \circ T \eta = \mu \circ \eta T = 1_T \quad (\text{as natural transformations $T \to T$, $1_T \equiv$ identity functor}) 
	\end{aligned}
	\end{equation}
	
	For the last statement, it is equal to commutative diagram Eq. \ref{Eq:MonadLeftRightUnitLawsDiagram}, since it can be redrawn as follows:
\[
\begin{tikzcd}
	T \arrow{d}{ T \eta} \arrow{r}{\eta T} \arrow[equal]{dr} & T^2 \arrow{d}{\mu} \\
	T^2 \arrow{r}{\mu} & T
\end{tikzcd}	
\]
	
\end{proposition}

\subsection{Monads and Adjoints}

cf. Ch. 6, Monads and Algebras, pp. 138 of Mac Lane (1971) \cite{MacL1978}.
\begin{proposition}
	adjunction $\langle F, G, \eta, \epsilon \rangle : X \to A$, $\exists \, $ monad in category $X$ (notation $\langle F,G, \eta, \epsilon \rangle : \mathbf{C} \to \mathbf{D}$, $\exists \, $ monad in category $\mathbf{C}$). 
	
	Specifically, 2 functors $F:\mathbf{C} \to \mathbf{D}$, $G:\mathbf{D} \to \mathbf{C}$ have composite $T = GF$, an endofunctor, \\
	unit $\eta$ of adjunction is natural transformation $\eta : 1 \to T$, \\
	counit $\epsilon :FG \to 1_A$ of adjunction yields by horizontal composition; a natural transformation
	\[
	\mu = G\epsilon F: GFGF \to GF = T
	\] 
\end{proposition}

TODO: adjunction.

\subsection{Applications of Monads: Correspondence between Monads in Computer Science and Monads in Category Theory}

cf. \href{https://ncatlab.org/nlab/show/monad+%28in+computer+science%29}{monad (in computer science), nLab}

For monads in computer science, \\
maps type $X$ to new type $T(X)$, \\
equipped with rule for composing 2 functions of form $f:X \to T(Y)$ (called Kleisli functions), $g:Y \to T(Z)$ to function 
\[
g\circ f : X \to T(Z) \quad \text{(their Kleisi composition)}
\]
associative in evident sense, unital with respect to given unit function called $\text{pure}_X: X \to T(X)$ to be thought of as taking a value to the pure computation that simply returns that value. \\

e.g. when monad $T(-)$ forms product types $T(X) = X \times Q$, some fixed type $Q$ that carries structure of monoid. \\
Then Kleisi function $f:X \to Y \times Q$ is a function $X\to Y$  that produces as a side effect output of type $Q$. \\
Kleisi composition of $\begin{aligned} &  \quad \\
	& f:X\to Y\times Q \\
	& g: Y \to Z\times Q\end{aligned}$ \, not only evaluates the 2 programs in sequence, but also combines their $Q$-output using monoid operation of $Q$, e.g.
	
	if $\begin{aligned} & \quad \\ 
	& fx = (y, q) \\ 
	& gy = (z,q')\end{aligned}$  \, then $(g\circ f)(x) = (z, qq')$ \\
	
Let syntactic category be denoted $\mathbf{C}$. \\

$\text{Obj}{\mathbf{C}} \ni X$ \quad \, $\to $ \, types of the (programming) language \\
$\text{Hom}_{\mathbf{C}}(X,Y)$ \quad \, $\to $ \, "programs" that takes value of type $X$ as input and returns value of type $Y$ \\

endofunctor $T: \mathbf{C} \to \mathbf{C}$ \\
object map $T:X \to T(X)$ sends each type $X\in \text{Obj}{\mathbf{C}}$ to another type $T(X) \in \text{Obj}{\mathbf{C}}$.  \\

unit natural transformation $\epsilon:1_{\mathbf{C}} \to T$ provides $\forall \,$ type $X$ a component morphism $\text{pure}_X :X \to T(X)$ (notation, \href{https://ncatlab.org/nlab/show/monad+%28in+computer+science%29}{ncat} uses the notation $\epsilon$; we will use $\eta$ for the "unit" natural transformation of a monad):
	\[
		\begin{aligned}
		&  \eta : 1_{\mathbf{C}} \to T \\ 
		& \eta_X : X\to T(X) \equiv \text{pure}_X : X \to T(X)
		\end{aligned}	
	\]

multiplication natural transformation $\mu :T^2 \to T$ provides $\mu_X : T^2(X) \to T(X)$ which induces Klesli composition by formula
\begin{equation}
\begin{aligned} 
	(g\circ f) & := (Y \xrightarrow{g} T(Z)) \circ_{\text{Klesli}} (X\xrightarrow{f} T(Y)) \\
	& := X \xrightarrow{f} T(Y) \xrightarrow{T(g)} T(T(Z)) \xrightarrow{ \mu(Z) } TZ
\end{aligned} 
\end{equation}
$T(g)$ uses fact that $T(-)$ is functor morphism $\mu(Z)$ is 1 that implements "$T$-computation".

Now \href{https://ncatlab.org/nlab/show/monad+%28in+computer+science%29}{nLab} says this about the "bind" operation: \\
	"bind" \quad $\leftrightarrow$ \, multiplication on monad $M$, \\
	\begin{equation}\label{Eq:BindAsStrongMonad}
	\begin{gathered} 
	MA \to (MB)^A \to MB \text{ equivalent to map } MA \times MB^A \to MB \\ 
	 MA \times MB^A \xrightarrow{ \text{ strength } } M(A\times MB^A) \xrightarrow{ M_{\text{eval}_{A, MB} } } MMB \xrightarrow{ mB } MB
	\end{gathered} 
	\end{equation}
To try to make sense of Eq. \ref{Eq:BindAsStrongMonad}, consider the following: 
\[
\begin{gathered}
\text{Recall for natural transformation $\eta$, the component $\eta_X$: } \mu_X : T^2(X) \to T(X) \text{ and for some morphism $f \in \text{Mor}{\mathbf{C}}$}, \\
	f:X\to Z \\
	Tf:T(X) \to T(Z)
\end{gathered} 
\]
So if $f:X\to T(Y)$ instead, 
\[
\begin{gathered}
Tf:T(X) \to T^2(Y) \\ 
(\mu_Y \circ Tf) : T(X) \to T(Y)
\end{gathered} 
\]
Form a Cartesian product of $T(X)$ and $\text{Hom}_{\mathbf{C}}(X,T(Y)) \ni f$ as inputs: $T(X) \times \text{Hom}_{\mathbf{C}}(X, T(Y))$. \\

Then I suggest that Eq. \ref{Eq:BindAsStrongMonad} is translated as follows:
\begin{equation}
T(X) \times \text{Hom}_{\mathbf{C}}(X, T(Y)) \xrightarrow{ \text{ apply } T } T( T(X) \times \text{Hom}_{\mathbf{C}}(X, T(Y))) \xrightarrow{ Tf} T^2(Y) \xrightarrow{ \mu_Y } T(Y) 
\end{equation}
where apply $T$ is on $f\in \text{Hom}_{\mathbf{C}}(X,T(Y))$ in order to form $Tf$.

\subsubsection{More on Klesli composition}

cf. \href{https://ncatlab.org/nlab/show/Kleisli+category}{Kleisli category, nLab}.

\begin{proposition}\label{Prop:KlesliCompositionForm}
	Klesli composition of $g\circ f$ of $\begin{aligned} & \quad \\ 
	& f: X\to T(Y) \\ 
	& g: Y \to T(Z) \end{aligned}$ \, is given by 
	\[
	X \xrightarrow{f} TY \xrightarrow{ Tg} T^2Z \xrightarrow{\mu_Z} TZ 
	\]
	i.e. 
	\begin{equation}
		\boxed{ g \circ_{\text{Klesli}} f = \mu_Z \circ Tg \circ f }
	\end{equation}
	with $ \mu_Z \circ Tg \circ f : X \to T(Z)$
\end{proposition}

\begin{proof}
	Fullness of functor $T$: \\
	
	$\forall \, $ morphism $g: T(X) \to T(Y)$ has antecedent the composition
	\[
	X\xrightarrow{ \eta_X} T(X) \xrightarrow{g} T(Y) 
	\]
	i.e. $g\circ \eta_X : X \to T(Y)$. \\
	
Consider $T(g \circ \eta_X) = Tg \circ T \eta_X : T(X) \to T^2(Y)$ for 
\[
\begin{aligned} 
	& T\eta_X : T(X) \to T^2(X) \\ 
	& Tg : T^2(X) \to T^2(Y) \\ 
	& \mu_Y : T^2(Y) \to T(Y) 
\end{aligned} 
\]
So 
\[
\mu_Y \circ Tg \circ T\eta_X = \mu_Y \circ T(g\circ \eta_X) : T(X) \to T(Y)
\]
Because $g$ is a morphism of algebras (TODO: understand what this means, from \href{https://ncatlab.org/nlab/show/Kleisli+category}{Kleisli category, nLab}), 
\[
\mu_Y \circ Tg \circ T\eta_X = g\circ \mu_X \circ T\eta_X = g
\]
where $\mu_Y \circ Tg = g\circ \mu_X$ uses natural transformation definition \ref{Def:NaturalTransformation} for the property $\mu_Z \circ T^2 f = Tf \circ \mu_X$ (TODO: Show $g=Tf$ is of this form), \\
and $\mu \circ T\eta = \mu \circ \eta T = 1_T$ (coherence condition from Prop. \ref{Prop:MonadCoherenceConditions}).  \\

Faithfulness: \\

If $\mu_Y \circ Tf = \mu_Y \circ Tg$, then precompose by $\eta_X$ yields 
\[
\mu_Y \circ Tf \circ \eta_X = \mu_Y \circ  \eta_{f(X)} \circ f = \mu_Y \circ \eta_{T(Y)} \circ f = f
\]
where \\
$Tf\circ \eta_X = \eta_{T(Y)} \circ f$ from natural transformation def. \ref{Def:NaturalTransformation} was used, and $\mu \circ \eta T = 1_T$ (coherence condition) was also used, for $f:X \to T(Y)$. \\

Similarly for $g$. $\mu_Y \circ Tf = \mu_Y \circ Tg \Longrightarrow f=g$.
\end{proof} 

Notice that the multiplication natural transformation $\mu:T^2 \to T$ was needed to induce the Klesli composition.

\subsubsection{Dictionary between Monads in Computer Science and Monads in Category Theory}

\[
\boxed{ \texttt{join} \quad \text{ is } \, \mu_X : T^2(X) \to T(X)}
\]

\[
\boxed{ \texttt{return} \quad \text{ is } \, \eta_X: X \to T(X) }
\]

\[
\boxed{ \texttt{fmap} \quad \text{ is the morphism map (arrow map) for functor } F}
\]

\[
\boxed{ \texttt{bind} \quad \text{ is } \, \mu_Y \circ Tf : T(X) \to T(Y) \text{ but ... }}
\]
\texttt{bind} is more nuanced in that, from the Haskell and functional programming perspective, it takes in \emph{two} inputs. \\

One of them is an element $x$ in the object $X$, $x \in X$. The other is a "transformation of type $X \to T(Y)$." I believe that would mean a morphism $f: X \to T(Y)$.  \\

What \v{C}uki\'{c} in \v{C}uki\'{c} (2018) \cite{Cuki2018} calls \texttt{transform} is the \emph{morphism map} (arrow map) for a functor $F$. However, note that when it comes to concrete implementation, the concrete implementation applies to \emph{instances} of a type $X \in \text{Obj}{\mathbf{C}}$. For a given type $X$, e.g. \verb|int| (the integer type in C or C++), there are many values that will have that type. It would be good that we work out how the definitions, theorems, and commutative diagrams apply in this case.

% TODO: work out the case when an object in $\text{Obj}{\mathbf{C}}$ for category $\mathbf{C}$, when the object itself has associated elements.

I don't think there's a great way to reconcile what Haskell and functional programming programmers mean by \texttt{bind} with the corresponding concept in category theory. 

\subsection{Examples of Monads in Computer Science}


\subsubsection{Reader Monad; Function Monad; Environment Monad} $[W, -] : \mathbf{C}\to \mathbf{C}$.

Given $W \in \text{Obj}{\mathbf{C}}$, ($W$ is a type), 
\[
[W, - ] = (W \to (-))
\]
where $[-, -] : \mathbf{C}^{\text{op}} \times \mathbf{C} \to \mathbf{C}$.

$W \mapsto $ internal hom out of $W$.

\[
\begin{aligned} 
& \eta_X : X \to [W, -](X) \\ 
& \eta_W: W \to [W, -](W) \\ 
& \eta_W : w \mapsto [W,-](W)(w) \text{ \, value to constant functions with that value } \\ 
& \Delta : X \in \text{Obj}{\mathbf{C}} \xrightarrow{ (1,1) } X \times X \\ 
& \Delta : x \mapsto (w,w)
\end{aligned} 
\]

"read in " state of type $W$ (an environment)

\href{https://en.wikipedia.org/wiki/Monad_(functional_programming)#State_monads}{wikipedia} calls this the Environment Nomad. \\

\texttt{reader}: $T \to E \to T = t\mapsto e \mapsto t$ corresponds to $\eta_X : X \to T(X)$ where $T(X) = \text{Hom}_{\mathbf{C}}(E,X)$ s.t. $\eta_X$ sends values $x\in X $ to constant functions (on $E$) to value $x$. \\

Therefore, rewrite the unit component at $X$, i.e. \texttt{reader}, as \\
\begin{equation}
\begin{gathered}
\begin{aligned}
& X \to E \to X \\
& x \mapsto e \mapsto x
\end{aligned} \qquad \, 
\begin{aligned}
	& \eta_X : X \to \text{Hom}_{\mathbf{C}}(E,X) \\ 
	& \eta_X : x \mapsto (e\mapsto x)
\end{aligned}
\end{gathered}
\end{equation}
Thus, the \emph{unit} component at $X$, called \texttt{unit} or \texttt{return} by programmers, truly maps a value $x \in X$ to a \emph{constant function}:
\begin{equation}
\eta_X : x \mapsto (e \mapsto x) \in \text{Hom}_{\mathbf{C}}(E, X)
\end{equation}


\texttt{bind}: $(E\to T) \to (T\to E \to T') \to E \to T' = r\mapsto f \mapsto e \mapsto f(re)e$ corresponds to $\mu_Y \circ Tf:T(X) \to T(Y)$ where $T(X) = \text{Hom}_{\mathbf{C}}(E,X)$, $T(Y) = \text{Hom}_{\mathbf{C}}(E,Y)$, and \\
$f:X\to T(Y)$ or $f:X\to \text{Hom}_{\mathbf{C}}(E,Y)$ \\
$Tf : T(X) \to T^2(Y)$ or $Tf : \text{Hom}_{\mathbf{C}}(E,X) \to \text{Hom}_{\mathbf{C}}(E,T(Y)) = \text{Hom}_{\mathbf{C}}(E, \text{Hom}_{\mathbf{C}}(E,Y))$. \\

So let's rewrite \texttt{bind} in our notation:
\[
\begin{aligned}
	& (E\to X) \to & (X \to E \to Y) \to & E \to & Y \\
	& r \mapsto & f \mapsto & e \mapsto (f(r))(e)(e)
\end{aligned}
\]

To clarify these definitions, rewrite the reader monad: the endomorphism $T$ is defined as
\begin{equation}
\boxed{  \begin{aligned} & T := [E, -] \\ & T(X) = [E, X] \end{aligned} }
\end{equation}

For any morphism $f : X \to T(Y) = [E, Y]$, then \\
recall the Klesli composition: $g \circ_{\text{Klesli}} f = \mu_Z \circ Tg \circ f$ with $g: Y \to T(Z) = [E,Z]$. 

But if you take a look at how wikipedia defines "bind" for the reader monad, then bind \emph{is not} the Klesli composition, but rather it's $\mu_Y \circ Tf$ (!!!):
\begin{equation}
\begin{gathered}
\mu_Y \circ Tf: T(X) \to T(Y) \text{ or } \mu_Y \circ Tf : [E, X] \to [E, Y] \\ 
r \in [E,X] \qquad \, r(e) \in X \text{ for } e \in E \qquad \, f(r(e)) \in T(Y) = [E,Y] \qquad \, f(r(e))(e) \in Y
\end{gathered}
\end{equation}
bind, as defined by wikipedia for the reader monad \emph{is not} the Klesli composition.

As an example, consider the following example: \\
$T(Y) \ni (E\to Y) \in \text{Hom}_{\mathbf{C}}(E,Y)$ \\
$e = $ "dag" $\mapsto y = $ "Hello Dag!" \\

$T(X) \ni (E\to X) \in \text{Hom}_{\mathbf{C}}(E,X)$ \\
$e \equiv $ \texttt{name} $\mapsto x = $ "Hi \texttt{name}!" \\

$f:X\to T(Y) \to f:X\to \text{Hom}{(E,Y)}$ \\
$f(x) = $ replace "Hi" with "Hello" in $X$. \\

\texttt{ask}: $E\to E = 1_E$. \\
\texttt{ask} operation used to retrieve current context. \\

\texttt{local}: $(E\to E) \to (E\to T) \to E \to T = f \mapsto c \mapsto e \mapsto c(fe)$ \\
local executes a computation in a modified subcontext. $(E\to E)$ modifies the environment, $(E\to T)$ uses the modified environment. \\
Rewrite \texttt{local} in our notation: \\
\[
\begin{aligned} 
	& (E\to E) \to & (E\to X) \to & E \to & X \\
	& f \mapsto & c \mapsto & e \mapsto & c(f(e))
\end{aligned}
\]
To make sense of this, let $f \in [E, E]$, $c\in [E,X] = T(X)$, $c\circ f \in [E, X]$ so $(c\circ f)(e) \in X$. \\


\subsubsection{Writer Monad} $W \times (-) : \mathbf{C} \to \mathbf{C}$ where $W \in \text{Obj}{\mathbf{C}}$. If $W$ equipped with the structure of monoid, $W \times (-)$ canonically inherits the structure of a \emph{monad}. Hence, the Writer \emph{Monad}.  

Recall $W$ monoid if $W$ is a set equipped with binary operation $\mu : M \times M \to M$ s.t. $(xy)z = x(yz)$ and $1 \in M$ s.t. $1\cdot x = x = x \cdot 1$. \\

\subsubsection{State Monad}

cf. \href{https://ncatlab.org/nlab/show/state+monad}{state monad, nLab}

Input of type $X$, output of type $Y$, mutable state type $W$.

Consider morphism 
\[
X\times W \to Y\times W
\]

Under (Cartesian product $\vdash$ internal hom) adjunction, this is equivalently given by its adjunt, which is a function of type
\[
X \to [W, W\times Y]
\]
$[W, W\times (-)]$ is the monad, induced by the above adjunction. \\

$X \to [W, W\times Y]$ regarded as a morphism.

$[W, W\times Y]:\mathbf{H} \to \mathbf{H}$ is called \emph{state monad} for mutable states of type $W$.

TODO: Understand the above.

Writer comonad $W \times (-):\mathbf{C} \to \mathbf{C}$, \\

Given by forming Cartesian product with $W$. \\

Reader Monad $\circ$ Writer Comonad is state monad.

cf. \href{https://en.wikipedia.org/wiki/Monad_(functional_programming)#State_monads}{wikipedia}

unit or "return":
\begin{equation}\label{Eq:ReturnStateMonadWikipedia}
\begin{aligned}
& X \to & S \to X \times S \\
& x \mapsto & (s \mapsto (x, s))
\end{aligned}
\end{equation} 
Compare this to 
\[
\begin{aligned} 
	& \eta_X : X \to T(X) = [S, S \times X] \\ 
	& \eta_X : x \mapsto (S \to S \times X)
\end{aligned} 
\]

"bind" was given by \href{https://en.wikipedia.org/wiki/Monad_(functional_programming)#State_monads}{wikipedia} as 
\begin{equation}\label{Eq:BindStateMonadWikipedia}
\begin{aligned} 
	& (S \to X \times S)  \to & (X \to S \to Y \times S) \to & S \to & Y \times S \\ 
	& m \mapsto & k \mapsto & s \mapsto & k(x)(s) 
\end{aligned} 
\end{equation}
where $(x, t) = m(s)$

\subsubsection{Properties of the State Monad}

For the unit or "return", $\eta_X : X \to T(X) = [S, S \times X]$, \\
%Choose $\eta_X$ s.t. it sets state $s\in S$ to be the initial state $s_0$
\begin{equation}
\begin{gathered} 
\eta_X : x \mapsto (S \to S \times X) \text{ s.t. } \\
(S \to S \times X) : s \mapsto (s, x)
\end{gathered} 
\end{equation}
Therefore, for the unit component at $X$ of a state monad,
\begin{equation}
\boxed{ \eta_X(x)(s) = (s, x) \text{ for } s \in S }
\end{equation}
Compare this to what wikipedia says how it defines the "\texttt{return}" operation in Eq. \ref{Eq:ReturnStateMonadWikipedia}.

Consider any morphism $f : X \to T(Y) = [S, S\times Y]$,
\begin{equation}
\begin{aligned}
& f : X \to T(Y) = [S, S\times Y] \\
& f:x \mapsto (S \to S\times Y) \text{ s.t. } (S \to S \times Y) : s \mapsto (t = f_s(s, x), y = f_x(s, x))
\end{aligned}
\end{equation}

Allow morphism $f$ to have "freedom" to set state to arbitrary $t$.

\begin{equation}
\begin{aligned}
& Tf:T(X) \to T^2(Y) \to Tf : [S, S\times X] \to T([S, S\times Y]) = [S, S \times [S, S\times Y]] \\
& Tf:(S \to S \times X) \mapsto (S \to S \times (S \to S \times Y))
\end{aligned}
\end{equation}

Then
\begin{equation}
\begin{aligned}
& \mu_Y \circ Tf : T(X) \to T(Y) \text{ or } \mu_Y \circ Tf : [S, S \times X] \to [S, S \times Y] \\ 
& \mu_Y \circ Tf: (S \to S \times X) \mapsto (S \to S \times Y)
\end{aligned}
\end{equation}

Note that 
\begin{equation}
	\begin{aligned}
	& \mu_X : T^2(X) \to T(X) \\ 
	& \mu_X : (S \to S \times (S \to S \times X)) \mapsto (S \to S \times X)
	\end{aligned}
\end{equation} 

\begin{equation}
\begin{aligned}
& T^2 f : T^2(X) \to T^3(Y) \\  
& T^2 f: (S \to S \times (S \to S\times X)) \mapsto (S \to S \times (S \to S \times (S \to S \times Y)))
\end{aligned}
\end{equation}

Now
\[
\begin{gathered} 
 \mu_X \circ T^2 f : (S \to (S \times (S \to S \times X))) \mapsto (S \to S \times (S \to S \times Y)) \\ 
 Tf \circ \mu_X : (S \to S \times (S \to S \times X)) \mapsto (S \to S \times (S \to S \times Y))
\end{gathered} 
\]
and so 
\[
\Longrightarrow \mu_X T^2 = Tf \mu_X 
\]
Thus, $\mu$, as defined above, \emph{is} a natural transformation.

Show $\eta_{T(Y)} \circ f = Tf\circ \eta_X$. 
\[
\begin{gathered} 
	Tf \circ \eta_X (x) = (S \to S \times (S \to S \times Y)) \\ 
 \eta_{T(Y)} \circ f(x) = \eta_{T(Y)} (S \to S \times Y) = (S \to S \times (S \to S \times Y))
\end{gathered} 
\]
%Thus, we have to backtrack and make $s= s_0$ for $f:X \to T(Y)$, and $T$ needs to induce $\eta_{T(Y)}$ to apply a non-trivial morphism.

Prove now the coherence conditions, Prop. \ref{Prop:MonadCoherenceConditions}. For the first one,
\[
\mu \circ T \mu = \mu \circ \mu T
\]

\[
\begin{gathered} 
	\mu \circ T \mu (S \to (S \to S \times (S\to S \times X))) = \mu \circ T (S \times (S \to S \times X)) = \mu (S \to S \times (S \times (S \to S \times Y))) = \\
	= (S \times (S \to S \times Y)) \\ 
 \mu\circ \mu T (S \to (S \to S \times (S\to S \times X))) = \mu^2 (S \to S \times (S \to (S \to S \times (S \to S \times Y)))) = \\
 	= S \times (S \to S \times Y)
\end{gathered} 
\]
\[
\Longrightarrow \mu \circ T \mu = \mu \circ \mu T
\]
So the first coherence condition is proven.

For the second, 
\[
%\begin{aligned} 
%&	\mu \circ T \eta (x) = (y, t) \\ 
%& \mu \eta T (x) = \mu \circ \eta(x, s) = (y, t)
%\end{aligned}  \Longrightarrow \begin{aligned} 
%& T:X\to T(X) \\ 
%& T: x\mapsto (x, s_0)
%\end{aligned} 
\begin{gathered}
\mu \circ T \eta (S\to S \times X) = \mu \circ T (S \to S \times (S \to S \times X)) = (S \to S \times (S \to S \times X)) \\
\mu \eta T (S\to S \times X) = \mu \circ (S \to S \times T(S \to S \times X)) = T(S \to S \times X) = (S \to S \times (S \to S \times X))
\end{gathered}
\]

\[
%\begin{aligned} 
%	& \mu \circ T \eta(x,s) = \mu \circ T ((y, t), s) = ((z,u) , t) \\ 
%	&  \mu \circ \eta T(x,s) = \mu\circ \eta ((y,t) , s) = ((z,u), t) 
%\end{aligned}  \Longrightarrow \begin{aligned}
%& T:T(X) \to T^2(X) \\ 
%& T(x,s) = ((y,t), s)
%\end{aligned}
\]
Thus, it's been shown that the choice of endomorphism for the state monad, $X \to [S, S \times X]$, fulfills the monad coherence conditions being of this form.

%However, $1_T(x,s) = ((y,t), s)$. Therefore, we must give up on making both $\mu \circ \eta T$ and $\mu \circ  T \eta$ be ever equal to $1_T$. Thus, diagram \ref{Eq:MonadLeftRightUnitLawsDiagram} is modified as such: 

%\begin{equation}\label{Eq:StateMonadLeftRightUnitLawsDiagram}
%\begin{tikzcd}
%T \arrow{d}{ T \eta} \arrow{r}{\eta T}  & T^2 \arrow{d}{\mu} \\
%T^2 \arrow{r}{\mu} & T
%\end{tikzcd}	
%\end{equation}

%I would argue that this is ok because there are examples of mathematical structures without an "identity" or "unit" such as a semi-group.

Consider what "bind" means in category theory. Given
\begin{equation}
\begin{aligned}
& f:X \to T(Y) = [S, S \times Y] \\ 
& g: Y \to T(Z) = [S, S\times Z] \\ 
& f(x) = (S \to S\times Y) \\
& f(x)(s) = (t, y) \text{ where } s, t \in W \\ 
& g(y) = (S \to S \times Z) \\ 
& g(y)(t) = (u, z)
\end{aligned}
\end{equation}
Therefore, if we define the usual projection operations on a Cartesian product,
\begin{equation}
\begin{aligned}
& \Pi_W : W \times X \to W \\
& \Pi_W(w,x) = w
\end{aligned} \qquad \, 
\begin{aligned}
& \Pi_X : W \times X \to X \\
& \Pi_X(w,x) = x
\end{aligned}
\end{equation}
\begin{equation}
\begin{aligned}
& \mu_Z \circ Tg \circ f : X \to T(Z) = [S, S\times Z] \ni (W \to W \times Z) \\ 
& \mu_Z \circ Tg \circ f : x \mapsto (S \to S \times Z) \equiv \mu_Z \circ Tg \circ f(x)
\end{aligned}
\end{equation}
such that 
\begin{equation}
\boxed{ g(y)(t) = (u,z) \text{ where } y = \Pi_Y(f(x)(s)), \, t = \Pi_W(f(x)(s)) }
\end{equation}
Compare this to what wikipedia says in Eq. \ref{Eq:BindStateMonadWikipedia}.

\subsubsection{Continuation Monad}

From \href{https://ncatlab.org/nlab/show/continuation+monad}{nLab}, \\
In a category $\mathbf{C}$ with internal homs $[-, -]$, so internal homs $[-,-]$ belong to $\text{Obj}{\mathbf{C}}$ (they're objects as well), given object $Y \in \text{Obj}{\mathbf{C}}$, the \emph{continuation monad} is endofunctor
\begin{equation}
\boxed{ X \mapsto [[X, Y], Y] } \text{ i.e. } T(X) = [[X, Y], Y] \text{ for object $Y \in \text{Obj}{\mathbf{C}}$ } 
\end{equation}
so that $T = X\mapsto [[X, Y] , Y]$

From \href{https://en.wikipedia.org/wiki/Monad\_(functional\_programming)\#Continuation\_monad}{wikipedia},

unit or return:  \\

return type $Y$, maps type $X$ into functions of type $(X \to Y) \to Y$
\begin{equation} 
\begin{aligned}
	& X \to & (X\to Y) \to & Y \\
	& x\mapsto & f \mapsto & f(x) = y
\end{aligned}
\end{equation}

Compare this to
\begin{equation}
\begin{aligned}
& T : X \to [[X, Y], Y] \\ 
& \eta_X : X \to T(X) = [[X,Y], Y]
\end{aligned}
\end{equation}

And so for the \emph{unit} of the Continuation monad,
\begin{equation}
\boxed{
\begin{aligned}
& \eta_X : X \to T(X) = [[X, Y], Y] \\
& \eta_X : x\mapsto (f \to y) \\ 
& \eta_X(x)(f) = y = f(x)
\end{aligned}
}
\end{equation}

bind: \\

\begin{equation}\label{Eq:ContinuationMonadBindWiki}
\begin{aligned}
& ((X\to Y) \to Y) \to & (X \to (X' \to Y) \to Y) \to & (X' \to Y) \to & Y \\
& c \mapsto & f \mapsto & k \mapsto &  c(t\mapsto ftk)
\end{aligned}
\end{equation}

From \href{https://ncatlab.org/nlab/show/continuation+monad}{nLab}, if morphism $f:X\to Y$ is in Klesi category of the continuation monad, then it's a morphism in $\mathbf{C}$ of form $X\to T(Y)$ in $\mathbf{C}$. Hence morphism in original category \emph{of the form} $X\to [[Y,S], S]$ is much like a map from $X \to Y$, only instead of "returning" output $Y$ directly, it instead feeds it into given function $Y\to S$, which hence \textbf{continues} the computation. 

So for $X \to [[Y, S], S]$, \href{https://ncatlab.org/nlab/show/internal+hom}{nLab} gives the corresponding \emph{computation rule} for function types of the internal hom $[X, S]$:
\[
(y \mapsto a(y))(x) = a(x)
\]

Hence for $X \to [[X, Y], Y]$, we have $x\mapsto f \mapsto f(x)$ because $f \in [X, Y]$ because $f$ is treated as an object in $\mathbf{C}$. \\

So do the following "rewrite" or change of notation on Eq. \ref{Eq:ContinuationMonadBindWiki}:

\begin{equation}\label{Eq:ContinuationMonadBindWiki2}
\begin{aligned}
& ((X \to Z) \to Z) \to (X \to (Y\to Z) \to Z) \to (Y \to Z) \to Z \\ 
& T(X) \to (X \to T(Y)) \equiv \text{Hom}(X, T(Y)) \to \text{Hom}(Y,Z) \to Z
\end{aligned}
\end{equation}
Let $c\in T(X) = [[X,Z], Z]$. \\
Let $k \in [Y,Z]$ \\
Let $f(x) \in [[Y,Z], Z]$ and so \\
$f(x)(k) \in Z$ \\

Form $x \mapsto f(x)(k) \in [X,Z]$, so $c(x\mapsto f(x)(k)) \in Z$. \\

So "bind" as defined in wikipedia, Haskell/Functional Programming isn't the Klesli composition, but it's
\[
\mu_Y \circ Tf : T(X) \to T(Y) = [[Y,Z], Z]
\]

Write this as 
\begin{equation}
\boxed{
\begin{aligned}
& (\mu_Y \circ T)(f)(c) \in T(Y) = [[Y,Z], Z] \\
& (\mu_Y \circ T)(f)(c)(k) \in Z
\end{aligned}}
\end{equation}


\emph{call with current continuation} function defined as follows: \\
call/cc
\begin{equation}\label{Eq:CallCurrentContinuationContinuationMonad}
\begin{aligned}
((X \to (X' \to Y) \to Y) \to (X\to Y) \to Y) & \to (X\to Y)  & \to Y \\ 
f & \mapsto k & \mapsto (f(t\mapsto x \mapsto kt) k) 
\end{aligned}
\end{equation}

Let's look at Eq. \ref{Eq:CallCurrentContinuationContinuationMonad}, step-by-step.
\[
\begin{gathered}
\begin{aligned} 
& (X\to (X' \to Y) \to Y) \\
& f
\end{aligned} \text{ corresponds to } \\
\begin{gathered}
X \to [[X' , Y], Y] = T(X') \\
f \equiv f_{XX'} : X \to T(X')
\end{gathered}
\end{gathered}
\]

\subsubsection{\texttt{future} as Continuation Monad}

 \v{C}uki\'{c} (2018) \cite{Cuki2018} asks first if \verb|std::future| in C++ is a functor. Recall the definition of a functor, Def. \ref{Def:Functor}:

\[
\begin{aligned}
& F: \mathbf{C} \to \mathbf{D} \text{ with "object" map } \\ 
& F: \text{Obj}{\mathbf{C}} \to \text{Obj}{\mathbf{D}} \\ 
& F: X \to F(X)
\end{aligned}
\] 
and the functor's "morphism map":
\[
\begin{aligned}
& Ff :F(X) \to F(Y) \\ 
& f:X \to Y, \, f \in \text{Hom}_{\mathbf{C}}(X, Y)
\end{aligned}
\]

Suppose $X = $ \texttt{T1}, $Y = $ \texttt{T2}. Then in the example on pp. 220, Sec. 10.7.1 Futures as monads" example of \v{C}uki\'{c} (2018) \cite{Cuki2018}, 
\[
\begin{aligned}
& F(X) = \verb|future<T1>| \\ 
& F(Y) = \verb|future<T2>|
\end{aligned}
\]

Instead, the morphisms to consider is of this form:
\[
f:X \to T(Y)
\]
where $T$ is a functor but a special one: the endomorphism. And $T$ is \verb|std::future|.

Here are examples of morphisms $f, g$:
\[
\begin{aligned}
& \verb|future<std::string> user_full_name(const std::string& login);| \\
& \verb|future<std::string> to_html(const std::string& text);|
\end{aligned}
\]

Now $Tf:T(X) \to T^2(Y)$, how the morphism map for $T$ applies to morphism $f$, now. Recall that we can compose this with the multiplication natural transformation component at $X$, $\mu_X$:
\[
\begin{aligned}
& \mu_X \circ Tf : T(X) \to T(Y) \\ 
& \mu_X : T^2(X) \to T(X)
\end{aligned}
\]

In order to compose morphisms, say $f,g$, recall the "Klesli composition", Prop. \ref{Prop:KlesliCompositionForm}
\begin{equation}
g\circ_{\text{Klesili}} f = \mu_Z \circ Tg \circ f
\end{equation}
If we call $\mu_Z \circ T$ "bind", $\mu_Z \circ T: \text{Hom}(Y, T(Z)) \to \text{Hom}(T(Y), T(Z))$. The correspondence is such:
\begin{equation}
(\texttt{bind}(\verb|to_html|))(\verb|user_full_name|) \Longleftrightarrow \mu_Z \circ Tg \circ f: X \to T(Z)
\end{equation}


\subsubsection{Resources for implementations of Monads} Python and C++ code. \\

\url{https://github.com/Iasi-C-CPP-Developers-Meetup/presentations-code-samples}, namely \\
\url{https://github.com/Iasi-C-CPP-Developers-Meetup/presentations-code-samples/tree/master/radugeorge} \\

\url{https://github.com/dbrattli/OSlash}, namely \\
\url{https://github.com/dbrattli/OSlash/tree/master/tests} \\

\href{https://gist.github.com/pfultz2/f538423ebc9bbbe3df92}{State Monad implementation in C++}


\section{Applications of Category Theory on Hybrid Systems}

cf. Ames (2006) \cite{Ames2006}.
	
\subsection{D-Categories}

$D$ stands for discrete.

Recall that a small category $\mathbf{C}$ is called \emph{small} if both $\text{Obj}(\mathbf{C})$ and $\text{hom}(\mathbf{C})$ are sets, not proper classes. 

\begin{definition}[Axiomatic D-categories]
Let D-category be a \emph{small} category $\mathbf{D}$ s.t.
\begin{enumerate}
	\item $\forall \, D \in \text{Obj}(\mathbf{D})$, \\
	$\exists \,$ morphism $f \in \text{Mor}(\mathbf{D})$ s.t. $f \neq 1$ s.t. \\
	$f \in \text{Hom}(D, *)$ or $f\in \text{Hom}(*, D)$, but never both, \\
	i.e. $\forall \, $ diagram $a_0 \xrightarrow{ \alpha_1} a_1 \xrightarrow{ \alpha_2} \dots \xrightarrow{ \alpha_n} a_n$ in $\mathbf{D}$, all but 1 morphism must be identity (i.e. longest chain of composite non-identity morphisms is of length 1). 
	\item If for $D\in \text{Obj}(\mathbf{D})$, $D$ is the domain of a non-identity morphism, i.e. $\exists \, f_1 \in \text{Mor}(\mathbf{D})$ s.t. 
	\[
	f_1 \in \text{Hom}(D, *), \, f_1 \neq 1
	\]
	then $\exists \, f_2 \in \text{Hom}(D, *)$, $f_2 \neq f_1$, $f_2 \neq 1$ and $\forall \, f \in \text{Hom}(D, *)$ s.t. $f\neq f_1,f_2$, \, $f=1$
\end{enumerate}
\end{definition}
	
cf. 1.2.1 Important objects in D-categories, Ames (2006) \cite{Ames2006}.

Let 
\[
\begin{gathered}
	\text{Mor}{\mathbf{A}} = \bigcup_{A, B \in \text{Obj}(\mathbf{A})} \text{Hom}(A,B) \qquad \, \text{(my notation)} \\
	\text{Mor}(\mathcal{D}) = \bigcup_{(a,b) \in \text{Obj}(\mathcal{D}) \times \text{Obj}(\mathcal{D}) } \text{Hom}_{\mathcal{D}}(a,b) \qquad \, \text{ (Ames' notation) }
\end{gathered}
\]	
	
Let 
\begin{equation}
\text{Mor}_{1}{\mathbf{A}} := \lbrace A \in \text{Mor}(\mathbf{A}) | A \neq 1 \rbrace 
\end{equation}

For a D-category, consider these subset of $\text{Obj}(\mathbf{D})$, 

\begin{definition}[Edge set]
	\textbf{edge set} of $\mathbf{D}$, $E(\mathbf{D})$, 
\begin{equation}
\begin{gathered}
E(\mathbf{D}) := \lbrace A \in \text{Obj}(\mathbf{D}) | \alpha \in \text{Hom}(A, *), \beta \in \text{Hom}(A, *), \alpha, \beta \in \text{Mor}_{1}(\mathbf{D}), \, \alpha \neq \beta \rbrace \text{ i.e. } \\
E(\mathbf{D}) := \lbrace A \in \text{Obj}(\mathbf{D}) | \alpha, \beta \in \text{Hom}(A, *), \, \alpha, \beta \neq 1, \, \alpha \neq \beta \rbrace
\end{gathered}
\end{equation}	
\end{definition}
i.e. $\forall \, A \in E(\mathbf{D})$, $\exists \, \alpha, \beta \in \text{Mor}(\mathbf{D})$, \, $\alpha, \beta \neq 1$, s.t. $\alpha, \beta \in \text{Hom}(D, *)$; denote these morphisms by $s_a,t_a$ (this specific choice will define an \textbf{orientation}).

Conversely, given morphism $\gamma \in \text{Mor}(\mathbf{D})$, $\gamma \neq 1$, $\exists \, ! \, A \in E(\mathbf{D})$ s.t. $\gamma = s_a$ or $\gamma = t_a$, i.e. $\gamma \in \text{Hom}(A, *)$. 

\begin{definition}[Vertex set]
\textbf{vertex set} of $\mathbf{D}$:
\begin{equation}
 V(\mathbf{D}) = (E(\mathbf{D}))^c
\end{equation} 
\end{definition}

\begin{definition}[Orientation]
	Orientation of D-category $\mathbf{D}$ is a pair of functions $(s,t)$ between sets.
	
\end{definition}


	
%\subsection{Blog (Running log)}

\part{Category Theory and Databases} 
	
\section{Types}

\subsection{Data models for nested arrays, dictionaries, and tabular data}

\begin{definition}[Container types]
	\textbf{Container types} - arrays, key/value pair dictionaries (or: hashes, association lists)
\end{definition}

\begin{definition}[atomic types]
	basic atomic types (e.g. numbers, strings, Booleans)
\end{definition}

\begin{definition}[nesting]
	\textbf{nesting}: containers may contain atomic values as well as other containers.
\end{definition}

\begin{definition}[flat]
	Tabular data model (i.e. tables) is \textbf{flat}: field contains \textbf{atomic} values.
\end{definition}
cf. Number 2, Data Models and Languages, Grust and Duta (2017) \cite{GrDu2017}


\subsection{Typed Data, Untyped data, in the relational data model}

\begin{definition}
	Untyped data models - text, JSON, and tabular data models (e.g. CSV) do \textbf{not} enforce values (container or atomic) to be of specific types. 
	
	These data models are thus referred to as being \textbf{untyped}.
\end{definition}
cf. Grust and Duta (2017) \cite{GrDu2017}


cf. Number 4, "The Relational Data Model", Grust and Duta (2017) \cite{GrDu2017}

\begin{definition}[Types]
Let $\mathbb{T} \equiv $ set of all data types (built-in and user-defined).  \\
$\forall \, $ value $v\in  \mathbb{V}$ stored in a relation cell must be of type $t\in \mathbb{T}$. \\
e.g. When PostgreSQL starts, $\mathbb{T}$ initialized as 
\begin{equation}
 \mathbb{T} = \lbrace \texttt{boolean}, \texttt{integer}, \texttt{text}, \texttt{bytea}, \dots \rbrace 
\end{equation}
Consider category \textbf{Text} s.t. $\text{Obj}(\mathbf{Types}) \equiv DT \in \text{Obj}(\textbf{Set})$. Then $\mathbb{T} \equiv DT$, denoting \emph{data type}.
\end{definition}

\begin{definition}[Values]
$\forall \, v \in \mathbb{V}$ stored in a relation cell, $v$ is an element of the set of all values $\mathbb{V}$. 

in the relational data model, all values $v\in \mathbb{V}$ are "atomic."

\[
\mathbb{V} = \lbrace \texttt{true}, \texttt{false}, 0, -1, 1, -2, 2 , \dots \rbrace
\]	

Here, I'll use the notation $V$ to denote $\mathbb{V}$, the set of all values.
\end{definition}

\begin{definition}[Domains]
	$\forall \, t \in DT$, its domain $\text{dom}(t) := $ set of all values of type $t$ (i.e. $\text{dom}(\cdot)$ is a function with signature 
	\[
	DT \to 2^V
	\])
	e.g. $\text{dom}(\texttt{integer}) = \lbrace 0 , -1, 1, -2, 2, \dots \rbrace $ \\
	$\text{dom}(\texttt{boolean}) = \lbrace \texttt{true}, \texttt{false} \rbrace$ 
\end{definition} 

\begin{definition}[type specification]
	type specification $:= $ function $\pi : U \to \mathbf{DT}$ (Spivak's notation) $ \equiv \pi : U \to DT$, $U, DT \in \textbf{Set}$.
	
	set $DT \equiv $ set of data types for $\pi$, set $U \equiv $ domain bundle for $\pi$.
	
	$\forall \, t \in DT$, preimage $\pi^{-1}(t) \subset U$, \, $\pi^{-1}(t) \equiv $ domain of $t$, $x \in \pi^{-1}(t) \equiv $ object of type $T$.

	To reconcile Grust and Duta (2017) \cite{GrDu2017}'s definition of types above, use this notation:
	\begin{equation}
	\boxed{
	\begin{gathered}
	\textbf{ type specification } \begin{aligned} & \quad \\ 
	& \pi : V \to DT \\ 
	& \pi(v) \in DT \end{aligned} \\
	\text{dom} \equiv \pi^{-1}: DT \to V, \text{ i.e. } \\
	\pi^{-1}(t) \subset t \qquad \, \forall \, t \in DT  
	\end{gathered}}
	\end{equation}
\end{definition}
	cf. Spivak (2009) \cite{Spiv2009}

\begin{corollary}[type specification]
	If $v$ has type $T$, $\pi(v) = T$, $\Longrightarrow v \in \pi^{-1}(T)$
\end{corollary}

\begin{proposition}[\texttt{CREATE DOMAIN}]
	Consider new type $t'$ (SQL command \texttt{CREATE DOMAIN}) so 
	\begin{equation}
	\begin{gathered}
	t' \in DT \\
	\pi^{-1}(t') \subseteq \pi^{-1}(t)
	\end{gathered}
	\end{equation}
\end{proposition}


\section{Relational Data Model}

	\textbf{relational data model} maybe understood as a typed variant of the tabular data model. 
	\begin{enumerate}
		\item $\exists \, $ only 1 container type: \textbf{table} (or: multisets) \textbf{ of rows}
		\item all rows are of same \textbf{row type} which is declared when table is created.
		\item row type \textbf{consists} of sequence of \textbf{atomic types}.
	\end{enumerate}

In the relational data mode, data is exclusively organized in \textbf{relations}, i.e. sets of tuples of data. Data in each \textbf{attribute} (tuple component) is \textbf{atomic}, and of declared \textbf{type}.

\subsection{Schemata and Relations}

In the relational data model, each \textbf{attribute} of a table has a \textbf{declared type}.

If attribute has declared type $t$, the RDBMS will exclusively store values $v$ in that attribute s.t. 
\begin{enumerate}
	\item $v \in \text{dom}(t)$ i.e. $v \in \pi^{-1}(t)$
	\item $v$ can successfully be casted to type $t$
\end{enumerate}

\subsection{Attributes (Columns)}

Let $\mathbb{A}$ denote set of attribute names of all relations.

\subsection{Attribute types}
$\forall \, $ attribute $a\in \mathbb{A}$ has declared (attribute) type $\text{type}(a) = t\in DT$ (i.e. $\text{type}(\cdot)$ is a function with signature $\mathbb{A} \to \mathbb{T}$).

Consider Definition 2.2.3 of Spivak (2009) \cite{Spiv2009}, 

\begin{definition}[simple schema of type $\pi$, $(C,\sigma)$]
	Let type specification $\pi :V \to DT$. 
	
	\textbf{simple schema} of type $\pi$ consists of pair $(C, \sigma)$ where $C$ is a finite (totally) ordered set and function $\sigma : C \to DT$.  $C \equiv $ \textbf{column set} or \textbf{set of attributes} for $\sigma$ and $\pi$ as \emph{type specification for} $\sigma$.
\end{definition}

Compare the notation above. Conclude that
\[
\begin{gathered}
C \equiv \mathbb{A}, \quad \, c \equiv a \\
\sigma(c) \equiv \text{type}(a)
\end{gathered}
\]

Here, choose the following notation:
\[
\boxed{\begin{gathered}
\sigma : C \to DT \\
\pi^{-1}: DT \to V \\
\pi^{-1} \circ \sigma \equiv \text{val} \equiv \text{set of (admissable) attribute values for attribute (column) $a$ ($c$)}
\end{gathered} }
\]
Also, summarize our definitions with these commutative diagrams:
\begin{equation}
\begin{gathered}
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=3em, column sep=4em, minimum width=2em]
{
	V     \\
	DT  \\
};
\path[->]
(m-1-1) edge node [left] {$\pi$} (m-2-1)
;
\end{tikzpicture}  \qquad \, 
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=3em, column sep=4em, minimum width=2em]
{
	v     \\
	t  \\
};
\path[|->]
(m-1-1) edge node [left] {$\pi$} (m-2-1)
;
\end{tikzpicture}  \qquad \, 
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=3em, column sep=4em, minimum width=2em]
{
	V &  \pi^{-1}(DT)  \\
	DT &  \\
};
\path[left hook->]
(m-1-2) edge node [above] {$i$} (m-1-1)
;
\path[->] 
(m-2-1) edge node [left] {$i \circ \pi^{-1}$} (m-1-1)
edge node [left] {$\pi^{-1}$} (m-1-2)
;
\end{tikzpicture} \qquad \, 
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=3em, column sep=4em, minimum width=2em]
{
	V &  V_t \subseteq V  \\
	t &  \\
};
\path[left hook->]
(m-1-2) edge node [above] {$i$} (m-1-1)
;
\path[|->] 
(m-2-1) edge node [left] {$\pi^{-1}$} (m-1-2)
;
\end{tikzpicture} \\
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=3em, column sep=4em, minimum width=2em]
{
	V &  \pi^{-1}(DT)  \\
	DT &  C \\
};
\path[left hook->]
(m-1-2) edge node [above] {$i$} (m-1-1)
;
\path[->] 
(m-2-1) edge node [left] {$i \circ \pi^{-1}$} (m-1-1)
edge node [left] {$\pi^{-1}$} (m-1-2)
(m-2-2) edge node [right] {$\pi^{-1} \circ \sigma \equiv \text{dom} \circ \text{type} $} (m-1-2)
edge node [above] {$\sigma$} (m-2-1)
;
\end{tikzpicture} \qquad \, 
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=3em, column sep=4em, minimum width=2em]
{
	V &  \pi^{-1}(\sigma(c_i)) = V_{c_i}  \\
	\sigma(c_i) \equiv t_i & c_i \\
};
\path[left hook->]
(m-1-2) edge node [above] {$i$} (m-1-1)
;
\path[|->] 
(m-2-1) edge node [left] {$\pi^{-1}$} (m-1-2)
(m-2-2) edge node [above] {$\sigma$} (m-2-1)
edge node [right] {$\pi^{-1} \circ \sigma$} (m-1-2)
;
\end{tikzpicture} 
\end{gathered}
\end{equation}


\begin{definition}[Relation Schema]
	A relation schema associates a relation (table?) name $R$ with its set of declared attributes (a subset of $\mathbb{A}$)
	\begin{equation}
	(R, \lbrace a_1, \dots a_n \rbrace)
	\end{equation}
Common notation: $R(a_1, \dots a_n)$, so that $R$ is called a $n$-ary relation.

More notation: $\text{sch}(R) = \lbrace a_1, \dots a_n \rbrace$, and $\text{deg}(R) = n$ (degree).
		
\textbf{Relational database schema}: a non-empty finite set of relation schemata makes a \textbf{relational database schema}
\begin{equation}
\lbrace (R_1, \alpha_1), (R_2, \alpha_2) , \dots \rbrace 
\end{equation}
where $\alpha_i \subseteq \mathbb{A}_i$. In a relational database schema, the relation names $R_i$ are unique.		
\end{definition}

\begin{definition}[Tuple]
	Given relation (i.e. table) $R(a_1, \dots , a_n)$, a \textbf{tuple} $t$ of $R$ maps attributes to values, i.e. $t$ is a function with signature $\lbrace a_1, \dots a_n \rbrace \to V$ with 
	\[
	\forall \, a \in \lbrace a_1 , \dots , a_n \rbrace : t(a) \in \text{val}(a)
	\]
	Common notation for $t(a)$ is $t.a$.
\end{definition}

Recall that $\text{val}(a) := \text{dom}(\text{type}(a))$.

Take note that \textbf{tuple}, defined by Grust and Duta (2017) \cite{GrDu2017}, is the \emph{same} as \textbf{record} or \textbf{row} $r$, defined by Spivak (2009) \cite{Spiv2009}.

\begin{definition}[record or row]
	\textbf{record} or \textbf{row} on $(C, \sigma)$
	\begin{equation}
	\begin{aligned}
	& r: C \to V_{\sigma} \equiv V_c \\ 
	& r(c) \equiv v_{rc} \in \pi^{-1}\circ \sigma(c)
	\end{aligned}
	\end{equation}
\end{definition} 

SQL \texttt{CREATE TABLE} command prescribes an order of the attributes of a relation. This deviates from relational data model's tuple model (name-to-value mapping).

\begin{definition}[Row]
	Given SQL table $R(a_1, \dots, a_n) \equiv R(\alpha) \equiv \tau$, a row $r$ of $\tau$ is an ordered sequence ($a_i$ is called the $i$th column)
	\begin{equation}
	r = (v_1, \dots, v_n) \in \text{val}(a_1) \times \dots \times \text{val}(a_n) \equiv \pi^{-1} \circ \sigma(a_1) \times \dots \times \pi^{-1} \circ \sigma(a_n)
	\end{equation}
	Thus, $r$ is a function $\lbrace 1, \dots , n \rbrace \to V$ with $\forall \, i \in \lbrace 1 , \dots , n \rbrace$, $r(i) \in \pi^{-1} \circ \sigma(a_i)$
\end{definition}

The set of tuples (rows) stored in a relation (table) is expected to change frequently.

\begin{definition}[Relation instance (state)]
	The current finite set of tuples $t_i \equiv r_i$ of relation (table) $R(a_1, \dots a_n) \equiv (A, \sigma)$ is called the relation's \textbf{instance} (or \textbf{state}).

\[
\text{inst}(R) = \lbrace t_1 , t_2 , \dots t_m \rbrace \Longrightarrow \equiv \Gamma^{\pi}(\sigma) \equiv \Gamma(A, \sigma)
\]

Database (instance) state - The database instance comprises instances of all its relations.
\[
= \lbrace \Gamma(A^i, \sigma^i) \rbrace_i
\]
\end{definition} 

\subsection{Constraints}

cf. Number 5, "Constraints" of Grust and Duta (2017) \cite{GrDu2017}.

\begin{definition}[Constraints]
	An \textbf{integrity constraints} specifies conditions which table states have to satisfy at all times. 
	
	Current set of constraints, $\mathbb{C}$, is integral part of database schema:
	\[
	(\lbrace (R_1, \alpha_1), (R_2, \alpha_2), \dots  \rbrace, \mathbb{C})
	\]
	Set of constraints $\mathbb{C} \equiv$ set of morphisms of table $\tau \equiv \lbrace (R_1,\alpha_1), (R_2, \alpha_2), \dots \rbrace $, $C \subset \text{Mor}{\tau}$. 
\end{definition} 

RDBMS will refuse table state changes that violate any constraint $c\in C$.

\subsection{Key constraints}

\begin{definition}[Key]
Key of a table $R(a_1, \dots, a_n) \equiv (\alpha, \sigma) \equiv (\alpha, \text{type}) :=$ set of columns $K \subseteq \lbrace a_1, \dots, a_n \rbrace$ that unique identifies rows of $R$:
\[
\forall \, t, u \in \text{inst}(R), \, t.K = u.K \Longrightarrow t = u
\]
Read: "If 2 rows agree on the columns in $K$, they are indeed the same row."

I will give the following change of notation a try:
\begin{equation}
\forall \, r_i , r_j \in \lbrace r_i \rbrace_i^{\tau}, \, \text{ if } r_i(K) = r_j(K), \text{ then } r_i = r_j
\end{equation}
\end{definition} 

\begin{equation}
\begin{gathered}
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=3em, column sep=4em, minimum width=2em]
{
	A &  DT  \\
	V_A &  \\
};
\path[->] 
(m-1-1) edge node [above] {$\sigma$} (m-1-2)
edge node [left] {$r$} (m-2-1)
(m-2-1) edge node [right] {$\pi^{-1}$} (m-1-2)
;
\end{tikzpicture} \qquad \, 
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=3em, column sep=4em, minimum width=2em]
{
	a &  t  \\
	V_A &  \\
};
\path[|->] 
(m-1-1) edge node [above] {$\sigma$} (m-1-2)
edge node [left] {$r$} (m-2-1)
(m-2-1) edge node [right] {$\pi^{-1}$} (m-1-2)
;
\end{tikzpicture}
\end{gathered}
\end{equation}


Here's a "dictionary" between the definitions so far for relational databases and familiar terms for tables filled with data: cf. 08-30, Week 1 slides of Yang (2012) \cite{Yang2012}.

database - collection of relations (or tables) \\
relation - table \\
attributes - columns \\
tuple - row - record \\
relation schema - heading (heading for a table?, Grust and Duta (2017) \cite{GrDu2017}) \\
relation contents - body (body of a table?, Grust and Duta (2017) \cite{GrDu2017})

\begin{tabular}{l c r}
	CSV & Relational Model & SQL \\
	& Domain & Domain \\ 
	& Type & Type \\
	& Schema & Schema \\
	File & Relation & Table \\
	Line & Tuple & Row \\
	Field & Attribute & Column
\end{tabular}

Indeed, even Grust and Duta (2017) \cite{GrDu2017} remarks: "You will find that textbooks, papers, practitioners, academics, these slides, and even PostgreSQL use a mixture of terminology. Deal with it."


cf. Slides Number 7, "Referential Integrity" of Grust and Duta (2017) \cite{GrDu2017}.

\begin{definition}[Foreign Keys]
	Let $(S, \alpha)$ and $(T, \beta)$ denote 2 relational schemata (not necessarily distinct), \\
	where $K = \lbrace b_{j_1}, \dots , b_{j_k} \rbrace \subseteq \beta$ is the primary key of $T$. \\
	Let $F = \lbrace a_{i_1}, \dots , a_{i_k} \rbrace \subseteq \alpha $ with $\text{type}(a_{i_h}) = \text{type}(b_{j_h})$, $h \in 1, \dots, k$. 
	
	$F$ is a \textbf{foreign key} in $S$ \textbf{referencing} $T$, if 
	\[
	\forall \, s \in \text{inst}(S) : \exists \, t \in \text{inst}(T) : s.F = t.K
	\]
\end{definition} 
The $\forall$ and $\exists $ condition validates the assumption of $K$ being a key in target $T$, i.e. that there \textbf{exists a row} in table $T$ whose $K$ identifier matches that of table $S$

$K$ being a key in target $T$ validates the assumption that there is \textbf{no more than one row} of in a table $T$ with a matching key $K$.

In general, \textbf{ a foreign key $F$ is not a key} in source table $S$. 2 rows $s_1, s_2 \in \text{inst}(S)$ with $s_1.F = s_2.F$ can refer to the same row in target $T$.

Here is a great example of a foreign key: \url{https://www.w3schools.com/sql/sql_foreignkey.asp}

So from w3schools, 

"A FOREIGN KEY is a key used to link 2 tables together.

A FOREIGN KEY is a field (or collection of fields) in 1 table that refers to the PRIMARY KEY in another table.

The table containing the foreign key is called the child table, and the table containing the candidate key is called the referenced or parent table.

"Persons" table:

\begin{tabular}{|l |c |c |r|}
\textbf{PersonID} & \textbf{LastName} & \textbf{FirstName} & \textbf{Age} \\
1 & Hansen & Ola & 30 \\
2 & Svendson & Tove & 23 \\
3 & Pettersen & Kari & 20 
\end{tabular}

"Orders" table:

\begin{tabular}{ | l | c | r | }
	\textbf{OrderID} & \textbf{OrderNumber} & \textbf{PersonID} \\ 
	1 & 77895 & 3 \\
	2 & 44678 & 3 \\
	3 & 22456 & 2 \\
	4 & 24562 & 1 
\end{tabular}

Notice that the "PersonID" column in the "Orders" table points to the "PersonID" column in the "Persons" table.

The "PersonID" column in the "Persons" table is the PRIMARY KEY in the "Persons" table.

The "PersonId" column in the "Orders" table is a FOREIGN KEY in the "Orders" table.

\quad \\
Thus, in other words, \\
given 2 tables (i.e. 2 relational schemata, not necessarily distinct), $(S, \alpha)$, $(T,\beta)$, \\
given primary key $PK = \lbrace b_{j_1}, \dots, b_{j_k} \rbrace \subseteq \beta$, primary key of of $T$, and \\
given foreign key $FK = \lbrace a_{i_1} , \dots , a_{i_k} \rbrace \subseteq \alpha$ s.t.
\[
\begin{gathered}
\text{type}(a_{i_h}) = \text{type}(b_{j_h}), \quad \, h \in 1, 2 , \dots k \\
\text{(alternate notation)}  \sigma(a_{i_h}) = \sigma(b_{j_h})
\end{gathered}
\]
then \\
$\forall \, s \in \text{inst}(S), \, \exists \, t \in \text{inst}(T)$ ((alternate notation) $s\in \Gamma(S), \, t\in \Gamma(T)$), s.t.
\[
s(FK) = t(PK)
\]

Describe this categorically as
\[
\begin{tikzpicture}
%\matrix(m)[matrix of math nodes, row sep=3em, column sep=3em, text height=1.5ex, text depth=0.25ex]
\matrix(m)[matrix of math nodes, row sep=4em, column sep=4em]
{
	S   &  T  \\
};
%\path[->,font=\scriptsize]
\path[->]
(m-1-1) edge node[auto]{$FK$} (m-1-2)
;
\end{tikzpicture} 
\]
which is from the introductory talk by Spivak (2012)\cite{Spiv2012}, "What does equivalence of paths mean?", where it states, "arrows represent foreign keys", "from table $a$ to table $b$," and where "we can take any record in table $a$ and return a record in table $b$.

\subsection{Functional Dependency}

\begin{definition}[Functional Dependency (FD)]
	cf. Slides Number 10, "Functional Dependencies" of Grust and Duta (2017) \cite{GrDu2017}.
	
	Let $(R, \alpha) \equiv $ relational schema. Given $\beta \subseteq \alpha$, $c\in \alpha$, \\
	\textbf{functional dependency} $\beta \to c$ holds in $R$ if 
	\[
	\forall \, t, u \in \text{inst}(R), \, t.\beta = u.\beta \Longrightarrow t.c = u.c
	\]
	Notation: the functional dependency $\beta \to \lbrace c_1, \dots , c_n \rbrace $ abbreviates set of FDs $\beta \to c_1, \dots , \beta \to c_n$.
	
	cf. \href{https://en.wikipedia.org/wiki/Functional_dependency}{"Functional dependency", wikipedia}
	
	A set of attributes $X \subseteq R$ ($\equiv X \subseteq \alpha$ for $R = (R,\alpha)$) is said to functionally determine another set of attributes $Y \subseteq R$ ($\equiv Y \subseteq \alpha$), written $X\to Y$. ($\equiv \beta \to c$) \\
	iff $\forall \, X$ value in $R$ is associated with precisely 1 $Y$ value in $R$; $R$ is then said to satisfy the functional dependency $X\to Y$
\end{definition}

e.g. Cars: $\beta = $ vehicle identification number (VIN), $c=$ Engine capacity (because assume a car cannot have 2 engines).

e.g Employee department: \\
$\beta = $ employee ID, \qquad \, $c = $ employee name. \\
$\beta = $ employee ID, \qquad \, $c = $ department ID. \\
$\beta = $ department ID, \qquad \, $c = $ department name.

Recall definition of injective function, $f:X \to Y$,
\[
\forall \, a,b \in X, \, f(a) = f(b) \Longrightarrow a =b
\]

Instead of writing the functional dependency (FD) with this notation: given $\beta, c \subseteq \alpha$, 
\[
\begin{gathered} 
\forall \, r_1, r_2 \in \text{inst}(R) \equiv \Gamma(\alpha), \, r_1(\beta) = r_2(\beta), \Longrightarrow r_1(c) = r_2(c) \\
\end{gathered} 
\]
\emph{rewrite} this as follows:

\begin{equation}
\begin{gathered} 
	\text{ Given } \\
	\begin{aligned} 
	& \beta : \Gamma(\alpha) \to \text{val}(\beta) \equiv \text{dom}(\text{type}(\beta)) \equiv \pi^{-1} \circ \sigma(\beta), \, \\
	& c : \Gamma(\alpha) \to \text{val}(c) \equiv \text{dom}(\text{type}(c)) \equiv \pi^{-1} \circ \sigma(c), \end{aligned} \\
\forall \, r_1, r_2 \in \text{inst}(R) \equiv \Gamma(\alpha), \, \beta(r_1), \beta(r_2) \in \text{val}(\beta)  \\
\text{ Then } \beta \in \text{Hom}(\text{inst}(R), \text{val}(\beta)) \equiv \text{Hom}(\Gamma(\alpha), \pi^{-1}\circ \sigma(\alpha))
\end{gathered} 
\end{equation}

So define a \textbf{functional dependency} $FD$ as 
\begin{equation}
\begin{gathered}
	\begin{aligned} 
&	\text{FD} : 2^{\alpha} \to 2^{\alpha} \\
& \text{FD} : \beta \mapsto c \text{ i.e. } \boxed{ FD(\beta) = c }
\end{aligned} 
\end{gathered}
\end{equation}
where $\beta, c \in 2^{\alpha} \equiv $ power set of $\alpha$, i.e. set of all subsets of $\alpha$, so that $\beta, c \subseteq \alpha$.  

Let $FD^{-1}:2^{\alpha} \to 2^{\alpha}$, s.t. $FD^{-1}(c) = \beta$.

So if $\forall \, r_1, r_2 \in \text{inst}(R) \equiv \Gamma(\alpha)$, for $\beta \subseteq \alpha$, $\beta(r_1), \beta(r_2) \in \text{val}(\beta)$. Then $\beta \in \text{Hom}(\text{inst}(R), \text{val}(\beta)) \equiv \text{Hom}(\Gamma(\alpha), \pi^{-1}\circ \sigma(\alpha))$.

Suppose $\beta(r_1) = \beta(r_2)$. The \emph{key insight} is the following:

\begin{equation}
\beta(r_1) = \beta(r_2) = \text{FD}^{-1}(c)(r_1) = \text{FD}^{-1}(c)(r_2) = (\text{FD}^{-1}\circ c)(r_1) = (\text{FD}^{-1}\circ c)(r_2)
\end{equation}

Then $c(r_1) = c(r_2)$ implies that $\text{FD}^{-1}$ is \emph{injective}.

Then $\text{FD}^{-1}$ is a \emph{monomorphism}, and $\text{FD}^{-1}$ is injective, since $\forall \, r_1, r_2 \in \text{inst}(R) \equiv \Gamma(\alpha)$,
\begin{equation}
\beta(r_1) = \beta(r_2) =  (\text{FD}^{-1}\circ c)(r_1) = (\text{FD}^{-1}\circ c)(r_2) \Longrightarrow c(r_1) = c(r_2)
\end{equation} 

\[
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=1.8em, column sep=1.8em, minimum width=1.2em]
{
	\text{inst}(R) & \text{val}(C) & \text{val}(\beta) \\
};
\path[->]
(m-1-1) edge node [above] {$c$} (m-1-2)
(m-1-2) edge node [above] {$\text{FD}^{-1}$} (m-1-3)
;
\end{tikzpicture} 
\]

Then conclude that 
\begin{theorem}
	Given a relational schema $(R, \alpha)$, a set of attributes $\alpha$, instance of the relation (i.e. a table), $\text{inst}(R) \equiv \Gamma(\alpha)$, and $\beta, c \subseteq \alpha$, \\ for morphisms $\beta, c$, 
\[	\begin{aligned}
		& \beta \in \text{Hom}(\Gamma(\alpha), \text{val}(\beta)) \\
		& c \in \text{Hom}(\Gamma(\alpha), \text{val}(c))
	\end{aligned}
	\]
Then for $\text{FD}:2^{\alpha} \to 2^{\alpha}$, $\text{FD}(\beta) =c$, $\text{FD}^{-1}$ is a \textbf{monomorphism}, i.e. $\forall \, r_1, r_2 \in \Gamma(\alpha)$,
\[
\beta(r_1) = \beta(r_2) = (\text{FD}^{-1}\circ c)(r_1) = (\text{FD}^{-1}\circ c)(r_2) \text{ i.e. } (\text{FD}^{-1}\circ c) = (\text{FD}^{-1} \circ c)
\]
then $c(r_1) = c'(r_2) $ i.e. $c=c'$.
\end{theorem}

Database Queries and Constraints via Lifting Problems. David I. Spivak.
\url{https://arxiv.org/pdf/1202.2591.pdf}

\section{Databases and Categories}

cf. Spivak (2012) \cite{Spiv2012}.

$A \xrightarrow{\text{FK}} B$, \, $A, B \in \text{Obj}(\mathbf{DB})$


\part{Reading notes on Cox, Little, O'Shea's \emph{Ideals, Varieties, and Algorithms: An Introduction to Computational Algebraic Geometry and Commutative Algebra}}

\section{Geometry, Algebra, and Algorithms}

\subsection{Polynomials and Affine Space}

fields are important is that linear algebra works over \emph{any} field

\begin{definition}[2] set of all polynomials in $x_1 , \dots , x_n$ with coefficients in $k$, denoted $k[x_1, \dots , x_n]$

\end{definition}

polynomial $f$ \emph{divides} polynomial $g$ provided $g= fh$ for some $h \in k[x_1, \dots , x_n ]$

$k[x_1, \dots, x_n]$ satisfies all field axioms except for existence of multiplicative inverses; commutative ring, $k[x_1, \dots , x_n]$ \emph{polynomial ring}


\subsubsection*{Exercises for 1}

\exercisehead{1}
$\mathbb{F}_2$ commutative ring since it's an abelian group under addition, commutative in multiplication, and multiplicative identity exists, namely $1$.  It is a field since for $1\neq 0$, the multiplicative identity is $1$.  

\exercisehead{2}
\begin{enumerate}
\item[(a)]
\item[(b)]
\item[(c)]
\end{enumerate}




\subsection{Affine Varieties }


\subsection{Parametrizations of Affine Varieties}


\subsection{Ideals}



\subsection{Polynomials of One Variable}




\section{Groebner Bases}

\subsection{Introduction}




\subsection{Orderings on the Monomials in $k[x_1, \dots , x_n]$ }




\subsection{A Division Algorithm in $k[x_1, \dots , x_n ]$ }



\subsection{Monomial Ideals and Dickson's Lemma }


\subsection{The Hilbert Basis Theorem and Groebner Bases}


\subsection{Properties of Groebner Bases}



\subsection{Buchberger's Algorithm}






\section{Elimination Theory}



\subsection{The Elimination and Extension Theorems}


\subsection{The Geometry of Elimination}



\section{The Algebra-Geometry Dictionary}


\subsection{Hilbert's Nullstellensatz}


\subsection{Radical Ideals and the Ideal-Variety Correspondence}



\section{Polynomial and Rational Functions on a Variety}


\subsection{Polynomial Mappings }


\section{Robotics and Automatic Geometric Theorem Proving}



\subsection{Geometric Description of Robots}






\part{Reading notes on Cox, Little, O'Shea's \emph{Using Algebraic Geometry}}

\textbf{Using Algebraic Geometry}.  David A. Cox.  John Little. Donal O'Shea. Second Edition.  Springer.  2005.  ISBN 0-387-20706-6 QA564.C6883 2004

\section{ Introduction }

\subsection{ Polynomials and Ideals }

\emph{monomial } 

\begin{equation}
  (1.1) \quad \quad \, x_1^{\alpha_1} \dots x_n^{\alpha_n}
\end{equation}

total degree of $x^{\alpha}$ is $\alpha_1 + \dots + \alpha_n \equiv |\alpha|$ \\



field $k$, $k[x_1 \dots x_n]$ collection of all polynomials in $x_1 \dots x_n$ with coefficients $k$.   \\

polynomials in $k[x_1 \dots x_n]$ can be added and multiplied as usual, so $k[x_1 \dots x_n]$ has structure of commutative ring (with identity) \\
however, only nonzero constant polynomials have multiplicative inverses in $k[x_1 \dots x_n]$, so $k[x_1 \dots x_n]$ not a field \\
\quad however set of rational functions $\lbrace f/g | f,g \in k[x_1 \dots x_n], \, g\neq 0\rbrace$ is a field, denoted $k(x_1 \dots x_n)$ \\

so
\[
f = \sum_{\alpha} c_{\alpha}x^{\alpha}
\]
where $c_{\alpha} \in k$

so

\[
f \in k [x_1 \dots x_n ] = \lbrace f | f = \sum_{\alpha} c_{\alpha} x^{\alpha} , x^{\alpha} = x_1^{\alpha_1} \dots x_n^{\alpha_n}, c_{\alpha} \in k \rbrace
\]

$f$ homogeneous if all monomials have same total degrees

polynomial $f$ is homogeneous if all monomials have the \emph{same total degree} \\

Given a collection of polynomials $f_1 \dots f_s \in k[x_1 \dots x_n]$, we can consider all polynomials which can be built up from these by multiplication by arbitrary polynomials and by taking sums

\begin{definition}[1.3] Let $f_1 \dots f_s \in k[x_1 \dots x_n]$ \\
Let $\langle f_1 \dots f_s \rangle = \lbrace p_1 f_1  + \dots + p_s f_s | p_i \in k[x_1 \dots x_n] \text{ for } i = 1 \dots s \rbrace$
\end{definition}


\exercisehead{1} 
\begin{enumerate}
\item[(a)] $x^2 = x \cdot ( x  -y^2 ) + y \cdot ( xy )$  
\item[(b)] 
\[
 p \cdot ( x - y^2 ) = p x - p y^2
\]
and for $p xy = (py)x$
\item[(c)] 
\[
p(y) ( x - y^2) = p(y)x - p(y) y^2 \notin \langle x^2, xy \rangle
\]
\end{enumerate}

\exercisehead{2} 
\[
\begin{gathered}
  \sum_{i=1}^s p_i f_i  + \sum_{j=1}^s q_j f_j = \sum_{i=1}^s (p_i + q_i )f_i, \quad \, p_i + q_i \in k[x_1 \dots x_n] \end{gathered}
\]
$\langle f_1 \dots f_s \rangle$ closed under sums in $k[x_1 \dots x_n]$ \\

If $f\in \langle f_1 \dots f_s \rangle$, \\
\phantom{If }$ p \in k [x_1 \dots x_n]$

\[
\begin{gathered}
p\cdot f = p \sum_{i=1}^s q_j f_j = \sum_{i=1}^s pq_j f_j, \quad \, pq_j \in k[x_1 \dots x_n] \text{ so }  \\
p\cdot f \in \langle f_1 \dots f_s \rangle
\end{gathered}
\]

Done.  \\

The 2 properties in Ex. 2 are defining properties of ideals in the ring $k[x_1 \dots x_n]$

\begin{definition}[1.5]
Let $I \subset k[x_1 \dots x_n]$, \, $I \neq \emptyset$ \\
$I$ ideal if 
\begin{enumerate}
\item[(a)] $f+ g \in I$, \, $\forall \, f,g \in I$ 
\item[(b)] $pf \in I$, \, $\forall \, f \in I$, arbitrary $p \in k[x_1 \dots x_n]$
\end{enumerate}
\end{definition}

Thus $\langle f_1 \dots f_s\rangle$ is an ideal by Ex. 2.  \\

we call it the ideal generated by $f_1 \dots f_s$.  

\exercisehead{3} Suppose $\exists \, $ ideal $J$, $f_1 \dots f_s \in J$ s.t. $J \subset \langle f_1 \dots f_s \rangle$ \\
if $f\in \langle f_1 \dots f_s \rangle$, $f = \sum_{i=1}^s p_i f_i$, \, $p_i \in k[x_1 \dots x_n]$ \\

$\forall \, i = 1 \dots s$, $p_i f_i \in J$ and so $\sum_{i=1}^s p_i f_i \in J$, by def. of $J$ as an ideal.

\[
\langle f_1 \dots f_s \rangle \subseteq J \quad \quad \, \Longrightarrow J = \langle f_1 \dots f_s \rangle
\]

$\Longrightarrow \langle f_1 \dots f_s \rangle$ is smallest ideal in $k[x_1 \dots x_n]$ containing $f_1 \dots f_s$


\exercisehead{4} For $\begin{aligned} & \quad \\
  & I = \langle f_1 \dots f_s \rangle \\
  & J = \langle g_1 \dots g_t \rangle \end{aligned}$ \\

 $I = J$ iff $s=t$ and $\forall \, f \in I$, $f = \sum_{i=1}^t q_i g_i$ and if $ 0  = \sum_{i=1}^t q_i g_i$, $q_i =0$, \, $\forall \, i = 1 \dots t$, and if $0 = \sum_{i=1}^s p_i f_i$, \, $p_i = 0$, \, $\forall \,  i = 1 \dots s$


\begin{definition}[1.6]
\[
\sqrt{I} = \lbrace g \in k[x_1\dots x_n] | g^m \in I \text{ for some } m \geq 1 \rbrace
\]
\end{definition}

e.g. $x+y \in \sqrt{ \langle x^2 + 3 xy , 3xy + y^2 \rangle }$

in $\mathbb{Q}[x,y]$ since 

\[
(x+y)^3 =x(x^2 + 3xy) + y(3xy + y^2) \in \langle x^2 + 3xy, 3xy + y^2\rangle
\]


%\begin{definition}[1.6]
%\[
%\sqrt{I } = \lbrace g \in k[x_1 \dots x_n ] | g^m \in I \text{ for some m } \geq 1 \rbrace
%\]
%\end{definition}

%e.g. $x+y \in \sqrt{ \langle x^2 + 3xy, 3xy + y^2 \rangle }$

%in $\mathbb{Q}[x,y]$ since

%\[
%(x+y)^3 = x(x^2 + 3xy) + y(3xy + y^2) \in \langle x^2 + 3xy, 3xy + y^2 \rangle
%\]

\begin{itemize}
\item (Radical Ideal Property) $\forall \, $ ideal $I\subset k[x_1 \dots x_n]$, $\sqrt{I}$ ideal, $\sqrt{I} \supset I$
\item \textbf{(Hilbert basis Thm.)} $\forall \, $ ideal $I\subset k[x_1\dots x_n]$ \\
$\exists \, $ finite generating set, \\
i.e. $\exists \, \lbrace f_1 \dots f_2 \rbrace \subset k [x_1 \dots x_n]$ s.t. $I=\langle f_1 \dots f_s \rangle$
\item (Division Algorithm in $k[x]$) $\forall \, f,g \in  k[x]$ (EY : in 1 variable) \\
$\forall \, f, g \in k[x]$ (in 1 variable )\\
$f= qg + r$, $\exists \, !$ quotient $q$, $\exists \, $ remainder $r$
\end{itemize}

\subsection{}

\subsection{Gr\"obner Bases}

\begin{definition}[3.1]
  Gr\"obner basis for $I$ $\equiv G = \lbrace g_1 \dots g_k \rbrace \subset I$ s.t. $\forall \, f \in I$, $\text{LT}(f)$ divisible by $\text{LT}(g_i)$ for some $i$
\end{definition}

\begin{itemize}
\item (Uniqueness of Remainders) let ideal $I\subset k[x_1 \dots x_n]$ \\
division of $f\in k[x_1 \dots x_n]$ by Gr\"o bner basis for $I$, produces $f=g+r$, $g\in I$, and no term in $r$ divisible by any element of $\text{LT}(I)$
\end{itemize}





\subsection{Affine Varieties}

affine $n$-dim. space over $k$ \quad \, $k^n = \lbrace (a_1 \dots a_n ) | a_1 \dots a_n \in k \rbrace$

$\forall \, $ polynomial $f\in k[x_1 \dots x_n ]$, $(a_1 \dots a_n) \in k^n$ \\
\phantom{ \quad } $f: k^n \to k$ \\
\phantom{ \quad } $f(a_1 \dots a_n)$ s.t. $x_i = a_i$ i.e. \\

if $f= \sum_{\alpha} c_{\alpha} x^{\alpha}$ for $c_{\alpha} \in k$, then  \\
\phantom{ \quad } $f(a_1 \dots a_n) =\sum_{\alpha} c_{\alpha}a^{\alpha} \in k$, where $a^{\alpha} = a_1^{\alpha_1} \dots a_n^{\alpha_n}$

\begin{definition}[4.1]
affine variety $\mathbf{V}(f_1 \dots f_s) = \lbrace ( a_1 \dots a_n) | (a_1 \dots a_n) \in k^n, \, f_1(x_1 \dots x_n) = \dots = f_s(x_1 \dots x_n) = 0 \rbrace$ \\
subset $V\subset k^n$ is affine variety if $V = V(f_1 \dots f_s)$ for some $\lbrace f_i \rbrace$, polynomial $f_i \in k[x_1 \dots x_n]$
\end{definition}

\begin{itemize}
  \item (Equal Ideals Have Equal Varieties) If $\langle f_1 \dots f_s \rangle = \langle g_1 \dots g_t \rangle$ in $k[x_1 \dots x_n]$, then $\mathbf{V}(f_1 \dots f_s) = \mathbf{V}(g_1 \dots g_t)$
\end{itemize}

so, recap \\
if $\langle f_1 \dots f_s \rangle = \langle g_1 \dots g_t \rangle $ in $k[x_1 \dots x_n]$, \\
then $V(f_1 \dots f_s) = V(g_1 \dots g_t)$   \\

Recall Hilbert basis Thm. $\forall \, $ ideal $I \subset k[x_1 \dots x_n]$ 
\[
I= \langle f_1 \dots f_s \rangle
\]
$\Longrightarrow $ if $I=J$, then $V(I) = V(J)$

think of $V$ defined by $I$, rather than $f_1 = \dots = f_s =0$

\exercisehead{3}

Recall Def. 1.5 Let $I\subset k[x_1 \dots x_n]$ \\
$I$ ideal if $\begin{aligned} & \quad \\
  & f + g \in I  \quad \, \forall \, f,g \in I \\
  & pf \in I, \quad \, \forall \, f \in I \text{ arbitrary } p \in k[x_1 \dots x_n]
\end{aligned}$

Let $f,g \in I(V)$ 
\[
\begin{gathered}
  (f+g)(a_1 \dots a_n) = f(a_1 \dots a_n) + g(a_1 \dots a_n) = 0 + 0 = 0 \quad \quad \, f+g \in I(V) \\ 
  pf(a_1 \dots a_n) = p(a_1 \dots a_n) f(a_1 \dots a_n) = 0 \quad \quad \, pf \in I(V)
\end{gathered}
\]
Then $I(V)$ an ideal.

%\exercisehead{3} Recall Def. 1.5. Let $I \subset k[x_1 \dots x_n]$, $I$ ideal if $\begin{aligned} & \quad \\
%  & f+g \in I \quad \, \forall \, f,g\in I \\
%  & pf \in I , \quad \, \forall \, f \in I, \text{ arbitrary } p \in k[x_1 \dots x_n ] \end{aligned}$

%Let $f,g \in I(V)$ 
%\[

$V = V(x^2)$ in $\mathbb{R}^2$ \\
$I=\langle x^2 \rangle$ in $\mathbb{R}[x,y]$, \, $I= \lbrace px^2 | p \in k[x,y]\rbrace$ \\
\phantom{ \quad } $I \subset I(V)$, since $px^2 = 0$ for $x^2=0$, $(0,b)$, \, $b\in \mathbb{R}$ \\
But $p(x,y) = x\in I(V)$, as 
\[
I(V) = \lbrace f \in k[x_1 \dots x_n] | f(a_1 \dots a_n)=0, \, \forall \, (a_1\dots a_n) \in V\rbrace
\]
\phantom{ \quad \quad } $p(0,b) = x = 0$

But $x\notin I$

\exercisehead{4} $I\subset \sqrt{I}$

Recall Def. 1.6 $\sqrt{I} = \lbrace g \in k[x_1 \dots x_n] |g^m \in I \text{ for some } m\geq 1\rbrace$ \\
$\forall \, f \in I$, $f=f^1$, $m=1$, so $f\in \sqrt{I}$, \quad \, $I\subset \sqrt{I}$ \\
\phantom{\quad \quad } Hilbert basis thm., $\forall \, $ ideal $I\subset k[x_1 \dots x_n]$ s.t. $I=\langle f_1 \dots f_s \rangle$ \\
\phantom{\quad } $V(I) = \lbrace (a_1 \dots a_n) |(a_1 \dots a_n) \in k^n, \, f_1(a_1\dots a_n) = \dots = f_s(a_1\dots a_n)=0\brace$ \\
$\mathbf{I}(\mathbf{V}(I)) = \lbrace f \in k[x_1 \dots x_n] | f(a_1 \dots a_n) =0 \quad \, \forall \, (a_1 \dots a_n) \in V(I) \rbrace$ \\
Let $g\in \sqrt{I}$, \, $g^m \in I$, \, $g^m=g^{m-1}g$  \\
\phantom{\quad \quad \,} $g^m(a_1 \dots a_n) =0 = g^{m-1}(a_1 \dots a_n)g(a_1 \dots a_n) =0$.  Then $g(a_1 \dots a_n)=0$ or $g^{m-1}(a_1\dots a_m)=0$ \\
\phantom{\quad }as $g^m\in I$, and $V(I)$ is s.t. $f_1(a_1 \dots a_n) = \dots = f_s(a_1 \dots a_n)=0$ for $I=\langle f_1 \dots f_s \rangle$

\begin{itemize}
  \item (Strong Nullstellensatz) if $k$ algebraically closed (e.g. $\mathbb{C}$), $I$ ideal in $k[x_1 \dots x_n]$, then 
\[
\mathbf{I}(\mathbf{V}(I) = \sqrt{I}
\]
\item (Ideal-variety correspondence) Let $k$ arbitrary field
\[
\begin{aligned}
  & I \subset I(V(I)) \\ 
  & V(I(V)) = V \quad \, \forall \, V
\end{aligned}
\]
\end{itemize}

\subsection*{Additional Exercises for Sec.4}

\exercisehead{6}



\section{ Solving Polynomial Equations}

\subsection{}

\subsection{Finite-Dimensional Algebras}

Gr\"obner basis $G = \lbrace g_1 \dots g_t \rbrace$ of ideal $I\subset k[x_1\dots x_n]$, \\
recall def.: Gr\"obner basis $G = \lbrace g_1 \dots g_t\rbrace \subset I$ of ideal $I$, \, $\forall \, f \in I$, $\text{LT}(f)$ divisible by $\text{LT}(g_i)$ for some $i$ \\
\phantom{\quad \, } $f \in k[x_1\dots x_n]$ divide by $G$ produces $f=g+r$, $g\in I$, $r$ not divisible by any $\text{LT}(I)$ uniqueness of $r$ \\
$f\in k[x_1 \dots x_n]$ divide by $G$, 

Recall from Ch. 1, divide $f\in k[x_1 \dots x_n]$ by $G$, the division algorithm yields

\begin{equation}
  (2.1)  \quad \quad \quad \, f = h_1 g_1 + \dots + h_t g_t + \overline{f}^G
\end{equation}
where remainder $\overline{f}^G$ is a linear combination of monomials $x^{\alpha} \notin \langle \text{LT}(I) \rangle $ \\
\phantom{\quad } since Gr\"obner basis, $f\in I$ iff $\overline{f}^G=0$

$\forall \, f \in k[x_1\dots x_n]$, we have coset $[f] = f+I = \lbrace f +h|h\in I\rbrace$ s.t. $[f]=[g]$ iff $f- g \in I$

We have a 1-to-1 correspondence 
\[
\begin{gathered}
\text{remainders } \leftrightarrow \text{ cosets } \\
\overline{f}^G \leftrightarrow [f]
\end{gathered}
\]
algebraic
\[
\begin{aligned}
  & \overline{f}^G + \overline{g}^G \leftrightarrow [f] + [g] \\ 
  & \overline{ \overline{f}^G \cdot \overline{g}^G } \leftrightarrow [f]\cdot [g]
\end{aligned}
\]
$B = \lbrace x^{\alpha} | x^{\alpha} \notin \langle \text{LT}(I) \rangle \rbrace$ is a basis of $A$, basis monomials, standard monomials

20141023 EY's take

$\forall \, [f] \in A = k[x_1 \dots x_n]/I$, \, $[f] = p_ib_i$; \, $b_i \in B = \lbrace x^{\alpha} | x^{\alpha} \notin \langle \text{LT}(I) \rangle \rbrace$ \\
For $I = \langle G \rangle$ \\
\phantom{\quad } e.g. $G=\lbrace x^2 + \frac{3}{2} xy + \frac{1}{2} y^2 - \frac{3}{2} x - \frac{3}{2} y, xy^2-x, y^3-y \rbrace$ \\
$\langle \text{LT}(I) \rangle = \langle x^2, xy^2,y^3 \rangle$ \\
e.g. $B=\lbrace 1,x,y,xy,y^2\rbrace$ \\
\phantom{\quad } $[f]\cdot[g] = [fg]$ \\
e.g. $f=x, \, g=xy, \, [fg] = [x^2y]$ \\
now $f=h_1g_1 + \dots +h_tg_t+ \overline{f}^G$

\subsection{}

\subsection{Solving Equations via Eigenvalues and Eigenvectors}


\section{Resultants}

\section{Computation in Local Rings}

\subsection{Local Rings}


\begin{definition}[1.1]
  \[
k[x_1 \dots x_n]_{\langle x_1 \dots x_n \rangle} \equiv \lbrace \frac{f}{g} | \text{ rational functions } \frac{f}{g} \text{ of } x_1 \dots x_n \text{ with } g(p) \neq 0 \text{ at } p \rbrace
\]
\end{definition}

main properties of $k[x_1 \dots x_n]_{\langle x_1 \dots x_n \rangle }$

\begin{proposition}[1.2]
  Let $R= k[x_1 \dots x_n]_{\langle x_1 \dots x_n \rangle }$.  Then
\begin{enumerate}
\item[(a)] $R$ subring of field of rational functions $k(x_1 \dots x_n) \supset k[x_1 \dots x_n]$
\item[(b)] Let $M=\langle x_1 \dots x_n \rangle \subset R$ (ideal generated by $x_1 \dots X_n$ in $R$) \\
Then $\forall \, \frac{f}{g} \in R \backslash M$, $\frac{f}{g}$ unit in $R$ (i.e. multiplicative inverse in $R$)
\item[(c)] $M$ maximal ideal in $R$
\end{enumerate}
\end{proposition}


\exercisehead{1} if $p=(a_1 \dots a_n) \in k^n$, $R = \lbrace \frac{f}{g} | f,g\in k[x_1 \dots x_n] , \, g(p) \neq 0 \rbrace$ 
\begin{enumerate}
\item[(a)] $R$ subring of field of rational functions $k(x_1 \dots x_n)$ 
\item[(b)] Let $M$ ideal generated by $x_1 - a_1 \dots x_n -a_n$ in $R$  \\
Then $\forall \, \frac{f}{g} \in R\backslash M$, $\frac{f}{g}$ unit in $R$ (i.e. multiplicative inverse in $R$)
\item[(c)]  $M$ maximal ideal in $R$
\end{enumerate}


\begin{proof}
let $p = (a_1 \dots a_n) \in k^n$ \\
let $g_1(p) \neq 0$, $g_2(p) \neq 0$ 
\[
\begin{gathered}
  \frac{f_1}{g_1 } + \frac{f_2}{g_2} = \frac{f_1 g_2 + f_2 g_1}{ g_1 g_2 } \quad \quad \,  g_1(p)g_2(p) \neq 0 \text{ so } \frac{f_1}{g_1} + \frac{f_2}{g_2} \in R \\
 \frac{f_1}{g_1} \cdot \frac{f_2}{g_2} = \frac{f_1 f_2}{g_1 g_2} \quad \quad \, g_1(p) g_2(p) \neq 0 \text{ so } \frac{f_1}{g_1}\frac{f_2}{g_2} \in R
\end{gathered}
\]
$f= \frac{f}{I} \in R$, \quad \, $\forall \, f\in k[x_1 \dots x_n]$, so $k[x_1 \dots x_n]\subset R$

\end{proof}

EY : 20141027, to recap, 

Let $V = k^n$ \\
Let $p = (a_1 \dots a_n)$ \\
single pt. $\lbrace p \rbrace$ is (an example of) a variety \\
$I(\lbrace p \rbrace) = \lbrace x_1 -a_1 \dots x_n -a_n \rangle \subset k[x_1 \dots x_n]$ \\

$R \equiv k[x_1 \dots x_n]_{\langle x_1 - a_1 \dots x_n-a_n \rangle }$ 
\[
R = \lbrace \frac{f}{g} | \text{ rational function $\frac{f}{g}$ of $x_1 \dots x_n$, $g(p) \neq 0$, $p=(a_1 \dots a_n) $ } \rbrace
\]

Prop. 1.2. properties 

\begin{enumerate}
\item[(a)] $R$ subring of field of rational functions $k(x_1 \dots x_n)$ \quad \, $k(x_1 \dots x_n) \subset R$ 
\item[(b)] $M = \langle x_1 \dots a_1 \dots x_n -a_n \rangle \subset R$.  ideal generated by $x_1 - a_1 \dots x_n-a_n$ \\
Then $\forall \, \frac{f}{g} \in R\backslash M$, $\frac{f}{g}$ unit in $R$ ( $\exists \, $ multiplicative inverse in $R$ )
\item[(c)] $M$ maximal ideal in $R$. \\
in $R$ we allow denominators that are not elements of this ideal $I(\lbrace p \rbrace)$ 
\end{enumerate}

\begin{definition}[1.3] local ring is a ring that has exactly 1 maximal ideal \end{definition}

\begin{proposition}[1.4] ring $R$ with proper ideal $M\subset R$ is local ring if $\forall \, \frac{f}{g} \in R\backslash M$ is unit in $R$
\end{proposition}

localization Ex. 8, Ex. 9 \\
parametrization

\exercisehead{2} \[
\begin{aligned}
  & x = x(t) = \frac{-2t^2 }{1+t^2} \\ 
 &  y = y(t) = \frac{2t}{1+t^2}
\end{aligned}
\]
$k[t]_{\langle t \rangle}$ \quad \, $\frac{-2t^2}{1+t^2}$ rational function of $t$.  $1+t^2 \neq 0$

if $k = \mathbb{C}$ or $\mathbb{R}$ \\

Consider set of convergent power series in $n$ variables \\

\begin{equation}
(1.5) \quad \quad \,   k\lbrace x_1 \dots x_n \rbrace = \lbrace \sum_{\alpha \in \mathbb{Z}^n_{\geq 0}} c_{\alpha} x^{\alpha} | c_{\alpha} \in k, \text{ series converges in some open $U\ni 0 \in k^n $ } \rbrace
\end{equation}

Consider set $k[[x_1 \dots x_n]]$ of formal power series

\begin{equation}
  (1.6) \quad \quad \, k[[x_1 \dots x_n]] = \lbrace \sum_{\alpha \in \mathbb{Z}^n_{\geq 0}} c_{\alpha} x^{\alpha} | c_{\alpha} \in k \rbrace \text{ series need not converge }
\end{equation} 


variety $V$ \\

$k[x_1\dots x_n]/\mathbf{I}(V)$ \phantom{ \quad \quad \quad } variety $V$


\subsection{Multiplicities and Milnor Numbers}


if $I$ ideal in $k[x_1\dots x_n]$, then denote $Ik[x_1\dots x_n]_{\langle x_1 \dots x_n \rangle}$ ideal generated by $I$ in larger ring $k[x_1\dots x_n]_{\langle x_1 \dots x_n \rangle}$

\begin{definition}[2.1] Let $I$ $0$-dim. ideal in $k[x_1 \dots x_n]$, so $V(I)$ consists of finitely many pts. in $k^n$.  \\
Assume $(0 \dots 0) \in V(I)$ \\
multiplicity of $(0\dots 0)\in V(I)$ is 
\[
\text{dim}_k{ k[x_1\dots x_n]_{\langle x_1\dots x_n \rangle}} / Ik[x_!\dots x_n]_{\langle x_1 \dots x_n \rangle}
\]
\end{definition}


generally, if $p=(a_1 \dots a_n) \in V(I)$ \\
multiplicity of $p$, $m(p) = \text{dim}{ k[x_1 \dots x_n]_M } / Ik[x_1 \dots x_n]_M$

\[
\text{dim}{ k[x_1 \dots x_n]_M } / Ik[x_1 \dots x_n]_M
\]

localizing $k[x_1 \dots x_n]$ at maximal ideal $M = I(\lbrace p \rbrace) = \langle x_1 - a_1 \dots x_n-a_n \rangle$


\section{}

\section{}

\section{ Polytopes, Resultants, and Equations }

\section{ Polyhedral Regions and Polynomials }

\subsection{ Integer Programming }

Prop. 1.12. \\

Suppose 2 customers $A, B$ ship to same location \\
\quad A: ship 400 kg pallet taking up $2 \, m^3$ volume \\
\quad B: ship 500 kg pallet taking up $3 \, m^3$ volume \\

shipping firm trucks carry up to 3700 \, kg, up to $20 \, m^3$ \\

B's product more perishable, paying \$ 15 per pallet \\

A pays \$ 11 per pallet

How many pallets from A, B each in truck to maximize revenues?

\begin{equation}
(1.1) \quad \quad \, \begin{gathered}
    4A + 5B \leq 37 \\
    2A  + 3B \leq 20 \\
    A, B \in \mathbb{Z}^*_{ \geq 0 } \end{gathered}
\end{equation}

maximize $11 A + 15 B$ \\

integer programming. \\
max. or min. value of some linear function 

\[
l(A_1 \dots A_n) = \sum_{i=1}^n c_i A_i 
\]

on set $(A_1 \dots A_n) \in \mathbb{Z}^n_{ \geq 0}$ s.t. 


3. Finally, by introducing additional variables; rewrite linear constraint inequalities as equalities. The new variables are called ``slack variables''

\begin{equation}
(1.4) \quad \quad \, a_{ij} A_j = b_i, \quad \, A_j \in \mathbb{Z}_{\geq 0}
\end{equation}

introduce indeterminate $z_i$, \, $\forall \, $ equation in (1.4)

\[
z_i^{a_{ij} A_j} = z_i^{b_i}
\]

$m$ constraints

\[
\prod_{i=1}^m z_i^{a_{ij}A_j} = \prod_{i=1}^m z_i^{b_i} = \left( \prod_{i=1}^m z_i^{a_{ij}} \right)^{ A_j}
\]

\begin{proposition}[1.6]
  Let $k$ field, define $\varphi: k[w_1 \dots w_n] \to k[z_1 \dots z_m]$ by 
\[
\varphi(w_j) = \prod_{i=1}^m z_i^{a_{ij}} \quad \quad \quad \, \forall \, j = 1 \dots n 
\]

and 

\[
\varphi(g(w_1 \dots w_n) ) = g(\varphi(w_1) \dots \varphi(w_n))
\]
$\forall \, $ general polynomial $g\in k[w_1 \dots w_n]$

Then $(A_1 \dots A_n)$ integer pt. in feasible region iff $\varphi: w_1^{A_1} \dots w_n^{A_n} \mapsto z_1^{b_1} \dots z_m^{b_m}$



\end{proposition}

\exercisehead{3}

Now 

\[
\begin{gathered}
\varphi(w_j) = \prod_{i=1}^m z_i^{a_{ij}} \\
z_i^{a_{ij} A_j} = z_i^{b_i}
\end{gathered}
\]

If $(A_1 \dots A_n)$ an integer pt. in feasible region, $a_{ij} A_j = b_i$

\[
\begin{gathered}
z_i^{a_{ij}A_j } = z_i^{b_i} = \prod_{j=1}^n z_i^{a_{ij} A_j} \Longrightarrow \prod_{j=1}^n \prod_{i=1}^m (z_i^{a_{ij} })^{A_j} = \prod_{i=1}^m z_i^{b_i} = \prod_{j=1}^n \varphi(w_j)^{ A_j} = \prod_{j=1}^n \varphi(w_j)^{A_j} = \varphi\left( \prod_{j=1}^n w_j^{ A_j } \right) = \prod_{i=1}^m z_i^{b_i}
\end{gathered}
\]
since $\varphi(g(w_1 \dots w_n)) = g(\varphi(w_1) \dots \varphi(w_n))$ \\

If $\varphi: \prod_{j=1}^n w_j^{A_j} \mapsto \prod_{i=1}^m z_i^{b_i}$

\[
\varphi\left( \prod_{j=1}^n w_j^{A_j} \right) = \prod_{j=1}^n (\varphi(w_j))^{A_j} = \prod_{i=1}^m z_i^{b_i} = \prod_{j=1}^n \left( \prod_{i=1}^m z_i^{a_{ij}} \right)^{ A_j} \Longrightarrow \prod_{j=1}^n z_i^{a_{ij} A_j} = z_i^{b_i}
\]
or $a_{ij}A_j = b_i$.  So $(A_1\dots A_n)$ integer pt.  




\exercisehead{4} 
\[
\prod_{i=1}^m z_i^{b_i} = \prod_{i=1}^m \prod_{j=1}^n z_i^{ a_{ij} A_j } = \prod_{j=1}^n \left( \prod_{i=1}^m z_i^{a_{ij}} \right)^{A_j} = \prod_{j=1}^n \varphi(w_j)^{A_j} = \varphi\left( \prod_{j=1}^n w_j^{A_j} \right)
\]
So if given $(b_1 \dots b_m) \in \mathbb{Z}^m$, and for a given $a_{ij}$, $a_{ij}A_j = b_i$ \\

For $m\leq n$, then $a_{ij}$ is surjective, so $\exists \, A_j$ s.t. $\prod_{i=1}^m z_i^{b_i} = \varphi\left( \prod_{j=1}^n w_j^{A_j} \right)$



\begin{proposition}[1.8]
Suppose $f_1 \dots f_n \in k[z_1 \dots z_m]$ given \\
Fix monomial order in $k[z_1 \dots z_n, w_1 \dots w_n ]$ with elimination property: \\
$\forall \, $ monomial containing 1 of $z_i$ greater than any monomial containing only $w_j$ \\

Let $\mathcal{G}$ Gr\"{o}bner basis for ideal
\[
I = \langle f_1 - w_1 \dots f_n - w_n \rangle \subset k[z_1 \dots z_m, w_1 \dots w_n]
\]
$\forall \, f \in k[z_1 \dots z_m]$, let $\overline{f}^{ \mathcal{G}}$ be remainder on division of $f$ by $\mathcal{G}$ \\
Then
\begin{enumerate}
\item[(a)] polynomial $f$ s.t. $f\in k[f_1 \dots f_n]$ iff $g= \overline{f}^{ \mathcal{G}} \in k[w_1 \dots w_n]$
\item[(b)] if $\begin{aligned} & \quad \\
  & f \in k [f_1 \dots f_n ] \\
  & g = \overline{f}^{\mathcal{G}}\in k[ w_1 \dots w_n] \end{aligned}$ \quad as in part (a), \\

then $f = g(f_1 \dots f_n)$ , giving an expression for $f$ as polynomial in $f_j$
\item[(c)] if $\forall \, f_i, f$ monomials, $f\in k[f_1 \dots f_n]$, \\
then $g$ also a monomial.  
\end{enumerate}
\end{proposition}



\subsection{Integer Programming and Combinatorics}



\section{Algebraic Coding Theory}


\section{The Berlekamp-Massey-Sakata Decoding Algorithm}





\href{https://martinralbrecht.files.wordpress.com/2010/07/20131022_buchberger_dtu.pdf}{Gr\"{o}bner Bases, Martin R. Albrecht of the DTU Crypto Group}

\part{Probability}

\section{Measure Theory}

\subsection{Measure Theory -Lect05- Frederic Schuller}

\href{https://youtu.be/6ad9V8gvyBQ?si=c8X7MUMjokirSn0F}{Measure Theory -Lec05- Frederic Schuller}, Schuller (2016) \cite{Schu2016}.

Lecture 5: \textbf{Measure Theory}

Short recap of basic notions of measure theory - without proofs - for two reasons:

EY: Without proofs because it would take too much time and they're relatively straightforward.

\begin{enumerate}
	\item spectral theory (Schuller: for self-adjoint operators) requires the (projection-valued) measures.
	\item \textbf{the} most commonly emerging $\infty$-dim. separable Hilbert space in quantum mechanics \\
	$L^2(\mathbb{R}^d)$ (Schuller: $d$ typically $=3$; you have to take the equivalence classes of square-integrable functions, almost everywhere; for physicists, theorems for exchanging integration and limits, for Riemann integral, you need uniform convergence, but for Lebesque integral you need not strong conditions). 
\end{enumerate}

\subsubsection{1. General measure spaces}

The basic definition is:
\begin{definition}
	Let $M$ be a non-empty set. \\
	Then a collection of subsets  
	\[
	\sigma \subseteq \mathcal{P}(M)
	\] is called \\
	a \textbf{$\sigma$-algebra for $M$} \\
	if \begin{enumerate}
		\item $M \in \sigma$ \\
		\item $A \in \sigma \Longrightarrow M  \setminus A \in \sigma$
		\item $A_1, A_2, \dots \in \sigma$ and $A_i \cap A_j = \emptyset$, $i\neq j$
		\[
		\Longrightarrow \bigcup_{n\geq 1} A_n \in \sigma
		\]
	\end{enumerate}
\end{definition}

\textbf{Terminology} $A\in \sigma$ called a \textbf{measurable set} in $M$. \\
\phantom{Terminology} $(M, \sigma)$ is called a \textbf{measurable} space. \\

Schuller: Volume will be called measure soon. Only sets in $\sigma$-algebra can be assigned a volume, i.e. measure. $\sigma$-algebra could be called set of all measurable subsets.

\textbf{Remark}: Clearly, taking $\sigma = \mathcal{P}(M)$. \\
In general, however, it does not provide a useful $\sigma$-algebra if $M$ is non-countable. (Schuller: e.g. discrete topology doesn't provide a useful topology)  \\

($\Longrightarrow$ problem sheet, Banach-Taichi paradox) (EY: Banach-Tarski paradox)

\begin{definition}\label{Def:measure}
	A measure $\mu : \sigma \to \mathbb{R}_0^+$ on a measurable space $(M, \sigma)$ is a map satisfying:
	\begin{enumerate}
		\item[(i)] $\mu(\emptyset) = 0$
		\item[(ii)] $A_1, A_2, \dots \in \sigma$ pairwise disjoint: $\forall i \neq j$, \, $A_i \cap A_j = \emptyset$ \\
		$\Longrightarrow \mu (\bigcup_{n \geq 1} A_n ) = \sum_{n \geq 1} \mu(A_n)$ (Schuller: this is often called "sigma additivity")
	\end{enumerate}
\end{definition}

\textbf{Terminology}: $ \underbrace{ ( \underbrace{M, \sigma}_{\text{measurable space}}, \mu) }_{\text{measure space}}$

\textbf{Properties} of a measure.\label{Thm:MeasureProperties}
\begin{enumerate}
	\item[(i)] \textbf{monotony}: $\underbrace{A_1}_{\in \sigma} \subseteq \underbrace{A_2}_{\in \sigma} \Longrightarrow \mu(A_1) \leq \mu(A_2)$ (Schuller, EY: Equality could happen if sets 1,2 differ by a point or in general a set of measure 0)
	\item[(ii)] Schuller: What if you dropped pairwise-disjoint property in the definition Def. \ref{Def:measure}? \\
	\textbf{sub-additivity} $\lbrace A_1, A_2, \dots \rbrace \subseteq \sigma$ : $\mu \left( \bigcup_{n\geq 1} A_n \right) \leq \sum_{n\geq 1} \mu (A_n)$
	\item[(iii)] \textbf{"continuity" from below}: \emph{Increasing exhaustive} sequence of measurable sets
	\[
	A_q \subseteq A_2 \subseteq \dots \quad \quad \, (\text{increasing})
		\]
		\[
		\bigcup_{n \geq 1} A_n = A \quad \quad \, \text{(exhastive)}
		\]
		
		Then $\lim_{n\to \infty} \mu(A_n) = \mu(A)$
	\item[(iv)] \textbf{"continuity from above"}: \\
	decreasing sequence enveloping: 
	\[
	\underbrace{A_1}_{\in \sigma} \supseteq \underbrace{A_2}_{\in \sigma} \subseteq \dots \text{ and } A = \bigcap_{n \geq 1 } A_n \, \left( \in \sigma \text{ due to \textbf{de Morgan} rule }\right)
	\]
	(Schuller: if these are measurable, $A_1, A_2, \dots$, are $A$ measurable?)

	\textbf{deMorgan} $M \setminus \bigcup_{n \geq 1} A_n = \bigcap_{n \geq 1} M \setminus A_n$

	\textbf{ and } $\mu (A_1) < \infty$

\[
\Longrightarrow \lim_{n \to \infty} \mu(A_n) = \mu(A)
\]

\begin{proof}
	$\Longrightarrow$ Problem Sheet.
\end{proof}

\end{enumerate}


\begin{definition} A measure $\mu$ is called finite if 
	\[
	\exists \lbrace A_1, A_2, \dots \rbrace \subseteq \sigma
	\]
	with $\bigcup_{n \geq 1} A_n = M$ s.t. $\mu (A_n) < \infty$, \, $\forall \, n \in \mathbb{N}$
\end{definition}

\subsubsection{2. Borel-$\sigma$-algebras}

How does one specify, in practice, a $\sigma$-algebra?

Schuller: measurability isn't a property of a set, but a property of a collection of sets. It's measurable with respect to a system.

\begin{definition}
	\begin{theorem}
		The smallest $\sigma$-algebra $\sigma$ for a set $M$ that \textbf{contains} (among other subsets of $M$) a collection of subsets $\mathcal{E} \subseteq \mathcal{P}(M)$ is called / defined as 
		\[
		\begin{aligned}
		\sigma(\mathcal{E}) & = \lbrace A \subseteq M | \forall \, \sigma-\text{algebras} \sigma \text{ of } M \text{ with } \mathcal{E} \subseteq \sigma: A \in \sigma \rbrace \\
		& = \bigcap_{\substack{ \sigma-\text{algebra (for $M$) } \sigma \\ \mathcal{E} \subseteq \sigma } } \sigma
		\end{aligned}
		\]
	\end{theorem}
\end{definition}

\begin{proof}
	(that $\sigma(\mathcal{E})$), generating set $\mathcal{E}$
\end{proof}

\begin{theorem}
	Every $\sigma$-algebra can be written as
	\[
	\sigma = \sigma(\mathcal{E})
	\] some $\mathcal{E}$

This construction immediately allows to link the notions of topology and $\sigma$-algebra for a set $M$
\end{theorem}

\begin{definition}
	Let $(M, \mathcal{O})$ be a topological space.
	
	Then $\sigma(\mathcal{O})$ is called the \textbf{Borel-$\sigma$-algebra} of $(M, \mathcal{O})$
\end{definition}
Schuller the $\sigma$ generated by set of open sets. $\mathcal{O}$ is a generating set of $\sigma$ algebra. There are non-open set in the $\sigma$ algebra.

\textbf{Instructive example}. \\
$M = \mathbb{R}$, $\mathcal{O} = \mathcal{O}_{ \substack{ \mathbb{R} \\ \text{ standard } } }$ "standard topology". \\

\textbf{Clearly}: $\sigma := \sigma(\mathcal{O})$ \\

$\forall \, a, b \in \mathbb{R}$: $(a,b) \in \sigma$ \\

$\Longrightarrow$ (by (iii) of $\sigma$-algebra and deMorgan) 
\[
\bigcap_{n \geq 1} \left( a - \frac{1}{n}, b \right) =: A_n \in \sigma(\mathcal{O}) = [a, b)
 \]
Schuller: So for instance, the half-open intervals are in the Borel-$\sigma$-algebra.

\subsubsection{3. Lebesgue measure on $M = \mathbb{R}^d$}

Schuller: There's a Lebesgue integral from measurable spaces, but only a Lebesgue measure on $\mathbb{R}^d$, not in general for measurable spaces.

Special construction of a measure 
\[
\begin{aligned}
	& M = \mathbb{R}^d \quad \quad \, \text{ some } d \in \mathbb{N}^+ \\
	& \sigma = \sigma \left( \mathcal{O}_{\mathbb{R}^d, \text{ standard } } \right)
\end{aligned}
\]

Then the \emph{\textbf{unique}} map $\mu_{\text{Lebesgue, $\mathbb{R}^d$} } \equiv \lambda : \sigma(\mathcal{O}) \to \overline{ \mathbb{R}}^+_0$ \\

$\mathbb{R}^2$:

Defined by

\[
\lambda \left( [a_1, b_1) \times [a_2, b_2) \times \dots \times [a_d, b_d) \right) = (b_1 - a_1) \cdot \dots \cdot (b_d - a_d) 
\]
$a_i < b_i$

is called \textbf{the} \textbf{Lebesgue-measure on} $\mathbb{R}^d$ \\

\textbf{Remark}: $(\underbrace{ \mathbb{R}, +, \cdot}_{\lambda}, |\cdot |) \rightsquigarrow \mathcal{O}_s \rightsquigarrow \sigma(\mathcal{O}_s)$ \quad \quad \, $(\mathbb{R}, \sigma(\mathcal{O}), \lambda)$ where $\sigma(\mathcal{O})$ is the \textbf{Borel}-$\sigma$-algebra, and $\lambda$ the Lebesgue measure \\

\textbf{From now on}: tacit agreement \\
\phantom{From now on} that $\mathbb{R}^d$ always be equipped, \\
\phantom{From now on} if the need arises, with \\
\phantom{From now on} Borel $\sigma$-algebra $\sigma(\mathcal{O}_{\mathbb{R}^d, s})$ and the Lebesgue measure. \\

\textbf{Remarks}: 
\begin{enumerate}
	\item[(i)] obviously, $\lambda$ is a finite measure.
	\item[(ii)]  an alternative, unique, characterization of $\lambda$ is that it is \textbf{the} measure that is invariant \\
	under translation: $\lambda(A + v) = \lambda(A) \quad \, \forall A \in \sigma(\mathcal{O}), \, \forall v \in \mathbb{R}^d$ \\
	and which sends $\lambda([0, 1]^{xd}) = +1$
\end{enumerate}

\subsubsection{4. Measurable maps}

\textbf{Standard philosophy}: $(M, \sigma_{M}) \xrightarrow{ \text{ study maps } } (N, \sigma_N)$

\begin{definition}
	A map $F: M \to N$ is called \textbf{measurable} (with respect to $\sigma_M$ and $\sigma_N$) if $\forall \, A \in \sigma_N : \text{preim}_f(A) \in \sigma_M$.
\end{definition}

\begin{lemma}
	Schuller: all the sets $A$ in the generator $E$

	To show that $f$ is \textbf{measurable} it suffices to check whether
	\[
	\forall \, A \in \mathcal{E}: \text{preim}_f(A) \in \sigma_M
	\]
	where $\sigma_N = \sigma(\mathcal{E})$
\end{lemma}

\begin{corollary}
	\begin{enumerate}
		\item[(i)] any continuous map is measurable with respect to the \textbf{Borel}-$\sigma$-algebras.
		\item[(ii)] any monotonous map
		\[
		f:\mathbb{R} \to \mathbb{R}
		\]
		is measurable with respect to Borel $\sigma$-algebra.
		\begin{proof}
			$\text{preim}_f(\text{interval})$ is an interval.
			
			Schuller: because open, half-open, half-closed, closed intervals are measurable with respect to Borel $\sigma$-algebra, it's measurable.
		\end{proof}
	\end{enumerate}
\end{corollary}

\begin{theorem}
	The composition $f\circ g : A \to C$ of two measurable maps \\
	$f:B\to C$ and $g:A \to B$ \\
	is again measurable.
\end{theorem}

\begin{proof}
	Problem sheet.
\end{proof}

Schuller: many more we can Lebesgue integrate than Riemann integrate.

\subsubsection{5. Push forward of a measure}

Let $(M, \sigma, \mu)$ be a \textbf{measure} space \\
and let $(N, \tau)$ be a measurable space \\

Schuller: measurable space, you don't know the measure for each set but you know it can be assigned a measure.

Further: Let $M \xrightarrow{f} N$ be a measurable map.

\begin{tikzpicture}
	\matrix (m) [matrix of math nodes, row sep=3em, column sep=3em]
	{ 
		M & N \\
		\sigma, \mu & \tau \\
	};
	\draw[->] (m-1-1) -- node[above] {$f$} (m-1-2);
	\draw[->,decorate,decoration={snake}] (m-1-1) -- (m-2-1);
	\draw[->,decorate,decoration={snake}] (m-1-2) -- (m-2-2);
\end{tikzpicture}

Schuller: could I push forward $\sigma$, $\mu$? A new $\mu$ induced?

Then the so-called \textbf{push-forward} $f_*\mu$ is a measure on $(N, \tau)$ defined by 
\[
\begin{gathered}
\begin{aligned}
f_*\mu : & \tau \to \overline{\mathbb{R}}^+_0 \\
& A \mapsto (f_* \mu)(A) := \mu(\text{preim}_f(A))
\end{aligned}
\end{gathered}
\]
where $\begin{aligned}
	& \mu : \sigma \to \overline{\mathbb{R}}^+_0 \\
	& f: M \to N
\end{aligned}$

\begin{proof}
	Problem sheet.
\end{proof}

\subsubsection{6. Sets of measure zero, and "almost everywhere"}

Schuller $\sigma$ you can assign a measure or volume, $\mu$ is the measure or volume.

\begin{definition}
	Let $(M, \sigma, \mu)$ be a measure space. Then
	$A\in \sigma$ is called a \textbf{set of measure zero} (null set) if
	\[
	\mu(A) = 0
	\]
\end{definition}

\textbf{Remark}: There may be other null sets then $\emptyset$.

\textbf{Terminology}: A condition, e.g. equality or convergence or \dots is said to hold \textbf{"almost everywhere"} (a.e.) if it holds $\forall \, m \in M \setminus N$ ($\leftarrow$ some $N$ with $\mu(N) = 0$).

\textbf{Examples}. 
\begin{enumerate}
	\item[(a)]
Let $\begin{aligned} & \quad \\
	& f: M \to N \\
	& g: M \to N \end{aligned}$ maps $\begin{aligned} & (M, \sigma, \mu) \\
	& N \text{ and naked set } \end{aligned}$
\begin{definition}
	\[
	f =_{\text{a.e.}} g : \Longleftrightarrow \exists \, A \in \sigma, \, \mu(A) = 0 \, \forall \, m \in M \setminus A : f(m) = g(m) 
	\]
\end{definition}
\item[(b)] 
\[
\begin{gathered}
	\left. \begin{aligned} & f_n: M \to N \\
		& f: M \to N \end{aligned}
\right\}  \begin{aligned} & (M, \sigma, \mu) \\ & (N, \mathcal{O}) \end{aligned} \\
f_n \to_{\text{a.e.} } f : \Longleftrightarrow \forall \, m \in M \setminus A: f_n(m) \to f(M) \\
\text{ where } A \in \sigma : \mu(A) = 0
\end{gathered}
\]
\end{enumerate}

Proof for Thm. \ref{Thm:MeasureProperties}, from Ch. 1. Measure Theory of Durrett (2019) \cite{Durr2019}.

\begin{proof}
\begin{enumerate}
	\item \textbf{monotonicity} or i.e. \textbf{monotony}: Recall set difference $B-A = B \cap A^c$. Let $x \in B-A$, so $x\in B$ and $x\neq A$. Then $x\in B \cap A^c$. If $B-A = \emptyset$ i.e. $B\cap A = B$, then $B\cap A^c = \emptyset$. Then $B-A \subseteq B \cap A^c$. \\
	Let $x\in B\cap A^c$, so $x\in B$ and $x\in A^c$. So $x\in B$ and $x\notin A$. $x\in B-A$. $B\cap A^c \subseteq B-A$. Thus $B\cap A^c = B-A$. \\
	
	Given $A\subset B$, $B=B-A + B\cap A = B-A + A$ (where $+$ denotes disjoint union), $\mu(B) = \mu (A) + \mu(B-A) \geq \mu(A)$
	\item EY: Insight, we know from Def. \ref{Def:measure} that if we have pairwise disjoint sets, we can say something about the measure. Thus, construct pairwise disjoint sets. \\
	
	Consider $B_1 = A_1$, $B_2 = A_2 - A_2 \cap A_1, \, B_3 = A_3 - A_3 \cap B_2 - A_3 \cap B_1 $.\\
	
	Let 
	\[
	B_i = A_i - \sum_{j=1}^{i-1} A_i \cap B_j
	\]
	
	The difference with union is as follows:
	\[
	S - (T_1 \cup T_2) = (S-T_1) (S-T_2)
	\]
	where we use the notation $A \cup B \equiv AB$ interchangeably and because
	\[
	\begin{gathered}
		S-(T_1 \cup T_2) = S \cap (T_1 \cup T_2)^c = S \cap (T_1^c T_2^c) = ST_1^c ST_2^c = (S-T_1) \cap (S-T_2)
	\end{gathered}
	\]

Likewise, the difference with intersection is $S - (T_1 \cap T_2) = (S - T_1) \cup (S-T_2)$ since
\[
\begin{gathered}
S-(T_1 \cap T_2) = S (T_1T_2)^c = S (T_1^c \cup T_2^c) = ST_1^c \cup ST_2^c = (S - T_1) \cup (S -T_2)
\end{gathered}
\]
where we used set theory' distributive theorem at the second to last equality.
	
	Thus
	\[
	\begin{gathered}
		B_{i+1} \cap B_i = (A_{i+1} - \sum_{j=1}^i A_{i + 1} \cap B_j) \cap B_i = \prod_{j=1}^i (A_{i + 1} - A_{i+1} \cap B_j) \cap B_i = \prod_{j=1}^{i - 1} (A_{i + 1} - A_{i+1} \cap B_j) (A_{i+1} - A_{i + 1} \cap B_i) B_i \\
		\text{ and since } (A_{i+1} A_{i+1}^c \cup A_{i+1} B_i^c) B_i = A_{i+1}B_i^c B_i = \emptyset, \text{ then } \\
		B_{i+1} \cap B_i = (A_{i+1} - \sum_{j=1}^i A_{i + 1} \cap B_j) \cap B_i = \emptyset \quad \, \text{(they're disjoint!)}
	\end{gathered}
	\]
	
We can use the same step used as above for $\forall i, j$, given $i > j$ (since they're be a $l$, $1 \leq l < i$ such that $l = j$), and use induction to show that $B_i$, $B_j$ disjoint.	

By construction, $\bigcup_{n=1}B_n = \bigcup_{n=1} A_n$. And because $B_i$'s pairwise disjoint, use Def. \ref{Def:measure}, (ii), to say
\[
\mu(\bigcup_{n \geq 1} A_n) = \mu(\bigcup_{n \geq 1} B_n) = \sum_{n\geq 1} \mu(B_n)
\]

Since we had defined $B_i = A_i - \sum_{j=1}^{i-1} A_i \cap B_j$, $B_i \subseteq A_i$. By Def. \ref{Def:measure}, $\mu(B_n) \leq \mu(A_n)$. Thus

\[
\mu(\bigcup_{n \geq 1} A_n) \leq \sum_{n=1} \mu(A_n)
\]

\end{enumerate}	
\end{proof}

\subsection{Integration of measurable functions -Lec06- Frederic Schuller}

\href{https://youtu.be/ot253Lhx2_o?si=0teIskVSrMHCaoGU}{Integration of measurable functions -Lec06- Frederic Schuller}, Schuller (2016) \cite{Schu2016}.

Lecture 6: \textbf{Integration of measurable functions}

Key definition: Lebesgue integral.\\
key application: definition: $L^p$ spaces. special: $p=2$

\subsubsection{1. Simple functions}

As a technical tool, we introduce

Schuller: for a measurable function, I need to know the $\sigma$ algebra on $M$ and $\sigma$ on $\mathbb{R}_0^+$.
\begin{definition} A measurable function $s: M \to \mathbb{R}_0^+$ is called a \textbf{simple function} if 
	\[
	s(M) = \lbrace s_1, \dots , s_N \rbrace
	\]
for some $N\in \mathbb{N}$.
\end{definition}

Schuller: for measurable function $s:M \to \mathbb{R}_0^+$, must know $\sigma$-algebra, $\sigma$ for $M$ and usually take the Borel $\sigma$ algebra $\sigma (\left. \mathcal{O}_s \right|_{\mathbb{R}_0^+} )$

\textbf{Implication}: \begin{enumerate}
	\item[(1)] $\text{preim}_S( \lbrace s_i \rbrace) \in \sigma$
	
	$s_i$ Borel-measurable.
	\item[(2)] $s = \sum_{z \in s(M)} z \cdot \chi_{\text{preim}_s(\lbrace z \rbrace) }$ \\
where $s(M)$ is finite.

\textbf{characteristic function} \\
$\begin{aligned}
	\chi_{A } : & M \to \mathbb{R} \\
	& m \mapsto \chi_A(m) := \begin{cases} 1 & m \in A \\
		0 & m \notin A \end{cases}
\end{aligned}$ where $A$ is any $A \subseteq M$. \\

Schuller: So $\sum_{z \in s(M)}$ in $s = \sum_{z \in s(M)} z \cdot \chi$ is a finite sum, and not a sequence, so there's no convergence issues. 

\end{enumerate}

\subsubsection{2. Integration for \emph{non-negative} measurable functions}

\begin{definition} By a non-negative measurable function, we mean
\[
f : M \to \underbrace{ \overline{\mathbb{R}}}_{ \mathbb{R} \cup \lbrace -\infty, + \infty \rbrace }
\]
such that \begin{enumerate}
	\item[(i)] $f(m) \geq 0 $ for all $m\in M$
	\item[(ii)] $f$ measurable.
\end{enumerate}
Schuller: where $\overline{\mathbb{R}}$ equipped with the $\sigma$ algebra \\
$\overline{\sigma} = \lbrace A \subseteq \overline{\mathbb{R}} | A \cap \mathbb{R} \in \sigma(\mathcal{O}_{\mathbb{R}}) \rbrace$

\end{definition}

In order to define the integral of a non-neg. measurable function, we need to have a measure $\mu$ on the \textbf{domain}.

Schuller: Riemann - find area under the cover; Lebesgue - look at all the simple functions, find the suprenum of the simple functions.

\begin{definition}
	Let $(M, \sigma, \mu)$ be a measure space. \\
	$[(\overline{R}, \overline{\sigma}) \text{ is a measurable space }]$ \\
	Then the integral $\int f d\mu$ of a non-negative measurable function $f: M \to \overline{\mathbb{R}}$ is the number $(\in \overline{\mathbb{R}})$
\[
\int f d\mu := \sup{ \lbrace \sum_{z \in s(M)} z \cdot \mu\left( \underbrace{ \text{preim}_s(\lbrace z \rbrace) }_{\in \sigma} \right) \rbrace }
\]

simple functions $s$ with $0\leq s \leq f$

\end{definition}

\begin{definition}
	Let $A \in \sigma$, i.e., a measurable subset $A \subseteq M$, then we define
	\[
	\int_A f d\mu := \int f \cdot \chi_A d\mu
	\]
	Schuller: $f\cdot \chi_A$, these are the function proper, not the function values.
	\[
	(f\cdot \chi_A)(m) := f(m) \underbrace{\cdot}_{\mathbb{R}} \chi_A(m)
	\]

\textbf{Notation}: It is often VERY convenient to write 
\[
\int f(x) \mu(dx) \text{ instead of } := \int f d\mu
\]
\textbf{application}: 

$\begin{aligned}
	\text{sq}_{\mathbb{R}} : & \mathbb{R} \to \mathbb{R} \\
	& x \mapsto x^2 
\end{aligned}$
\[
\int \underbrace{ \text{sq}_{\mathbb{R}}(x) }_{x^2} \mu(dx) \equiv   \int \text{sq}_{\mathbb{R}} d\mu
\]

\textbf{Properties}: $f$ \emph{non-negative} measurable
\begin{enumerate}
	\item[(i)] Markov inequality: $z \in \mathbb{R}^+_0$
	\[
	\int f d\mu \leq z \cdot \mu(\text{preim}_f(\lbrace z \rbrace))
	\]
\end{enumerate}


\end{definition}

\part{Fourier Transform}

\section{Derivation of Fourier Transform; Definition}

We will follow Sec. 32.2 of Mauch (2004) \cite{Mauc2004}.

Consider now this definition of the Fourier Transform, different from Mauch (2004) \cite{Mauc2004}.

\begin{definition}
\begin{equation}
\begin{aligned}
\widehat{f}(k) &= \frac{1}{2\pi} \int_{-\infty}^{\infty} dx f(x) e^{-ikx} \\
f(x) & = \int_{-\infty}^{\infty} dk \widehat{f}(k) e^{ikx} \quad \, \forall \, x \in \mathbb{R}
\end{aligned}
\end{equation}
\end{definition}

\subsection{Fourier Transform Properties}

Recall "Fourier Transformation of a Derivative", Mauch (2004) \cite{Mauc2004}.

\[
\begin{gathered}
\mathcal{F}[y'(x)] = \frac{1}{2\pi} \int_{-\infty}^{\infty} dx y'(x) e^{-i\omega x } = \left[ \frac{1}{2\pi} y(x) e^{-i\omega x} \right]_{-\infty}^{\infty} - \frac{1}{2\pi} \int_{-\infty}^{\infty} dx y(x) e^{-i\omega x} (-i \omega) = \\
= i\omega \mathcal{F}[y(x)]
\end{gathered}
\]
Next, consider $y''(x)$:
\[
\begin{gathered}
\mathcal{F}[y''(x)] = \frac{1}{2\pi} \int_{-\infty}^{\infty} dx y''(x) e^{-i\omega x } = \left[ \frac{1}{2\pi} y'(x) e^{-i\omega x} \right]_{-\infty}^{\infty} + i \omega \mathcal{F}[y'(x)] = \\
= (i\omega)^2 \mathcal{F}[y(x)]
\end{gathered}
\]
Then 
\begin{equation}
\mathcal{F}[y^{(n)}(x) ] = (i\omega)^n \mathcal{F}[y(x)]
\end{equation}

\part{Laplace Transform}

\begin{quotation}
This is for you, you, my number one \\
This is for you, you, my number one \\

This is for you, you, my number one \\

Spotlights, big stage \\
Fifty thousand fans screamin' in a rage \\
Bodyguards and limousines \\
This is the way I see you in my dreams \\
\end{quotation}
- Usher, "Superstar" \\

\begin{quotation}
Me: In which category or functor in category theory do Laplace transforms belong in? \\

Chat-GPT: Laplace transforms can be studied in the category of topological vector spaces. More specifically, the Laplace transform can be seen as a functor from the category of functions of exponential growth to the category of holomorphic functions defined on a half-plane in the complex plane. \\

In this category, the morphisms are continuous linear maps that preserve the exponential growth of functions. The Laplace transform functor takes a function in the source category and maps it to its Laplace transform in the target category. \\

The use of category theory provides a powerful framework for studying Laplace transforms and their properties in a more abstract and general way.
\end{quotation}

\section{Laplace Transform: Definitions and Properties}

\subsection{Laplace Transform Definition and Examples}

We will follow Mauch (2004) \cite{Mauc2004}.

\begin{definition}
\begin{equation}
\mathcal{L}[f(t)] = \int_0^{\infty} e^{-st} f(t) dt \equiv \widehat{f}(s)
\end{equation}
\end{definition}

\begin{definition}
A function $f(t)$ is of \textbf{exponential order} $\alpha$ if $\exists \, $ constants $t_0$, and $M$ s.t.
\begin{equation}
|f(t) | < M e^{\alpha t} \quad \, \forall \, t > t_0
\end{equation}
\end{definition}

If $\exists \, $ $\int_0^{t_0} f(t) dt$ and $f(t)$ is of exponential order $\alpha$, then $\exists \, \widehat{f}(s)$ \, $\forall \, \Re{(s)} > \alpha$.

\begin{proof}
\[
\begin{gathered}
| \int_0^{\infty} e^{-st} f(t) dt | = | \int_0^{\infty} \exp{ (-\Re{(s)} t - i \Im{ (s)} t )} f(t) dt | \leq \int_0^{\infty} \exp{( -\Re{(s)} t)} |f(t)| dt < \\
< \int_0^{\infty} \exp{ (- \Re{(s)} t) } Me^{\alpha t} dt   = M \int_0^{\infty} dt \exp{ (- (\Re{ (s)} - \alpha ) t ) } = M \left. \left( \frac{ \exp{ (- (\Re{ (s)} - \alpha ) t} }{ - (\Re{ (s)} - \alpha ) } \right) \right|_0^{\infty} = \frac{M }{ \Re{ (s) } - \alpha }
\end{gathered}
\]
if $\Re{(s)} > \alpha$
\end{proof}

For example, \\
$\sin{(t)}$ is of exponential order 0. \\
$te^{2t}$ is of exponential order $\alpha$, \, $\forall \, \alpha >2$.

Example 31.1 (Mauch (2004) \cite{Mauc2004}). Consider the Laplace transform of $f(t) = 1$.  Since $f(t)= 1$ is of exponential order $\alpha $ \, $\forall \, \alpha >0$, Laplace transform integral converges for $\Re{(s)} < 0$.

\[
\begin{gathered}
\widehat{f}(s) = \int_0^{\infty} e^{-st} dt = \left[ \frac{-1}{s} e^{-st} \right]_0^{\infty} = \frac{1}{s}
\end{gathered}
\]

Example 31.1.3. Consider Laplace transform of the Heaviside function
\[
\begin{gathered}
H(t-c) = \begin{cases}
0 & \text{ for } t < c \\
1 & \text{ for } t > c
\end{cases}
\end{gathered}
\]
where $c>0$.

\[
\begin{gathered}
\mathcal{L}[H(t-c)] = \int_0^{\infty} e^{-st} H(t-c) dt = \int_c^{\infty} e^{-st} dt = \left[ \frac{e^{-st}}{-s} \right]_c^{\infty} = \frac{e^{-cs}}{s} \quad \, \forall \, \Re{(s)} > 0
\end{gathered}
\]

Example 31.1.4. Consider $H(t-c) f(t-c)$
\[
\begin{gathered}
\mathcal{L}[H(t-c) f(t-c)] = \int_0^{\infty} dt e^{-st} H(t-c) f(t-c) = \int_c^{\infty} dt e^{-st} f(t-c) = \int_0^{\infty} dt e^{-s(t+c) } f(t) = e^{-cs} \widehat{f}(s)
\end{gathered}
\]

\subsubsection{Laplace Transform Properties and Formulae}

\begin{theorem}
\begin{equation}
\begin{aligned}
& \mathcal{L}\left[ \frac{d}{dt} f(t) \right] = s\widehat{f}(s) - f(0) \\
& \mathcal{L}\left[ \frac{d^2}{dt^2} f(t) \right] = s^2 \widehat{f}(s) - sf(0) - f'(0)
\end{aligned}
\end{equation}
\end{theorem}

\begin{proof}
To deserve these formulas,
\[
\begin{gathered}
\begin{aligned}
\mathcal{L}\left[ \frac{d}{dt} f(t) \right] & = \int_0^{\infty} dt e^{-st} f'(t) = \left[ e^{-st}f(t) \right]_0^{\infty} - \int_0^{\infty}dt (-se^{-st}) f(t) = -f(0) + s\widehat{f}(s) \\
\mathcal{L}\left[ \frac{d^2}{dt^2} f(t) \right] & = \int_0^{\infty} dt e^{-st} f''(t) = \left[ e^{-st} f'(t) \right]_0^{\infty} - \int_0^{\infty} dt (-se^{-st} ) f'(t) = -f'(0) + s \mathcal{L} [ \frac{d}{dt} f'(t) ] = \\
& = -f'(0) - sf(0 ) + s^2 \widehat{f}(s)
\end{aligned}
\end{gathered}
\]
\end{proof}

\subsection{Inverse Laplace Transform: Definition}

\begin{definition}
The inverse Laplace transform is denoted
\begin{equation}
f(t) = \mathcal{L}^{-1}[ \widehat{f}(s) ]
\end{equation}
Compute the inverse Laplace transform with the Mellin inversion formula:

\begin{equation}
f(t) = \frac{1}{2\pi i} \int_{\alpha - i \infty}^{\alpha + i \infty} ds e^{st} \widehat{f}(s)
\end{equation}
where $\alpha$ is a real constant that's to the right of the singularities of $\widehat{f}(s)$.
\end{definition}

Consider 
\[
\begin{gathered}
\mathcal{L} [ \mathcal{L}^{-1} [\widehat{f}(s)] ] =  \mathcal{L} \left[ \frac{1}{2\pi i} \int_{\alpha - i \infty}^{\alpha + i \infty} dz e^{zt} \widehat{f}(z) \right] = \int_0^{\infty} dt e^{-st} \frac{1}{2\pi i} \int_{\alpha - i \infty}^{\alpha + i \infty} dz e^{zt} \widehat{f}(z)
\end{gathered}
\]
Interchange order of integration:
\[
\begin{gathered}
\frac{1}{2\pi i} \int_{\alpha - i \infty }^{\alpha + i \infty} dz \widehat{f}(z) \int_0^{\infty} dt e^{-(s- z) t}
\end{gathered}
\]
Since $\Re{ (z)} = \alpha$ (because $z$ is from $\alpha - i \infty$ to $\alpha + i \infty$, the integral in $t$ exists for $\Re{ (s)} > \alpha$.
So
\[
\begin{gathered}
\int_0^{\infty} dt e^{-(s-z)t} =  \left( \frac{ e^{-(s-z)t} }{ -(s-z) } \right)_0^{\infty} = \frac{1}{s-z} \Longrightarrow \frac{1}{2 \pi i} \int_{\alpha - i \infty}^{\alpha + i \infty} dz \frac{\widehat{f}(z) }{ s-z}
\end{gathered}
\]

\part{Waves}

\section{Forced Oscillation and Resonance, and Damped Oscillations}

See Georgi (1992) \cite{Geor1992}.

\subsection{Damped Oscillators}

See Sec. 2.1 "Damped Oscillations", Georgi (1992) \cite{Geor1992}.

For small velocities, frictional force takes the form of

\begin{equation}
	-m\Gamma v
\end{equation}
See (2.1.1) of Georgi (1992) \cite{Geor1992}. $1/\Gamma$ has the dimensions of time.

Now
\[
\begin{gathered}
	\sum F = m\ddot{x} = -m \Gamma v - Kx
\end{gathered}
\]
or
\begin{equation}
	\ddot{x} + \Gamma \dot{x} + \frac{K}{m} x = \ddot{x} + \Gamma \dot{x} + \omega_0^2 x = 0
\end{equation}
where $\omega_0 = \sqrt{ \frac{K}{m} }$. See (2.1.2) of Georgi (1992) \cite{Geor1992}.

Since $\ddot{x} + \Gamma \dot{x} + \omega_0^2 x = 0$ is 1. time translation invariant, i.e. if $x(t+a)$ is a solution, then $x(t)$ is a solution, and 2. linearity, then find irreducible solutions of form $z(t) = e^{\alpha t}$.

\[
\Longrightarrow \alpha^2 + \Gamma \alpha + \omega_0^2 =0 \text{ or } \alpha = \frac{ -\Gamma \pm \sqrt{ \Gamma^2 - 4\omega_0^2}}{2}
\]

\subsection{Overdamped oscillations} See Sec. 2.1.1 "Overdamped Oscillations" of Georgi (1992) \cite{Geor1992}.

If $\frac{\Gamma}{2} > \omega_0$, let
\begin{equation}
	\Gamma_{\pm} = \frac{\Gamma}{2} \pm \sqrt{ \frac{\Gamma^2}{4} - \omega_0^2}
\end{equation}
See (2.1.8) of Georgi (1992) \cite{Geor1992}

\begin{equation}
	x(t) = A_+ e^{-\Gamma_+ t} + A_- e^{-\Gamma_- t}
\end{equation}
See (2.1.7) of Georgi (1992) \cite{Geor1992}.

\subsection{Underdamped Oscillations} See Sec. 2.1.2 "Underdamped Oscillations" of Georgi (1992) \cite{Geor1992}.

If $\frac{\Gamma}{2} < \omega_0$, so
\[
\alpha = \frac{-\Gamma }{2} \pm i \sqrt{ \omega_0^2 - \frac{\Gamma^2}{2} } 
\]

so 
\begin{equation}
	\omega^2 = \omega_0^2 - \frac{ \Gamma^2}{4}
\end{equation}

\begin{equation}
	x(t) = Ae^{\frac{-\Gamma}{2} t} \cos{ (\omega t- \theta)}
\end{equation}
See (2.1.10) of Georgi (1992) \cite{Geor1992}.

\[
x(t) = A e^{\frac{-\Gamma}{2} t} c(\omega t - \theta) = Ae^{\frac{-\Gamma}{2}t } (c(\omega t) c(\theta) + s(\omega t) s(\theta))
\]
\begin{equation}\label{Eq:UnderdampedOscillationsSolution}
	x(t) = e^{-\frac{\Gamma}{2}t} (c \cos{(\omega t)} + d\sin{(\omega t)})
\end{equation}
See (2.1.11) of Georgi (1992) \cite{Geor1992}, where $c= A\cos{\theta}$, $d=A\sin{\theta}$.

\subsubsection{Critically Damped Oscillations} See Sec. 2.1.3 "Critically Damped Oscillations" of Georgi (1992) \cite{Geor1992}.

If $\frac{\Gamma}{2} = \omega_0$, we only get $e^{\frac{-\Gamma}{2} t}$. We know that there will be 2 solutions to the 2nd-order differential equation.

One way to find the other solution is to approach this situation from underdamped case as a limit, i.e.
\[
\omega \to 0 \text{ from } \omega > 0
\]

\[
\begin{gathered}
	\begin{aligned}
		& \lim_{\omega \to 0} e^{ \frac{-\Gamma}{2}(t) } c\cos{(\omega t)} = e^{ \frac{-\Gamma}{2} t} \\
		& \lim_{\omega\to 0} e^{\frac{-\Gamma}{2} t} d \sin{\omega t} = 0
	\end{aligned}
\end{gathered}
\]

Divide the second term by $\omega$, because $\omega$ doesn't depend on $\omega$, $\frac{1}{\omega} e^{\frac{-\Gamma}{2} t} d\sin{\omega t}$ is still a solution.

\[
\begin{gathered}
	\lim_{\omega \to 0} e^{ \frac{-\Gamma}{2} t} \frac{ \sin{ \omega t} }{\omega} = te^{\frac{-\Gamma}{2} t} (\text{by L'Hopital's rule})
\end{gathered}
\]
So
\[
x(t) = ce^{ - \Gamma t/2} + dte^{-\Gamma t/2}
\]

\subsection{Forced oscillations} See Sec. 2.2 "Forced Oscillations" of Georgi (1992) \cite{Geor1992}.
Equation of motion is
\begin{equation}\label{Eq:ForcedOscillationEquationOfMotion}
	\ddot{x}(t) + \Gamma \dot{x} + \omega_0^2 x = F(t) /m 
\end{equation}
where
\begin{equation}
	F(t) = F_0 \cos{(\omega_dt)}
\end{equation}
See (2.1.5), (2.1.4) of Georgi (1992) \cite{Geor1992}, respectively. \\

$\frac{\omega_d}{2\pi} = $ driving frequency, driving frequency can be tuned completely independently of the other parameters of the system.

If we let 
\[
\ddot{z}(t) + \Gamma \dot{z}(t) + \omega_0^2 z(t) = \mathcal{F}(t) /m
\]
where $\mathcal{F}(t) = F_0 e^{-i \omega_0 t}$.

For in particular numerical computation applications, we can transform Eq. \ref{Eq:ForcedOscillationEquationOfMotion} into a system of first order equations: \\
Let 
\[
\begin{aligned}
	& x_1(t) = x(t) \\
	& x_2(t) = \dot{x}(t)
\end{aligned}
\]
so that
\[
\begin{aligned}
	& \dot{x}_1 = x_2 \\
	& \dot{x}_2 = -\Gamma x_2 - \omega_0^2 x_1 + f(t)
\end{aligned}
\]

Then if we look for steady state solution of the form
\[
z(t) = A e^{-i \omega_d t}
\]

One can think like the steady state solution is such that the system is driven with driving frequency $\omega_d$.

\begin{equation}
	(-\omega_d^2 + (-i \omega_d)\Gamma + \omega_0^2)A = \frac{F_0}{m} 
\end{equation}
See (2.20) of Georgi (1992) \cite{Geor1992}

or
\begin{equation}\label{Eq:ForcedOscillationSteadyStateSolutionAmplitude}
	A = \frac{ F_0 / m }{ \omega_0^2 - i\omega_d \Gamma - \omega_d^2}
\end{equation}
See (2.21) of Georgi (1992) \cite{Geor1992}

The amplitude $A$ of the displacement is proportional to amplitude of driving force; this is as expected from linearity.

\[
\begin{gathered}
	\begin{aligned}
		& A = \frac{ \frac{F_0}{m} (\omega_0^2 + i \omega_d \Gamma - \omega_d^2 )}{ (\omega_0^2 - \omega_d^2)^2 + (\omega_d \Gamma)^2 } \text{ with } & \\
		& \Re{A} = \frac{ (\omega_0^2 - \omega_d^2) F_0/m }{(\omega_0^2 - \omega_d^2)^2 + (\omega_d \Gamma)^2} & \Im{A} \equiv B = \frac{ \Gamma \omega_d F_0 /m }{ (\omega_0^2 - \omega_d^2)^2 + (\Gamma \omega_d )^2 }
	\end{aligned} \\
	\mathcal{A} e^{- i\omega_d t} = \mathcal{A} ( c(\omega_dt) - i s(\omega_dt)) \xrightarrow{\Re} \Re{A } c(\omega_d t) + \Im{A} s(\omega_d t)
\end{gathered}
\]
where I use $\mathcal{A} \equiv A$ notation interchangeably, relying on context on whether it's real or complex, and $\cos{\omega_d t} \equiv c(\omega_d t)$, $\sin{\omega_d t} \equiv s(\omega_d t)$ as shorthand notation for sin and cos. \\

For 
\[
x(t) = \Re{z(t)} = (\Re{A}) c(\omega_d t) + Bs(\omega_d t)
\]

Term proportional to $B$ is $90^{\circ}$ out of phase. \\
Real part of $\mathcal{A}$, $A = \Re{A}$ is the \emph{elastic amplitude.} \\
Imaginary part of $\mathcal{A}$, $B = \Im{A}$ is called the \emph{absorptive amplitude}. \\

In the case where 
\[
F(t) = F_0 \sin{(\omega_dt)}
\]
we'll see that the fundamental physical characteristics don't change, but the initial conditions for the solution do change, which is important for actual modeling (but gets looked over a bit in physics that concern about high-level concepts).

If $F(t) = F_0 \sin{(\omega_d t)}$, while the following doesn't change:
\[
\begin{gathered}
	\begin{aligned}
		& z(t) = \mathcal{A} e^{-i\omega_d t} \\
		& \dot{z}(t) = (-i \omega_d) z \\
		& \ddot{z}(t) = (-\omega_d^2)z
	\end{aligned}
\end{gathered}
\]
but now consider 
\[
\begin{gathered}
	\mathcal{F}(t) = + i F_0 e^{-i\omega_d t} = +i F_0 (c(\omega_d t)  -i s(\omega_d t) ) \\
	\Re{(\mathcal{F}(t) )} = F_0 s(\omega_dt)
\end{gathered}
\]
so then
\[
\begin{gathered}
	(-\omega_d^2 + (-i \omega_d)\Gamma + \omega_0^2)\mathcal{A} = \frac{iF_0}{m}  \text{ or } 	\\
	\mathcal{A} = \frac{ iF_0 / m }{ \omega_0^2 - \omega_d^2- i\omega_d \Gamma} = \frac{ \frac{iF_0}{m} (\omega_0^2 - \omega_d^2 + i \omega_d \Gamma  )}{ (\omega_0^2 - \omega_d^2)^2 + (\omega_d \Gamma)^2 }
\end{gathered}
\]

So then in this case, 
\begin{equation}\label{Eq:AmplitudeValuesForcedOscillationsForceProportionalToSine}
	\begin{aligned}
		& \Re{A} = \frac{ -\Gamma \omega_d F_0 /m }{ (\omega_0^2 - \omega_d^2)^2 + (\Gamma \omega_d )^2 } \equiv A \\
		& \Im{A} = \frac{ (\omega_0^2 - \omega_d^2) F_0/m }{(\omega_0^2 - \omega_d^2)^2 + (\omega_d \Gamma)^2} \equiv B 
	\end{aligned}
\end{equation}

and so the general form of the steady-state solution doesn't change, but the values for the amplitudes get switched:

\[
\begin{gathered}
	x(t) = \Re{ z(t)} = Ac(\omega_d t) + Bs(\omega_dt) \\
	\dot{x}(t) = \omega_d \left[ -A s(\omega_dt) + Bc(\omega_dt) \right]
\end{gathered}
\]

\subsection{Resonances} See Sec. 2.3 "Resonances" of Georgi (1992) \cite{Geor1992}.

\[
\omega_d = \omega_0
\]
so $\Re{A} = 0$, $B = \frac{ F_0 / m}{ \Gamma \omega_d}$.

\subsection{Work, Work done by forced oscillation on the system}

Work is a nonlinear function of force, so we must use real force and real displacement.

\[
P(t) = F(t) \frac{\partial }{\partial t} X(t) = F_0 c(\omega_d t) (\omega_d) (-\Re{A} s(\omega_d t) + B c(\omega_d t))
\]

The first term is proportional to $s(2\omega_d t)$ and averages to 0 over a half period.

\[
\int_{t_0}^{t_0 + \pi / \omega_d} s(2\omega_d t) dt = \left. \frac{ -c(2\omega_d t) }{2 \omega_d } \right|_{t_0}^{t_0 + \pi /\omega_d} = 0
\]

This is why $\Re{A}$ is called elastic amplitude. If $A$ dominates, then energy fed into the system at 1 time is returned at a later time, as in elastic collision in mechanics.
\[
\begin{gathered}
	P_{\text{average}} \text{of 2nd. term} = P_{\text{average}} \\
	\text{ Consider } \\
	F_0 \omega_d B \int_{t_0}^{t_0 + \pi/ \omega_d} c^2 (\omega_d t) dt = F_0 \omega_d B \int_{t_0}^{t_0 + \pi/ \omega_d} \frac{ c(2\omega_d t) + 1}{2} dt = \\
	F_0 \omega_d B \left. \left( \frac{ s(2\omega_d t) }{ 4 \omega_d } + \frac{t}{2} \right) \right|_{t_0}^{t_0 + \frac{\pi}{\omega_d} } = F_0 \omega_d B \frac{\pi}{2\omega_d} = \frac{F_0 B\pi}{2} \\
	P_{\text{average}} = \frac{ \int_{t_0}^{t_0 + \pi / \omega_d} P(t) }{ \Delta t}  \text{ where } \Delta t = \pi / \omega_d \\
	\Longrightarrow P_{\text{average}} = \frac{ F_0 B\pi /2}{ \pi / \omega_d}  = \boxed{ \frac{F_0 \omega_d B}{2} }
\end{gathered}
\]

Recall that
\[
B = \frac{ \Gamma \omega_d F_0 /m }{ (\omega_0^2 - \omega_d^2)^2 + (\Gamma \omega_d)^2 }
\]

\[
\begin{gathered}
	P_{\text{average}} = \frac{F_0 \omega_d B}{2} = \frac{ (F_0 \omega_d)^2 \Gamma /2m }{ (\omega_0^2 - \omega_d^2)^2 + (\Gamma \omega_d)^2 } \xrightarrow{ \omega_d\to \omega_0} \frac{F_0^2}{ 2m \Gamma}
\end{gathered}
\]

The maximum average power is inversely proportional to $\Gamma$. \\

This analysis doesn't change when $F(t) = F_0 \sin{(\omega_d t)}$.

\[
\begin{gathered}
	P(t) = F(t) \dot{x}(t) = F_0 s(\omega_d t) \omega_d [ -A s(\omega_d t) + Bc(\omega_d t) ] \\
	\begin{aligned}
		& \int_{t_0}^{t_0 + \frac{\pi}{\omega_d} } dt c(\omega_dt) s(\omega_d t) = \left. \frac{1}{2 \omega_d} s^2(\omega_d t) \right|_{t_0}^{t_0 + \frac{\pi}{\omega_d} } = 0 \\
		& \int_{t_0}^{t_0 + \frac{\pi}{\omega_d} } dt s^2(\omega_dt) = \int_{t_0}^{t_0 + \frac{\pi}{\omega_d} } dt \frac{1 - c(2\omega_dt)}{2} = \frac{\pi}{2 \omega_d} - \left. \frac{s(2\omega_dt)}{ 4\omega_d} \right|_{t_0}^{t_0 + \frac{\pi}{\omega_d} } = \frac{\pi}{2\omega_d}
	\end{aligned} \\
	P_{\text{average}} = \frac{ \int_{t_0}^{t_0 + \frac{\pi}{\omega_d} } dt P(t) }{ \pi /\omega_d} = \frac{-F_0 A \pi}{2 / \pi/\omega_d} = \frac{-F_0 A \omega_d}{2}
\end{gathered}
\]
So $B$ is now the elastic amplitude and $A$ is the absorptive amplitude, but the same values are obtained, since $A$ and $B$ are effectively switched for $F(t) = F_0 \sin{\omega_d t}$.

To find the width (for fixed height) of the resonance curve (curve of $P_{\text{average}}$, depending on $\omega_d$), \\
find the value $\omega_d = \omega_{1/2}$ s.t. 
\[
P_{\text{average}} = \frac{P_{\text{average,max}}}{2} = \frac{F_0^2}{4m \Gamma}
\]
Then

\[
\begin{gathered}
	\frac{P_{\text{average,max}}}{2} = \frac{F_0^2}{4m \Gamma} = \frac{ (F_0^2 \Gamma /2m ) \omega_{1/2}^2 }{ (\omega_{1/2}^2 - \omega_0^2)^2 + (\Gamma \omega_{1/2})^2 } \text{ or } \omega_{1/2}^4 -2\omega_{1/2}^2 \omega_0^2 + \omega_0^2 + \Gamma^2 \omega_{1/2}^2 = 2\Gamma^2 \omega_{1/2}^2 \text{ or } \\
	\begin{aligned}
		& \omega_{1/2}^4 - (2\omega_0^2 + \Gamma^2) \omega_{1/2}^2 + \omega_0^4 = 0 \\
		& \omega_{1/2}^2 = \frac{ (2 \omega_0^2 + \Gamma^2) \pm \sqrt{ ( \Gamma^2 + 2\omega_0^2)^2 - 4\omega_0^4 } }{2} = \omega_0^2 + \frac{ \Gamma^2}{2} \pm \sqrt{ \frac{\Gamma^4 }{4}  + \Gamma^2 \omega_0^2 } = \omega_0^2 + \frac{ \Gamma^2}{2} \pm \Gamma \sqrt{ \frac{\Gamma^2 }{4}  +  \omega_0^2 }
	\end{aligned}
\end{gathered}
\]
Now (EY: it seems like you would have needed to have known the answer beforehand to have tried this factorization)
\[
\begin{gathered}
	\omega_{1/2}^2 = \left( \sqrt{ \omega_0^2 + \frac{\Gamma^2}{4} } \right)^2 \pm 2 \frac{\Gamma}{2} \sqrt{ \frac{\Gamma^2}{4} + \omega_0^2 } + \left( \frac{\Gamma}{2} \right)^2  = \left( \sqrt{ \omega_0^2 + \frac{ \Gamma^2}{4} } \pm \frac{\Gamma}{2} \right)^2
\end{gathered}
\]
Then
\begin{equation}
	\boxed{ \omega_{1/2} = \sqrt{ \omega_0^2 + \frac{\Gamma^2}{4} } \pm \frac{\Gamma}{2} }
\end{equation}

The "free oscillation" of the system would be the case of underdamped oscillations; recall
\[
x(t) = A \exp{ \left( \frac{-\Gamma t}{2} \right) }\cos{ (\omega t - \theta) }
\]
Notice the exponential decay behavior of the amplitude or i.e. magnitude of $x(t)$ due to the $\exp{ \left( \frac{-\Gamma t}{2} \right)}$ factor. Let's just say the "lifetime" of free oscillation is the time for the amplitude to drop to half its value, i.e.
\[
\begin{gathered}
	\frac{1}{2} = \exp{ \left( \frac{-\Gamma t_{1/2} }{2} \right) } \text{ or } -\ln{2} = \frac{-\Gamma t_{1/2} }{2} , \quad \text{ or } t_{1/2} = \frac{2\ln{2} }{\Gamma}
\end{gathered}
\]

For the time dependence of the free oscillation, i.e. $x(t) = A \exp{ \left( \frac{-\Gamma t}{2} \right) }\cos{ (\omega t - \theta) }$, then we say that the lifetime of the state in free oscillation is of order $1/\Gamma$, i.e.
\[
t_{1/2} = \frac{2\ln{2}}{ \Gamma}
\]

The width of the resonance peak in forced oscillation is 
\[
\Delta \omega_{1/2} = \Gamma
\]
so width of the resonance peak in forced oscillation is inversely proportional to the lifetime of the corresponding normal mode of free oscillation.

\subsection{Apply Fourier Transform to Forced Oscillations}

So for the equation of motion, Eq. \ref{Eq:ForcedOscillationEquationOfMotion},
\[
\ddot{x} + \Gamma \dot{x} + \omega_0^2 x = F(t)
\]

Assume we drive the system at frequency $\omega_d$ and that system's response's frequency is also $\omega_d$.

Then

\[
\begin{gathered}
	(i\omega_d)^2 \widehat{x} + (i\omega_d) \Gamma \widehat{x} + \omega_0^2 \widehat{x} = \widehat{F}(\omega_d) \text{ or } \frac{ \widehat{x}(\omega_d) }{ \widehat{F}(\omega_d) } = \frac{1}{ - (\omega_d^2 - i \omega_d \Gamma - \omega_0^2) }
\end{gathered}
\]

So in general, $\frac{ \widehat{x}(\omega_d) }{ \widehat{F}(\omega_d) }$ has a real part and imaginary part.


\subsection{Apply Laplace Transform to Forced Oscillations}

Recall Eq. \ref{Eq:ForcedOscillationEquationOfMotion},
\[
\ddot{x} + \Gamma \dot{x} + k x = mF(t)
\]
so that if $\frac{k}{m} = \omega_0^2$, then
\[
\begin{gathered}
	\xrightarrow{ \mathcal{L}} s^2 \widehat{x}(s) - s x(0) - x'(0) + \Gamma (s\widehat{x}(s) - x(0)) + \omega_0^2 \widehat{x}(s) = \widehat{F}(s) \text{ or } \\
	(s^2 + \Gamma s + \omega_0^2) \widehat{x}(s) - (\Gamma + s) x(0) - x'(0) = \widehat{F}(s)
\end{gathered}
\]

If $x'(0) = 0$, and we start system at $x(0) =0$, so that we rely upon $F(t)$ to drive system, then we get a ratio of output or "response" to input, the driving, forced oscillation, per mass,
\[
\begin{gathered}
	\frac{ \widehat{x}(s) }{ \widehat{F}(s) } = \frac{1}{ s^2 + \Gamma s + \omega_0^2 } = \frac{1}{ \left( s + \frac{ \Gamma + \sqrt{ \Gamma^2 - 4 \omega_0^2 } }{ 2 } \right) \left( s + \frac{ \Gamma - \sqrt{ \Gamma^2 - 4 \omega_0^2 } }{ 2} \right) }
\end{gathered}
\]
Now look at where the denominator "blows up", the singularities. We had the case that if $\Gamma^2 - 4\omega^2 \geq 0 $ or $\frac{\Gamma}{2} \geq \omega_0$, we had overdamped or critically damped exponential decay. Then, the value of $s$ where a singularity occurs would be completely real. For the underdamped case with free oscillation, the value of $s$ where a singularity occurs would have an imaginary part.

If initial conditions can't be ignored, \\
then if $x'(0) =0$,
\[
\begin{gathered}
	(s^2 + \Gamma s + \omega_0^2) \widehat{x}(s) - x'(0) = \widehat{F}(s) \text{ or } \frac{ \widehat{x}(s) }{ \widehat{F}(s) } = \frac{ 1 + x'(0) / \widehat{F}(s) }{ s^2 + \Gamma s + \omega_0^2 }
\end{gathered}
\]

But if $x'(0) =0$,
\[
\begin{gathered}
	\frac{ \widehat{x}(s) }{ \widehat{F}(s) } = \frac{ 1 + (\Gamma +s )x(0) / \widehat{F}(s) }{ s^2 + \Gamma s + \omega_0^2 }
\end{gathered}
\]

\subsection{General solution to forced oscillation}

For subscript $s$ meaning steady-state driven solution, see Eq. \ref{Eq:ForcedOscillationSteadyStateSolutionAmplitude}
\[
\begin{gathered}
	x_s(t) = Ac(\omega_d t) + Bs(\omega_d t) \\
	\begin{aligned}
		& A = \frac{ (\omega_0^2 - \omega_d^2) F_0 / m }{ (\omega_0^2 - \omega_d^2)^2 + (\omega_d \Gamma)^2 } \\
		& B = \frac{ \Gamma \omega_d F_0 / m }{ (\omega_0^2 - \omega_d^2)^2 + (\Gamma \omega_d)^2 }
	\end{aligned}
\end{gathered}
\] 
so then
\[
\begin{aligned}
	& x_s(0) = A \\
	& \dot{x}_s(0) = \omega_dB
\end{aligned}
\]

Let $x_{\text{free}}$ denote the response, or solution, or the resulting motion for the "free oscillation", the underdamped, exponential decaying solution, for $\omega_0 > \frac{\Gamma}{2}$. See Eq. \ref{Eq:UnderdampedOscillationsSolution},

\[
\begin{gathered}
	\begin{aligned}
		x_{\text{free}}(t) & = \exp{ \left( \frac{-\Gamma t}{2} \right) } (c\cos{(\omega t)} + d\sin{ (\omega t)} ), \quad \, \omega^2 = \omega_0^2 -\frac{\Gamma^2}{2} \\
		x_{\text{free}}(0) &= c \\
		\dot{x}_{\text{free}}(t) & = \frac{-\Gamma}{2} x_{\text{free}}(t) + e^{-\frac{\Gamma}{2} t} \omega( - cs(\omega t) + dc(\omega t) ) \\
		\dot{x}_{\text{free}}(0) & = \frac{-\Gamma}{2} c + \omega d
	\end{aligned}
\end{gathered}
\]

The most general solution $x(t)$ is of the form
\[
\begin{gathered}
	x(t) = x_{\text{free}}(t) + x_s(t)
\end{gathered}
\]
with initial conditions
\[
\begin{aligned}
	& x(0) = c + A \text{ so } c = x(0) - A \\
	& \dot{x}(0) = \frac{-\Gamma}{2} c + \omega d + \omega_d B \text{ so } d = \frac{1}{\omega} \left[ \dot{x}(0) + \frac{\Gamma}{2} (x(0) - A) - \omega_d B \right]
\end{aligned}
\]

And so the full, general solution is 
\begin{equation}
	\begin{gathered}
		x(t) = e^{\frac{-\Gamma t}{2} } (c\cos{(\omega t)} + d \sin{ (\omega t)} ) + A \cos{ (\omega_d t)} + B \sin{(\omega_d t)} \\
		\text{ where } \\
		\begin{aligned}
			& A = \frac{ (\omega_0^2 - \omega_d^2) F_0 / m }{ (\omega_0^2 - \omega_d^2)^2 + (\omega_d \Gamma)^2 } \\
			& B = \frac{ \Gamma \omega_d F_0 / m }{ (\omega_0^2 - \omega_d^2)^2 + (\Gamma \omega_d)^2 }
			& \omega^2 = \omega_0^2 - \frac{\Gamma^2}{4}, \\
			& c = x(0) - A, \\
			& d = \frac{1}{\omega} \left[ \dot{x}(0) + \frac{\Gamma}{2} (x(0) - A) - \omega_d B \right]
		\end{aligned}
	\end{gathered}
\end{equation}

For the case of $F(t) = F_0 \sin{(\omega_d t)}$, i.e. the force is proportional to $\sin$, then the exact same analysis leads to the same result as above, but for $A,B$ values switched to be as Eq. \ref{Eq:AmplitudeValuesForcedOscillationsForceProportionalToSine}.

\[
\begin{aligned}
	& \Re{A} = \frac{ -\Gamma \omega_d F_0 /m }{ (\omega_0^2 - \omega_d^2)^2 + (\Gamma \omega_d )^2 } \equiv A \\
	& \Im{A} = \frac{ (\omega_0^2 - \omega_d^2) F_0/m }{(\omega_0^2 - \omega_d^2)^2 + (\omega_d \Gamma)^2} \equiv B 
\end{aligned}
\]

\subsection{Forced Oscillation and Resonance, and Damped Oscillations}

See Georgi (1992) \cite{Geor1992}.

\subsubsection{Damped Oscillators}

See Sec. 2.1 "Damped Oscillations", Georgi (1992) \cite{Geor1992}.

For small velocities, frictional force takes the form of

\begin{equation}
	-m\Gamma v
\end{equation}
See (2.1.1) of Georgi (1992) \cite{Geor1992}. $1/\Gamma$ has the dimensions of time.

Now
\[
\begin{gathered}
	\sum F = m\ddot{x} = -m \Gamma v - Kx
\end{gathered}
\]
or
\begin{equation}
	\ddot{x} + \Gamma \dot{x} + \frac{K}{m} x = \ddot{x} + \Gamma \dot{x} + \omega_0^2 x = 0
\end{equation}
where $\omega_0 = \sqrt{ \frac{K}{m} }$. See (2.1.2) of Georgi (1992) \cite{Geor1992}.

Since $\ddot{x} + \Gamma \dot{x} + \omega_0^2 x = 0$ is 1. time translation invariant, i.e. if $x(t+a)$ is a solution, then $x(t)$ is a solution, and 2. linearity, then find irreducible solutions of form $z(t) = e^{\alpha t}$.

\[
\Longrightarrow \alpha^2 + \Gamma \alpha + \omega_0^2 =0 \text{ or } \alpha = \frac{ -\Gamma \pm \sqrt{ \Gamma^2 - 4\omega_0^2}}{2}
\]

\subsubsection{Overdamped oscillations} See Sec. 2.1.1 "Overdamped Oscillations" of Georgi (1992) \cite{Geor1992}.

If $\frac{\Gamma}{2} > \omega_0$, let
\begin{equation}
	\Gamma_{\pm} = \frac{\Gamma}{2} \pm \sqrt{ \frac{\Gamma^2}{4} - \omega_0^2}
\end{equation}
See (2.1.8) of Georgi (1992) \cite{Geor1992}

\begin{equation}
	x(t) = A_+ e^{-\Gamma_+ t} + A_- e^{-\Gamma_- t}
\end{equation}
See (2.1.7) of Georgi (1992) \cite{Geor1992}.

\subsubsection{Underdamped Oscillations} See Sec. 2.1.2 "Underdamped Oscillations" of Georgi (1992) \cite{Geor1992}.

If $\frac{\Gamma}{2} < \omega_0$, so
\[
\alpha = \frac{-\Gamma }{2} \pm i \sqrt{ \omega_0^2 - \frac{\Gamma^2}{2} } 
\]

so 
\begin{equation}
	\omega^2 = \omega_0^2 - \frac{ \Gamma^2}{4}
\end{equation}

\begin{equation}
	x(t) = Ae^{\frac{-\Gamma}{2} t} \cos{ (\omega t- \theta)}
\end{equation}
See (2.1.10) of Georgi (1992) \cite{Geor1992}.

\[
x(t) = A e^{\frac{-\Gamma}{2} t} c(\omega t - \theta) = Ae^{\frac{-\Gamma}{2}t } (c(\omega t) c(\theta) + s(\omega t) s(\theta))
\]
\begin{equation}\label{Eq:UnderdampedOscillationsSolution}
	x(t) = e^{-\frac{\Gamma}{2}t} (c \cos{(\omega t)} + d\sin{(\omega t)})
\end{equation}
See (2.1.11) of Georgi (1992) \cite{Geor1992}, where $c= A\cos{\theta}$, $d=A\sin{\theta}$.

\subsubsection{Critically Damped Oscillations} See Sec. 2.1.3 "Critically Damped Oscillations" of Georgi (1992) \cite{Geor1992}.

If $\frac{\Gamma}{2} = \omega_0$, we only get $e^{\frac{-\Gamma}{2} t}$. We know that there will be 2 solutions to the 2nd-order differential equation.

One way to find the other solution is to approach this situation from underdamped case as a limit, i.e.
\[
\omega \to 0 \text{ from } \omega > 0
\]

\[
\begin{gathered}
	\begin{aligned}
		& \lim_{\omega \to 0} e^{ \frac{-\Gamma}{2}(t) } c\cos{(\omega t)} = e^{ \frac{-\Gamma}{2} t} \\
		& \lim_{\omega\to 0} e^{\frac{-\Gamma}{2} t} d \sin{\omega t} = 0
	\end{aligned}
\end{gathered}
\]

Divide the second term by $\omega$, because $\omega$ doesn't depend on $\omega$, $\frac{1}{\omega} e^{\frac{-\Gamma}{2} t} d\sin{\omega t}$ is still a solution.

\[
\begin{gathered}
	\lim_{\omega \to 0} e^{ \frac{-\Gamma}{2} t} \frac{ \sin{ \omega t} }{\omega} = te^{\frac{-\Gamma}{2} t} (\text{by L'Hopital's rule})
\end{gathered}
\]
So
\[
x(t) = ce^{ - \Gamma t/2} + dte^{-\Gamma t/2}
\]

\subsubsection{Forced oscillations} See Sec. 2.2 "Forced Oscillations" of Georgi (1992) \cite{Geor1992}.
Equation of motion is
\begin{equation}\label{Eq:ForcedOscillationEquationOfMotion}
	\ddot{x}(t) + \Gamma \dot{x} + \omega_0^2 x = F(t) /m 
\end{equation}
where
\begin{equation}
	F(t) = F_0 \cos{(\omega_dt)}
\end{equation}
See (2.1.5), (2.1.4) of Georgi (1992) \cite{Geor1992}, respectively. \\

$\frac{\omega_d}{2\pi} = $ driving frequency, driving frequency can be tuned completely independently of the other parameters of the system.

If we let 
\[
\ddot{z}(t) + \Gamma \dot{z}(t) + \omega_0^2 z(t) = \mathcal{F}(t) /m
\]
where $\mathcal{F}(t) = F_0 e^{-i \omega_0 t}$.

For in particular numerical computation applications, we can transform Eq. \ref{Eq:ForcedOscillationEquationOfMotion} into a system of first order equations: \\
Let 
\[
\begin{aligned}
& x_1(t) = x(t) \\
& x_2(t) = \dot{x}(t)
\end{aligned}
\]
so that
\[
\begin{aligned}
& \dot{x}_1 = x_2 \\
& \dot{x}_2 = -\Gamma x_2 - \omega_0^2 x_1 + f(t)
\end{aligned}
\]


Then if we look for steady state solution of the form
\[
z(t) = A e^{-i \omega_d t}
\]

One can think like the steady state solution is such that the system is driven with driving frequency $\omega_d$.

\begin{equation}
	(-\omega_d^2 + (-i \omega_d)\Gamma + \omega_0^2)A = \frac{F_0}{m} 
\end{equation}
See (2.20) of Georgi (1992) \cite{Geor1992}

or
\begin{equation}
	A = \frac{ F_0 / m }{ \omega_0^2 - i\omega_d \Gamma - \omega_d^2}
\end{equation}
See (2.21) of Georgi (1992) \cite{Geor1992}

The amplitude $A$ of the displacement is proportional to amplitude of driving force; this is as expected from linearity.

\[
\begin{gathered}
	\begin{aligned}
		& A = \frac{ \frac{F_0}{m} (\omega_0^2 + i \omega_d \Gamma - \omega_d^2 )}{ (\omega_0^2 - \omega_d^2)^2 + (\omega_d \Gamma)^2 } \text{ with } & \\
		& \Re{A} = \frac{ (\omega_0^2 - \omega_d^2) F_0/m }{(\omega_0^2 - \omega_d^2)^2 + (\omega_d \Gamma)^2} & \Im{A} \equiv B = \frac{ \Gamma \omega_d F_0 /m }{ (\omega_0^2 - \omega_d^2)^2 + (\Gamma \omega_d )^2 }
			\end{aligned} \\
		\mathcal{A} e^{- i\omega_d t} = \mathcal{A} ( c(\omega_dt) - i s(\omega_dt)) \xrightarrow{\Re} \Re{A } c(\omega_d t) + \Im{A} s(\omega_d t)
\end{gathered}
\]
where I use $\mathcal{A} \equiv A$ notation interchangeably, relying on context on whether it's real or complex, and $\cos{\omega_d t} \equiv c(\omega_d t)$, $\sin{\omega_d t} \equiv s(\omega_d t)$ as shorthand notation for sin and cos. \\

For 
\[
x(t) = \Re{z(t)} = (\Re{A}) c(\omega_d t) + Bs(\omega_d t)
\]

Term proportional to $B$ is $90^{\circ}$ out of phase. \\
Real part of $\mathcal{A}$, $A = \Re{A}$ is the \emph{elastic amplitude.} \\
Imaginary part of $\mathcal{A}$, $B = \Im{A}$ is called the \emph{absorptive amplitude}. \\

In the case where 
\[
	F(t) = F_0 \sin{(\omega_dt)}
\]
we'll see that the fundamental physical characteristics don't change, but the initial conditions for the solution do change, which is important for actual modeling (but gets looked over a bit in physics that concern about high-level concepts).

If $F(t) = F_0 \sin{(\omega_d t)}$, while the following doesn't change:
\[
\begin{gathered}
\begin{aligned}
& z(t) = \mathcal{A} e^{-i\omega_d t} \\
& \dot{z}(t) = (-i \omega_d) z \\
& \ddot{z}(t) = (-\omega_d^2)z
\end{aligned}
\end{gathered}
\]
but now consider 
\[
\begin{gathered}
\mathcal{F}(t) = + i F_0 e^{-i\omega_d t} = +i F_0 (c(\omega_d t)  -i s(\omega_d t) ) \\
\Re{(\mathcal{F}(t) )} = F_0 s(\omega_dt)
\end{gathered}
\]
so then
\[
\begin{gathered}
	(-\omega_d^2 + (-i \omega_d)\Gamma + \omega_0^2)\mathcal{A} = \frac{iF_0}{m}  \text{ or } 	\\
	\mathcal{A} = \frac{ iF_0 / m }{ \omega_0^2 - \omega_d^2- i\omega_d \Gamma} = \frac{ \frac{iF_0}{m} (\omega_0^2 - \omega_d^2 + i \omega_d \Gamma  )}{ (\omega_0^2 - \omega_d^2)^2 + (\omega_d \Gamma)^2 }
\end{gathered}
\]

So then in this case, 
\begin{equation}\label{Eq:AmplitudeValuesForcedOscillationsForceProportionalToSine}
\begin{aligned}
& \Re{A} = \frac{ -\Gamma \omega_d F_0 /m }{ (\omega_0^2 - \omega_d^2)^2 + (\Gamma \omega_d )^2 } \equiv A \\
& \Im{A} = \frac{ (\omega_0^2 - \omega_d^2) F_0/m }{(\omega_0^2 - \omega_d^2)^2 + (\omega_d \Gamma)^2} \equiv B 
\end{aligned}
\end{equation}

and so the general form of the steady-state solution doesn't change, but the values for the amplitudes get switched:

\[
\begin{gathered}
x(t) = \Re{ z(t)} = Ac(\omega_d t) + Bs(\omega_dt) \\
\dot{x}(t) = \omega_d \left[ -A s(\omega_dt) + Bc(\omega_dt) \right]
\end{gathered}
\]

\subsubsection{Resonances} See Sec. 2.3 "Resonances" of Georgi (1992) \cite{Geor1992}.

\[
\omega_d = \omega_0
\]
so $\Re{A} = 0$, $B = \frac{ F_0 / m}{ \Gamma \omega_d}$.

\subsubsection{Work, Work done by forced oscillation on the system}

Work is a nonlinear function of force, so we must use real force and real displacement.

\[
P(t) = F(t) \frac{\partial }{\partial t} X(t) = F_0 c(\omega_d t) (\omega_d) (-\Re{A} s(\omega_d t) + B c(\omega_d t))
\]

The first term is proportional to $s(2\omega_d t)$ and averages to 0 over a half period.

\[
\int_{t_0}^{t_0 + \pi / \omega_d} s(2\omega_d t) dt = \left. \frac{ -c(2\omega_d t) }{2 \omega_d } \right|_{t_0}^{t_0 + \pi /\omega_d} = 0
\]

This is why $\Re{A}$ is called elastic amplitude. If $A$ dominates, then energy fed into the system at 1 time is returned at a later time, as in elastic collision in mechanics.
\[
\begin{gathered}
	P_{\text{average}} \text{of 2nd. term} = P_{\text{average}} \\
	\text{ Consider } \\
	F_0 \omega_d B \int_{t_0}^{t_0 + \pi/ \omega_d} c^2 (\omega_d t) dt = F_0 \omega_d B \int_{t_0}^{t_0 + \pi/ \omega_d} \frac{ c(2\omega_d t) + 1}{2} dt = \\
	F_0 \omega_d B \left. \left( \frac{ s(2\omega_d t) }{ 4 \omega_d } + \frac{t}{2} \right) \right|_{t_0}^{t_0 + \frac{\pi}{\omega_d} } = F_0 \omega_d B \frac{\pi}{2\omega_d} = \frac{F_0 B\pi}{2} \\
	P_{\text{average}} = \frac{ \int_{t_0}^{t_0 + \pi / \omega_d} P(t) }{ \Delta t}  \text{ where } \Delta t = \pi / \omega_d \\
	\Longrightarrow P_{\text{average}} = \frac{ F_0 B\pi /2}{ \pi / \omega_d}  = \boxed{ \frac{F_0 \omega_d B}{2} }
\end{gathered}
\]

Recall that
\[
B = \frac{ \Gamma \omega_d F_0 /m }{ (\omega_0^2 - \omega_d^2)^2 + (\Gamma \omega_d)^2 }
\]

\[
\begin{gathered}
	P_{\text{average}} = \frac{F_0 \omega_d B}{2} = \frac{ (F_0 \omega_d)^2 \Gamma /2m }{ (\omega_0^2 - \omega_d^2)^2 + (\Gamma \omega_d)^2 } \xrightarrow{ \omega_d\to \omega_0} \frac{F_0^2}{ 2m \Gamma}
\end{gathered}
\]

The maximum average power is inversely proportional to $\Gamma$. \\

This analysis doesn't change when $F(t) = F_0 \sin{(\omega_d t)}$.

\[
\begin{gathered}
P(t) = F(t) \dot{x}(t) = F_0 s(\omega_d t) \omega_d [ -A s(\omega_d t) + Bc(\omega_d t) ] \\
\begin{aligned}
& \int_{t_0}^{t_0 + \frac{\pi}{\omega_d} } dt c(\omega_dt) s(\omega_d t) = \left. \frac{1}{2 \omega_d} s^2(\omega_d t) \right|_{t_0}^{t_0 + \frac{\pi}{\omega_d} } = 0 \\
& \int_{t_0}^{t_0 + \frac{\pi}{\omega_d} } dt s^2(\omega_dt) = \int_{t_0}^{t_0 + \frac{\pi}{\omega_d} } dt \frac{1 - c(2\omega_dt)}{2} = \frac{\pi}{2 \omega_d} - \left. \frac{s(2\omega_dt)}{ 4\omega_d} \right|_{t_0}^{t_0 + \frac{\pi}{\omega_d} } = \frac{\pi}{2\omega_d}
\end{aligned} \\
P_{\text{average}} = \frac{ \int_{t_0}^{t_0 + \frac{\pi}{\omega_d} } dt P(t) }{ \pi /\omega_d} = \frac{-F_0 A \pi}{2 / \pi/\omega_d} = \frac{-F_0 A \omega_d}{2}
\end{gathered}
\]
So $B$ is now the elastic amplitude and $A$ is the absorptive amplitude, but the same values are obtained, since $A$ and $B$ are effectively switched for $F(t) = F_0 \sin{\omega_d t}$.


To find the width (for fixed height) of the resonance curve (curve of $P_{\text{average}}$, depending on $\omega_d$), \\
find the value $\omega_d = \omega_{1/2}$ s.t. 
\[
P_{\text{average}} = \frac{P_{\text{average,max}}}{2} = \frac{F_0^2}{4m \Gamma}
\]
Then

\[
\begin{gathered}
\frac{P_{\text{average,max}}}{2} = \frac{F_0^2}{4m \Gamma} = \frac{ (F_0^2 \Gamma /2m ) \omega_{1/2}^2 }{ (\omega_{1/2}^2 - \omega_0^2)^2 + (\Gamma \omega_{1/2})^2 } \text{ or } \omega_{1/2}^4 -2\omega_{1/2}^2 \omega_0^2 + \omega_0^2 + \Gamma^2 \omega_{1/2}^2 = 2\Gamma^2 \omega_{1/2}^2 \text{ or } \\
\begin{aligned}
& \omega_{1/2}^4 - (2\omega_0^2 + \Gamma^2) \omega_{1/2}^2 + \omega_0^4 = 0 \\
& \omega_{1/2}^2 = \frac{ (2 \omega_0^2 + \Gamma^2) \pm \sqrt{ ( \Gamma^2 + 2\omega_0^2)^2 - 4\omega_0^4 } }{2} = \omega_0^2 + \frac{ \Gamma^2}{2} \pm \sqrt{ \frac{\Gamma^4 }{4}  + \Gamma^2 \omega_0^2 } = \omega_0^2 + \frac{ \Gamma^2}{2} \pm \Gamma \sqrt{ \frac{\Gamma^2 }{4}  +  \omega_0^2 }
\end{aligned}
\end{gathered}
\]
Now (EY: it seems like you would have needed to have known the answer beforehand to have tried this factorization)
\[
\begin{gathered}
\omega_{1/2}^2 = \left( \sqrt{ \omega_0^2 + \frac{\Gamma^2}{4} } \right)^2 \pm 2 \frac{\Gamma}{2} \sqrt{ \frac{\Gamma^2}{4} + \omega_0^2 } + \left( \frac{\Gamma}{2} \right)^2  = \left( \sqrt{ \omega_0^2 + \frac{ \Gamma^2}{4} } \pm \frac{\Gamma}{2} \right)^2
\end{gathered}
\]
Then
\begin{equation}
\boxed{ \omega_{1/2} = \sqrt{ \omega_0^2 + \frac{\Gamma^2}{4} } \pm \frac{\Gamma}{2} }
\end{equation}

The "free oscillation" of the system would be the case of underdamped oscillations; recall
\[
x(t) = A \exp{ \left( \frac{-\Gamma t}{2} \right) }\cos{ (\omega t - \theta) }
\]
Notice the exponential decay behavior of the amplitude or i.e. magnitude of $x(t)$ due to the $\exp{ \left( \frac{-\Gamma t}{2} \right)}$ factor. Let's just say the "lifetime" of free oscillation is the time for the amplitude to drop to half its value, i.e.
\[
\begin{gathered}
\frac{1}{2} = \exp{ \left( \frac{-\Gamma t_{1/2} }{2} \right) } \text{ or } -\ln{2} = \frac{-\Gamma t_{1/2} }{2} , \quad \text{ or } t_{1/2} = \frac{2\ln{2} }{\Gamma}
\end{gathered}
\]

For the time dependence of the free oscillation, i.e. $x(t) = A \exp{ \left( \frac{-\Gamma t}{2} \right) }\cos{ (\omega t - \theta) }$, then we say that the lifetime of the state in free oscillation is of order $1/\Gamma$, i.e.
\[
t_{1/2} = \frac{2\ln{2}}{ \Gamma}
\]

The width of the resonance peak in forced oscillation is 
\[
\Delta \omega_{1/2} = \Gamma
\]
so width of the resonance peak in forced oscillation is inversely proportional to the lifetime of the corresponding normal mode of free oscillation.

\subsection{Apply Fourier Transform to Forced Oscillations}

So for the equation of motion, Eq. \ref{Eq:ForcedOscillationEquationOfMotion},
\[
\ddot{x} + \Gamma \dot{x} + \omega_0^2 x = F(t)
\]

Assume we drive the system at frequency $\omega_d$ and that system's response's frequency is also $\omega_d$.

Then

\[
\begin{gathered}
(i\omega_d)^2 \widehat{x} + (i\omega_d) \Gamma \widehat{x} + \omega_0^2 \widehat{x} = \widehat{F}(\omega_d) \text{ or } \frac{ \widehat{x}(\omega_d) }{ \widehat{F}(\omega_d) } = \frac{1}{ - (\omega_d^2 - i \omega_d \Gamma - \omega_0^2) }
\end{gathered}
\]

So in general, $\frac{ \widehat{x}(\omega_d) }{ \widehat{F}(\omega_d) }$ has a real part and imaginary part.

\subsection{Apply Laplace Transform to Forced Oscillations}

Recall Eq. \ref{Eq:ForcedOscillationEquationOfMotion},
\[
\ddot{x} + \Gamma \dot{x} + k x = mF(t)
\]
so that if $\frac{k}{m} = \omega_0^2$, then
\[
\begin{gathered}
\xrightarrow{ \mathcal{L}} s^2 \widehat{x}(s) - s x(0) - x'(0) + \Gamma (s\widehat{x}(s) - x(0)) + \omega_0^2 \widehat{x}(s) = \widehat{F}(s) \text{ or } \\
(s^2 + \Gamma s + \omega_0^2) \widehat{x}(s) - (\Gamma + s) x(0) - x'(0) = \widehat{F}(s)
\end{gathered}
\]

If $x'(0) = 0$, and we start system at $x(0) =0$, so that we rely upon $F(t)$ to drive system, then we get a ratio of output or "response" to input, the driving, forced oscillation, per mass,
\[
\begin{gathered}
	\frac{ \widehat{x}(s) }{ \widehat{F}(s) } = \frac{1}{ s^2 + \Gamma s + \omega_0^2 } = \frac{1}{ \left( s + \frac{ \Gamma + \sqrt{ \Gamma^2 - 4 \omega_0^2 } }{ 2 } \right) \left( s + \frac{ \Gamma - \sqrt{ \Gamma^2 - 4 \omega_0^2 } }{ 2} \right) }
\end{gathered}
\]
Now look at where the denominator "blows up", the singularities. We had the case that if $\Gamma^2 - 4\omega^2 \geq 0 $ or $\frac{\Gamma}{2} \geq \omega_0$, we had overdamped or critically damped exponential decay. Then, the value of $s$ where a singularity occurs would be completely real. For the underdamped case with free oscillation, the value of $s$ where a singularity occurs would have an imaginary part.

If initial conditions can't be ignored, \\
then if $x'(0) =0$,
\[
\begin{gathered}
(s^2 + \Gamma s + \omega_0^2) \widehat{x}(s) - x'(0) = \widehat{F}(s) \text{ or } \frac{ \widehat{x}(s) }{ \widehat{F}(s) } = \frac{ 1 + x'(0) / \widehat{F}(s) }{ s^2 + \Gamma s + \omega_0^2 }
\end{gathered}
\]

But if $x'(0) =0$,
\[
\begin{gathered}
\frac{ \widehat{x}(s) }{ \widehat{F}(s) } = \frac{ 1 + (\Gamma +s )x(0) / \widehat{F}(s) }{ s^2 + \Gamma s + \omega_0^2 }
\end{gathered}
\]

\subsubsection{General solution to forced oscillation}

For subscript $s$ meaning steady-state driven solution, see Eq. \ref{Eq:ForcedOscillationSteadyStateSolutionAmplitude}
\[
\begin{gathered}
x_s(t) = Ac(\omega_d t) + Bs(\omega_d t) \\
\begin{aligned}
& A = \frac{ (\omega_0^2 - \omega_d^2) F_0 / m }{ (\omega_0^2 - \omega_d^2)^2 + (\omega_d \Gamma)^2 } \\
& B = \frac{ \Gamma \omega_d F_0 / m }{ (\omega_0^2 - \omega_d^2)^2 + (\Gamma \omega_d)^2 }
\end{aligned}
\end{gathered}
\] 
so then
\[
\begin{aligned}
& x_s(0) = A \\
& \dot{x}_s(0) = \omega_dB
\end{aligned}
\]

Let $x_{\text{free}}$ denote the response, or solution, or the resulting motion for the "free oscillation", the underdamped, exponential decaying solution, for $\omega_0 > \frac{\Gamma}{2}$. See Eq. \ref{Eq:UnderdampedOscillationsSolution},

\[
\begin{gathered}
\begin{aligned}
x_{\text{free}}(t) & = \exp{ \left( \frac{-\Gamma t}{2} \right) } (c\cos{(\omega t)} + d\sin{ (\omega t)} ), \quad \, \omega^2 = \omega_0^2 -\frac{\Gamma^2}{2} \\
x_{\text{free}}(0) &= c \\
\dot{x}_{\text{free}}(t) & = \frac{-\Gamma}{2} x_{\text{free}}(t) + e^{-\frac{\Gamma}{2} t} \omega( - cs(\omega t) + dc(\omega t) ) \\
\dot{x}_{\text{free}}(0) & = \frac{-\Gamma}{2} c + \omega d
\end{aligned}
\end{gathered}
\]

The most general solution $x(t)$ is of the form
\[
\begin{gathered}
x(t) = x_{\text{free}}(t) + x_s(t)
\end{gathered}
\]
with initial conditions
\[
\begin{aligned}
& x(0) = c + A \text{ so } c = x(0) - A \\
& \dot{x}(0) = \frac{-\Gamma}{2} c + \omega d + \omega_d B \text{ so } d = \frac{1}{\omega} \left[ \dot{x}(0) + \frac{\Gamma}{2} (x(0) - A) - \omega_d B \right]
\end{aligned}
\]

And so the full, general solution is 
\begin{equation}
\begin{gathered}
x(t) = e^{\frac{-\Gamma t}{2} } (c\cos{(\omega t)} + d \sin{ (\omega t)} ) + A \cos{ (\omega_d t)} + B \sin{(\omega_d t)} \\
\text{ where } \\
\begin{aligned}
& A = \frac{ (\omega_0^2 - \omega_d^2) F_0 / m }{ (\omega_0^2 - \omega_d^2)^2 + (\omega_d \Gamma)^2 } \\
& B = \frac{ \Gamma \omega_d F_0 / m }{ (\omega_0^2 - \omega_d^2)^2 + (\Gamma \omega_d)^2 }
& \omega^2 = \omega_0^2 - \frac{\Gamma^2}{4}, \\
& c = x(0) - A, \\
& d = \frac{1}{\omega} \left[ \dot{x}(0) + \frac{\Gamma}{2} (x(0) - A) - \omega_d B \right]
\end{aligned}
\end{gathered}
\end{equation}

For the case of $F(t) = F_0 \sin{(\omega_d t)}$, i.e. the force is proportional to $\sin$, then the exact same analysis leads to the same result as above, but for $A,B$ values switched to be as Eq. \ref{Eq:AmplitudeValuesForcedOscillationsForceProportionalToSine}.

\[
\begin{aligned}
& \Re{A} = \frac{ -\Gamma \omega_d F_0 /m }{ (\omega_0^2 - \omega_d^2)^2 + (\Gamma \omega_d )^2 } \equiv A \\
& \Im{A} = \frac{ (\omega_0^2 - \omega_d^2) F_0/m }{(\omega_0^2 - \omega_d^2)^2 + (\omega_d \Gamma)^2} \equiv B 
\end{aligned}
\]

\part{Statistical Mechanics: Ising Model}  

\section{Ising Model}  

\subsection{Definition of Ising Model}  

cf. \href{https://en.wikipedia.org/wiki/Ising_model}{Wikipedia, "Ising model"}

Consider set of lattice sites $\Lambda$, each with set of adjacent sites (e.g. \textbf{graph}) forming $d$-dim. lattice.  \\
$\forall \, $ lattice site $k\in \Lambda$, $\exists \, $ discrete variable $\sigma_k$, s.t. $\sigma_k \in \lbrace -1, 1\rbrace$.  \\
spin configuration $\equiv \sigma = (\sigma_k)_{k\in \Lambda}$ is an assignment of spin value to each lattice site.  

i.e. 

$d=1$, consider "line" configuration: $i \in \mathbb{Z}$, $i=0,1,\dots L-1$.  Lattice site $k \in \Lambda = \Lambda_{d=1}$.  $\forall \, k \in \Lambda$, \\ 
$\exists \, $ bijection to its index $i$, $k\mapsto i$, and $\exists \, \sigma_k$ i.e. 
\[
\begin{aligned}
	& \sigma : \Lambda \leftrightarrow \sigma: \mathbb{Z} \to \mathbb{Z}_2 \\ 
	& \sigma(k) \equiv \sigma_k \leftrightarrow \sigma(i) \equiv \sigma_i \mapsto \lbrace -1, 1 \rbrace
\end{aligned}
\]
spin configuration $\sigma : \Lambda \mapsto (\sigma_k)_{k\in \Lambda} \in \lbrace -1,1 \rbrace^{| \Lambda |}$, where $|\Lambda | =L$.  \\
$\forall \, k \in \Lambda$, $\exists \, ! $ only at most 2 edges, given, for $k\mapsto i$, $i+1,i-1$, $\forall \, i = 1 \dots L-2$.  

$d=2$, "rectangle" configuration.  $(i,j) \in \mathbb{Z}^2$.   $\begin{aligned} & \quad \\ 
&	 i \in 0,1,\dots L_x-1 \\ 
&	 j \in 0,1,\dots L_y-1 \end{aligned}$.  Lattice site $\mathbf{k} \in \Lambda = \Lambda_{d=2}$.  \\ $\forall \, \mathbf{k} \in \Lambda$, $\exists \, $ bijection to its "grid coordinates" $(i,j)$, $\mathbf{k} \mapsto (i,j)$, and $\exists \, \sigma_{\mathbf{k}} $ i.e. $\sigma_{\mathbf{k}} = \sigma_{ij} \in \lbrace -1,1\rbrace$.  \\
spin configuration $\sigma: \Lambda \mapsto (\sigma_{\mathbf{k}})_{\mathbf{k} \in \Lambda} \in \lbrace -1,1\rbrace^{|\Lambda|}$, where $|\Lambda | \equiv |\Lambda_{d=2} | = L_xL_y$.  \\
$\forall \, \mathbf{k} \in \Lambda$, $\exists \, !$ only at most 4 edges, given by $\mathbf{k} \mapsto (i,j)$, $(i \pm 1, j ), (i,j\pm 1)$, \  $\begin{aligned} & \quad \\ & i = 1\dots L_x -2 \\ & j = 1\dots L_y-2 \end{aligned}$.  

Note that in both cases, I haven't yet defined the boundary conditions, and leave that to be discussed thoroughly in the future (i.e. following sections).  

There are $2^{|\Lambda|}$ number of configurations in any dim. $d$.  

cf. \href{https://en.wikipedia.org/wiki/Ising_model}{Wikipedia, "Ising model"}

\subsubsection{Interaction $J_{ij} \equiv J_{\mathbf{k} \mathbf{l}}$, Hamiltonian (energy functional)for a configuration $H(\sigma)$}  

$\forall \, $ 2 adjacent (lattice) sites, $i,j \equiv \mathbf{k}, \mathbf{l} \in \Lambda$, let there be an interaction $J_{ij} \equiv J_{\mathbf{k} \mathbf{l}}$ i.e. $\begin{aligned} & \quad \\ 
& J : \Lambda^2 \to \mathbb{R} \\ 
& J: (\mathbf{k}, \mathbf{l}) \mapsto J_{\mathbf{k} \mathbf{l}} \end{aligned}$.   \\
Adjacent means $\exists \, $ edge $\mathbf{k} \mapsto \mathbf{l}$ (the mapping is the edge)  

Suppose $\forall \, $ site $j \equiv \mathbf{l} \in \Lambda$ , $\exists \, $ external magnetic field $h_j \equiv h_{\mathbf{l}}$ interacting with it.  \\
Given (site) configuration $\sigma : \Lambda \mapsto (\sigma_{\mathbf{k}})_{\mathbf{k} \in \Lambda} \in \lbrace -1 ,1 \rbrace^{ | \Lambda | }$.  
\begin{equation}
H(\sigma) = -\sum_{ \langle i j \rangle } J_{ij} \sigma_i \sigma_j - \mu \sum_j h_j \sigma_j \equiv H(\sigma(\Lambda)) = -\sum_{\langle \mathbf{k} \mathbf{l} \rangle } J_{\mathbf{k} \mathbf{l} }\sigma_{\mathbf{k}} \sigma_{\mathbf{l}} - \mu \sum_{ \mathbf{k} \in \Lambda } h_{\mathbf{k}} \sigma_{ \mathbf{k}}
\end{equation}
where $\sum_{ \langle \mathbf{k} \mathbf{l} \rangle }$ is overall pairs of adjacent spins (every pair is counted once),  \\
\phantom{where } $\langle \mathbf{k}, \mathbf{l} \rangle \equiv $ sites $\mathbf{k}, \mathbf{l}$ are nearest neighbors.  

Note sign in 2nd. term, $-\mu \sum_{\mathbf{k}} h_{\mathbf{k}} \sigma_{\mathbf{k}}$ should be positive because of electron's magnetic moment is antiparallel to its spin, but negative term used conventionally.  

Nothing was said about boundary conditions, I propose that it can be either fixed in the summation or by setting $J_{\mathbf{k} \mathbf{l}}=0$.  

$\forall \, \mathbf{k} \in \Lambda$, let $\begin{aligned} & \quad \\
	& \mathbf{y} : \Lambda \to E \\ 
		& \mathbf{y}: \mathbf{k} \mapsto \lbrace \langle \mathbf{k}, \mathbf{l} \rangle_{\mathbf{l}} \end{aligned}$, with $\lbrace \langle \mathbf{k}, \mathbf{l} \rangle \rbrace_{\mathbf{l}}$ be set of all edges from $\mathbf{k}$
		
		Then clearly $\sum_{\langle \mathbf{k} \mathbf{l} \rangle } = \frac{1}{2} \sum_{\mathbf{k} \in \Lambda} \sum_{ \lbrace \langle \mathbf{k} \mathbf{l} \rangle \rbrace_{\mathbf{l}}}$.  
		
		
Taking into account only interaction between adjoining dipoles, on a square lattice: 
\[
E(\sigma) = -J \sum_{k,l=0}^{L-1} ( \sigma_{kl}\sigma_{k,l+1} + \sigma_{kl} \sigma_{k+1, l} )
\]
cf. Landau and Lifshitz \cite{LaLi1980}


EY : 20171223 Things to check from Hjorth-Jensen (2015) \cite{Hjor2015}:  

2-dim. Ising model, with $\mathcal{B} \equiv h_j =0$, undergoes phase transition of 2nd. order: meaning below given critical temperature $T_C$, there's spontaneous magnetization with $\langle \mathcal{M} \rangle \equiv \langle \mathbf{M} \rangle \neq 0$.  $\langle \mathbf{B} \rangle \to 0$ at $T_C$ with \emph{infinite} slope, a behavior called \emph{critical phenomena}.  Critical phenomenon normally marked by 1 or more thermodynamical variables which is 0 above a critical point.  In this case, $\langle \mathbf{B} \rangle \neq 0$, such a parameter normally called \emph{order parameter}.  

Critical phenomena; we still don't have a satisfactory understanding of system's properties close to the critical point, even for simplest 3-dim. systems.  Even mean-field models can predict wrong physics; mean-field theory results in a 2nd.-order phase transition for 1-dim. Ising model, wherea 1-dim. Ising model doesn't predict any spontaneous magnetization at any finite temperature $T$.  

e.g. Consider 1-dim. $N$-spin system.  Assume periodic boundary conditions.  Consider state of all spins up, with total energy $-NJ$ and magnetization $N$.  Flip half of spins (e.g. all spins of index $i>N/2$) so 1st half of spins point upwards and last half points downwards.  Energy is $-NJ + 4J$, net magnetization $0$.  This is an example of a possible disordered state with net magnetization $0$.  Change in energy is too small to stabilize disordered state (to $-NJ$).  

\begin{definition}[configuration probability]
\textbf{configuration probability} $P_{\beta}(\sigma)$ given by Boltzmann distribution:  
\begin{equation}\label{Eq:Isingconfigprob}
 P_{\beta}(\sigma) = \frac{ \exp{ (-\beta H(\sigma))} }{ Z_{\beta} } = \text{ prob. of configuration } \sigma \equiv \sigma(\Lambda) \equiv (\sigma_{\mathbf{k}})_{\mathbf{k} \in \Lambda}
\end{equation} with the partition function as normalization constant $Z_{\beta}$: 
\begin{equation}\label{Eq:IsingPartitionFuncZ}
Z_{\beta} = \sum_{\sigma} \exp{ -\beta H(\sigma)}
\end{equation}
\end{definition}  



cf. pp. 504 Sec. 151 Phase transitions of the second kind in a 2-dim. lattice,  Landau and Lifshitz \cite{LaLi1980}


\begin{equation}\label{Eq:2dIsingZexact}
Z = 2^N(1-x^2)^{-N} \coprod_{p,q=0}^{L-1} \left[ (1+x^2)^2 - 2x(1-x^2) \left( \cos{ \frac{2\pi p}{L} } + \cos{ \frac{2\pi q }{L} } \right) \right]^{1/2} 
\end{equation}
cf. (151.11) of Landau and Lifshitz \cite{LaLi1980}, where $x= \tanh{\theta}$, $\theta = J/T \equiv J/\tau = \beta J$.  

\begin{equation}
\begin{gathered}
\Phi \equiv F = -\tau \ln{Z} = \\
= -\tau N \ln{2} + \tau N \ln{ (1-x^2)} - \frac{\tau}{2} \sum_{p,q=0}^L \ln{ \left[ (1+x^2)^2 - 2x(1-x^2) \left( \cos{ \frac{2\pi p}{L} } + \cos{ \frac{2\pi q }{L} } \right) \right] }
\end{gathered}
\end{equation}

Let $\begin{aligned}& \quad \\ 
& \omega_1 = \frac{2\pi p }{ L } \text{ with } p\to 0 \text{ as } L \to \infty \\ 
& \omega_2 = \frac{2\pi q }{ L } \text{ with } q\to 0 \text{ as } L \to \infty \end{aligned}$ so $\begin{aligned} & \quad \\ 
& \frac{ L d\omega_1 }{2\pi } = dp \\ 
& \frac{ L d\omega_2}{ 2\pi } = dq \end{aligned}$ and using $L^2 = N$.  


\[
\Phi = -\tau N \ln{2} + \tau N \ln{ (1-x^2)} - \frac{N\tau }{ 2(2\pi)^2 } \int_0^{2\pi } \int_0^{2\pi } d\omega_1 d\omega_2 \ln{ \left[ (1-x^2) -  2x(1-x^2) \left( \cos{  \omega_1 } + \cos{  \omega_2 } \right) \right]  }
\] 

$F \equiv \Phi$ has singularity when $  (1-x^2) -  2x(1-x^2) \left( \cos{  \omega_1 } + \cos{  \omega_2 } \right)  $ in $\ln{ \left[ (1-x^2) -  2x(1-x^2) \left( \cos{  \omega_1 } + \cos{  \omega_2 } \right) \right]  }$.  \\
$  (1-x^2) -  2x(1-x^2) \left( \cos{  \omega_1 } + \cos{  \omega_2 } \right) $ minimized when $\cos{\omega_1} = \cos{\omega_2}=1$ (since $-1 < x < 1$) 
\[
\begin{gathered}
\Longrightarrow (1+x^2)^2 - 4x(1-x^2 ) = 1+2x^2 + x^4 - 4x + 4x^3 = (x^2+2x-1)^2 =0 \Longrightarrow x = \frac{-2 \pm \sqrt{ 4-4(-1) } }{2} = -1 + \sqrt{2} \\
x = \tanh{\theta} = \frac{e^{\theta} - e^{-\theta} }{ e^{\theta} + e^{-\theta} } = \sqrt{2}  -1 \text{ or } \begin{gathered}
\qquad \\ e^{\theta} - e^{-\theta} = \sqrt{2} e^{\theta} + \sqrt{2} e^{-\theta} - e^{\theta} - e^{-\theta} \text{ so } \\ 
(2-\sqrt{2}) e^{\theta} = \sqrt{2} e^{-\theta} \\
e^{2\theta} = \frac{\sqrt{2}}{ 2-\sqrt{2}} \left( \frac{2+\sqrt{2} }{ 2 + \sqrt{2}} \right) \text{ or } \\ 
2\theta = \ln{ (1+ \sqrt{2})}
\end{gathered}
\end{gathered}
\]

\[
\begin{gathered}
\frac{J}{T_c} = \frac{1}{2} \ln{ (1+\sqrt{2})} \text{ or } 
\end{gathered}
\]
\begin{equation}
\boxed{ \tau_c = \frac{2J}{ \ln{ (1+\sqrt{2}) }} }
\end{equation}
so that $\tau_C \equiv T_C$ is where phase transition occurs.  

Let $t:= \tau - \tau_c$.  $\theta = \frac{J}{\tau} = \frac{J}{t+\tau_C}$  

Expand about minimum  

EY:20171230 do this explicitly 

\[
\begin{gathered}
\int_0^{2\pi } \int_0^{2\pi} d\omega_1 d\omega_2 \ln{ [ c_1 t^2 + c_2(\omega_1^2 + \omega_2^2 )]} \\ 
F  \equiv \Phi \simeq a + \frac{1}{2} b (\tau-\tau_c)^2 \ln{ |\tau-\tau_c|} \\ 
C = \frac{ \partial^2 F}{ \partial \tau } \simeq - b\tau_c \ln{ |\tau-\tau_c| }
\end{gathered}
\]
with $C$ being heat capacity.  

Order parameter $\langle M \rangle \equiv \eta = \text{constant}(\tau_c - \tau)^{1/8} = \begin{cases} 0 & \text{ if } \tau > \tau_c \\ 
\text{ constant } (\tau_c-\tau)^{1/8} & \text{ if } \tau < \tau_c \end{cases}$  

cf. pp. 505 Sec. 151 Phase transitions of the second kind in a 2-dim. lattice,  Landau and Lifshitz \cite{LaLi1980}, L.Onsager 1947.  

\subsection{An actual calculation of a small number of spins with Ising model}  

Sec. 3.7 "An actual calculation" on pp. 76 of Newman and Barkema (1999) \cite{NeBa1999}
goes through a simple actual Monte Carlo calculation as a test case check so to compare this exact calculation/solution to the simulation, as a test of whether the simulation/program is correct.  This is done in Sec. 1.3 of Newman and Barkema (1999) \cite{NeBa1999}.  

However, none of these promised simple calculations were shown explicitly in Newman and Barkema (1999) \cite{NeBa1999}.  I will forego this simple case.  

\subsection{Explicit calculation showing stencil operation on each spin on a periodic lattice grid}  

Consider 
\[
\begin{gathered}
H(\sigma) = -\sum_{ \langle \mathbf{k} \mathbf{l} \rangle } J \sigma_{\mathbf{k}} \sigma_{\mathbf{l}} =  -J \sum_{i=0}^{L_x-1} \sum_{j=0}^{L_y-1} \sigma_{ij}( \sigma_{i+1j} + \sigma_{ij+1} ) = \\	
= \frac{-J}{2} \left( \sum_{i=0}^{L_x-1} \sum_{j=0}^{L_y-1} \sigma_{ij} (\sigma_{i+1 j} + \sigma_{ij+1} ) + \sum_{i=1}^{L_x} \sum_{j=0}^{L_y-1}   \sigma_{i-1j} (\sigma_{ij} + \sigma_{i-1 j+1} ) \right) = \\
	= \frac{-J}{2} \left( \sum_{i=0}^{L_x-1} \sum_{j=0}^{L_y-1} \sigma_{ij} (\sigma_{i+1 j} + \sigma_{ij+1} ) + \sum_{i=1}^{L_x} \sum_{j=0}^{L_y-1}   \sigma_{i-1j} \sigma_{ij} + \sum_{i=0}^{L_x-1} \sum_{j=1}^{L_y} \sigma_{i j-1} \sigma_{ij} \right) 
\end{gathered}
\]
Now for each of these terms, 
\[
\begin{gathered}
	\sum_{i=1}^{L_x} \sum_{j=0}^{L_y-1} \sigma_{i-1 j} \sigma_{ij} = \sum_{i=1}^{L_x} \left( \sum_{j=1}^{ L_y-1 } \sigma_{i-1 j} \sigma_{ij} + \sigma_{i-1 0 }\sigma_{i0} \right) = \sum_{i=1}^{L_x-1} \left( \sum_{j=1}^{L_y-1} \sigma_{i-1 j} \sigma_{ij} + \sigma_{i-10} \sigma_{i0} \right) + \left( \sum_{j=1}^{L_y-1} \sigma_{L_x-1 j } \sigma_{L_xj} \right) + \sigma_{L_x-1 0 } \sigma_{L_x0}   \\ 
\sum_{i=0}^{L_x-1} \sum_{j=1}^{L_y} \sigma_{ij-1} \sigma_{ij} = \sum_{j=1}^{L_y-1} \left( \sum_{i=1}^{L_x-1} \sigma_{ij-1} \sigma_{ij}+ \sigma_{0j-1} \sigma_{0j} \right)  + \sum_{i=1}^{L_x-1} \sigma_{i L_y-1} \sigma_{iL_y} + \sigma_{0L_y-1} \sigma_{0L_y} 
\end{gathered}
\]
\[
\begin{gathered}
	\sum_{i=0}^{L_x-1} \sum_{j=0}^{L_y-1} \sigma_{ij} (\sigma_{i+1j } + \sigma_{ij+1} ) = \sum_{i=0}^{L_x-1} \left( \sum_{j=1}^{L_y} \sigma_{ij} ( \sigma_{i+1j } + \sigma_{ij+1} ) + \sigma_{i0} (\sigma_{i+1 0 } + \sigma_{i1} ) \right) = \\
	\sum_{i=1}^{L_x-1} \left( \sum_{j=1}^{L_y-1} \sigma_{ij} (\sigma_{i+1j}  + \sigma_{ij+1}) + \sigma_{i0} (\sigma_{i+1 0 } + \sigma_{i1}) \right) + \sum_{j=1}^{L_y-1} \sigma_{0j} (\sigma_{1j} + \sigma_{0j+1} ) + \sigma_{00} (\sigma_{10} + \sigma_{01} )
\end{gathered}
\]

Apply periodic boundary conditions.  Adding up all the terms above, clearly we obtain 1 term which shows the stencil operation for spins on the "interior" of the grid: 
\[
\sum_{i=1}^{L_x-1} \sum_{j=1}^{L_y-1} \sigma_{ij} ( \sigma_{i+1j} + \sigma_{ij+1} + \sigma_{i-1j} + \sigma_{ij-1} )
\]
and if we apply \emph{periodic} boundary conditions, neatly, we'll see all the lattice sites at the boundary also will have this stencil operation:  
\[
\begin{gathered}
	\sum_{i=1}^{L_x - 1} \sigma_{i0} (\sigma_{i+10} + \sigma_{i1} ) + \sum_{j=1}^{L_y-1} \sigma_{0j} (\sigma_{1j} + \sigma_{0j+1} ) + \sigma_{00} (\sigma_{10} + \sigma_{01} ) + \left( \sum_{i=1}^{L_x-1} \sigma_{iL_y-1} \sigma_{i0} \right) + \sigma_{0L_y-1} \sigma_{00} + \sum_{j=1}^{L_y-1} \sigma_{0j-1} \sigma_{0j} +  \\
	+ \sum_{j=1}^{L_y - 1} \sigma_{L_x- 1 j} \sigma_{0j} + \sigma_{L_x-1 0} \sigma_{00} + \sum_{i=1}^{L_x-1} \sigma_{i-10} \sigma_{i0} 
\end{gathered}
\]

Now, we can obtain the following for Hamiltonian, given spin configuration $\sigma$ with a lattice grid obeying periodic conditions:  

\begin{equation}
\begin{gathered}
H(\sigma) = -\frac{J}{2} \sum_{i=0}^{L_x-1} \sum_{j=0}^{L_y-1} \sigma_{ij} (\sigma_{i+1j } + \sigma{i-1j} + \sigma_{ij+1} + \sigma_{ij-1} ) = \\
= \frac{-J}{2} \left[  \sum_{i=0}^{L_x-1} \left( \sum_{ \substack{ j=0 \\ j \neq j' \\ } }^{L_y -1} \sigma_{ij} ( \sigma_{i+1j} +  \sigma_{i-1j} + \sigma_{ij+1} + \sigma_{ij-1} ) + \sigma_{ij'} ( \sigma_{i+1j'} + \sigma_{i-1j'} + \sigma_{ij'+1} + \sigma_{ij'-1}  ) \right)  + \right. \\ 
\left. \sum_{ \substack{j=0 \\ j\neq j' \\ } }^{L_y-1} \sigma_{i'j} ( \sigma_{i'+1j} + \sigma_{i'-1j} + \sigma_{i'j+1} + \sigma_{i'j-1} ) + \sigma_{i'j'} ( \sigma_{i'+1j'}  + \sigma_{i'-1j'} + \sigma_{i'j'+1} + \sigma_{i'j'-1}) \right] 
 \end{gathered}
\end{equation}

Consider a psin flip of $\sigma_{i'j'}$.  Contribution to $\Delta H$ at stencil operation on $\sigma_{i'j'}$, at $(i'j') \in \Lambda$, is 
\[
\frac{-J}{2} ( - \sigma_{i'j'} - \sigma_{i'j'} ) (\sigma_{i'+1j'} + \sigma_{i'-1j'} + \sigma_{i'j'+1} + \sigma_{i'j'-1}) = J\sigma_{i'j'} ( \sigma_{i'+1j'} + \sigma_{i'-1j'} + \sigma_{i'j'+1} + \sigma_{i'j'-1})
\]
Consider $\sigma_{i'j'} \sigma_{i'+1j'}$.  Clearly, term $\sigma_{i-1j'} \sigma_{ij'}$ with $i=i'+1$ only occurs once more in the summation.  Thus, we can definitely conclude that for $\Delta H \equiv \Delta H(\Delta \sigma_{i'j'})$ due to a single spin-flip is 
\begin{equation}
\Delta H(\Delta \sigma_{i'j'}) = 2J\sigma_{i'j'} ( \sigma_{i'+1j'} + \sigma_{i'-1j'} + \sigma_{i'j'+1} + \sigma_{i'j'-1} )
\end{equation}


\url{https://www.colorado.edu/physics/phys7240/phys7240_fa12/notes/Week3.pdf}
\href{https://www.colorado.edu/physics/phys7240/phys7240_fa12/notes/Week3.pdf}{Victor Gurarie, Advanced Statistical Mechanics, Fall 2012}
Exact solution by transfer matrices for 2-dim. Ising model.  


\part{Conformal Field Theory; Virasoro Algebra}  

cf. Schottenloher (2008)  \cite{Scho2008}

\section{Conformal Transformations}

\subsection{Semi-Riemannian manifolds (review and (key) examples)}

cf. pp. 7, Ch. 1 "Conformal Transformations and Conformal Killing Fields." Schottenloher (2008)  \cite{Scho2008}

Semi-Riemannian manifold is a pair $(M, g)$ s.t. \\
smooth manifold $M$, $\text{dim}{M} = n$, \\
smooth tensor field $g$ s.t. $g: a\in M \mapsto \Omega^2(T_aM)$, i.e. 
$\forall \, a \in M$, $g$ assigns $a$ a nonnegative and symmetric bilinear form on tangent space $T_aM$. 

In local coordinates, $x^1 \dots x^n $ of manifold $M$,  \\
given chart $\phi : U \to V$, open subset $U \subseteq M$, open subset $V \subseteq \mathbb{R}^n$, 
\[
\phi(a) = (x^1(a) \dots x^n(a)), \, a\in M
\]
Bilinear form $g_a$ on $T_aM$, written
\[
g_a(X,Y) = g_{\mu \nu}(a) X^{\mu} Y^{\nu}
\]

Tangent vectors $X = X^{\mu} \partial_{\mu}$, $Y = Y^{\nu} \partial_{\nu} \in T_aM$ basis $\partial_{\mu} := \frac{ \partial }{ \partial x^{\mu}}$, $\mu = 1 \dots n$ of tangent space $T_aM$, induced by chart $\phi$. 

By assumption, matrix
\[
g_{\mu \nu}(a)
\]
Nondegenerate and symmetric, $\forall \, a \in U$, i.e. 
\[
\text{det}(g_{\mu \nu }(a)) \neq 0 , \qquad \, (g_{\mu \nu}(a))^T = (g_{\mu \nu}(a))
\]

Differentiating of $g_a$ implies matrix $g_{\mu \nu}(a)$ depends differentiably on $a$.

That means that in its dependence on local coordinates $x^j$, coefficient $g_{\mu \nu} = g_{\mu \nu}(x)$ are smooth functions.

In general, $g_{\mu \nu}X^{\mu} X^{\nu} >0 $ doesn't hold $\forall \, X \neq 0$, i.e. $g_{\mu \nu}(a)$ not required to be positive-definite.

2 important subcases: \footnote{\url{https://doc.sagemath.org/html/en/reference/manifolds/sage/manifolds/differentiable/pseudo_riemannian.html}}

Riemannian manifold: metric $g$ positive definite, signature $n= \text{dim}M$. 

Lorentz manifold specified as semi-Riemannian manifold with $(p,q)= (n-1,1)$ or $(p,q) = (1, n-1)$. 

Metric $g$ has signature $n-2$ (positive convention) or $2-n$ (negative convention).

\subsubsection{Examples (of Riemannian manifolds for Conformal Field Theory)}

$\mathbb{R}^{p,q} = (\mathbb{R}^{p,q}, g^{p,q})$, $p,q \in \mathbb{N}$, where
\[
g^{p,q}(X,Y) := \sum_{i=1}^p X^i Y^i - \sum_{i = p+1}^{p+q} X^i Y^i
\]

Hence
\[
(g_{\mu \nu}) = \left( \begin{matrix} 1_p & \\ & -1_q \end{matrix} \right) = \text{diag}(1\dots 1, -1, \dots  -1)
\]

$\mathbb{R}^{1,3} = \mathbb{R}^{3,1}$, usual Minkowski space. \\
$\mathbb{R}^{1,1}$, 2 -dim. Minkowski space (Minkowski plane). \\
$\mathbb{R}^{2,0}$, Euclidean plane. \\
$\mathbb{S}^2 \subset \mathbb{R}^{3,0}$, compactification of $\mathbb{R}^{2,0}$, structure of Riemannian manifold on 2-sphere $\mathbb{S}^2$ induced by inclusion in $\mathbb{R}^{2,0}$ \\
$\mathbb{S} \times \mathbb{S} \subset \mathbb{R}^{2,2}$, compactification of $\mathbb{R}^{1,1}$. More precisely, \\
$\mathbb{S} \times \mathbb{S} \subset \mathbb{R}^{2,0} \times \mathbb{R}^{0,2} \simeq \mathbb{R}^{2,2}$ where structure of semi-Riemannian manifold on $\mathbb{S} \times \mathbb{S}$ induced by inclusion into $\mathbb{R}^{2,2}$. 

$\mathbb{S}^p \times \mathbb{S}^q \subset \mathbb{R}^{p+1, 0} \times \mathbb{R}^{0, q+1} \simeq \mathbb{R}^{p+1,q+1}$ with $p$-sphere $\mathbb{S}^p = \lbrace X \in \mathbb{R}^{p+1} : g^{p+1, 0}(X,X) = 1\rbrace \subset \mathbb{R}^{p+1,0}$, $q$-sphere $\mathbb{S}^q \subset \mathbb{R}^{0, q+1}$ \\
yields a compactification of $\mathbb{R}^{p,q}$ for $p,q \geq 1$

Compact semi-Riemannian manifold denoted by $\mathbb{S}^{p,q}$, for $p, q\geq 0$.

Quadrics $N^{p,q}$ (of Sec. 2.1) are locally isomorphic to $\mathbb{S}^{p,q}$ from point of view of conformal geometry.

For the "\emph{negative convention}": 

\[
g^{p,q}(X,Y) = - \sum_{i=0}^{p-1} X^i Y^i + \sum_{i=p}^{p+q} X^i Y^i
\]
\[
(g_{\mu \nu}) = \left( \begin{matrix} -1_p & \\ & 1_q \end{matrix} \right) = \text{diag}(-1 , \dots - 1, 1 \dots 1)
\]

$\mathbb{R}^{1,3} $, Minkowski space. \\
$\mathbb{R}^{1,1}$, 2 -dim. Minkowski space. \\
$\mathbb{R}^{0,2}$, Euclidean plane. \\
$\mathbb{S}^2 \subset \mathbb{R}^{0,3}$, compactification of $\mathbb{R}^{0,2}$ \\
$\mathbb{S} \times \mathbb{S} \subset \mathbb{R}^{0,2} \times \mathbb{R}^{2,0} \simeq \mathbb{R}^{2,2}$ 

$\mathbb{S}^p \times \mathbb{S}^q \subset \mathbb{R}^{0, p+1} \times \mathbb{R}^{q+1, 0} \simeq \mathbb{R}^{p+1,q+1}$ with $p$-sphere $\mathbb{S}^p = \lbrace X \in \mathbb{R}^{p+1} : g^{ 0, p+1}(X,X) = 1\rbrace \subset \mathbb{R}^{0, p+1}$, $q$-sphere $\mathbb{S}^q \subset \mathbb{R}^{q+1, 0}$ \\
yields a compactification of $\mathbb{R}^{p,q}$ 




\begin{definition}[Conformal transformation or conformal map]
Let 2 semi-Riemannian manifolds$(M,g)$, $(M',g')$, $\text{dim}M = \text{dim}M'$, let open $U\subset M$, open $V\subset M'$.  

\textbf{conformal transformation} or \textbf{conformal map} is a smooth $\varphi : U\to V$ of maximal rank, if $\exists \, $ smooth $\Omega : U\to \mathbb{R}^+$ s.t. 
\begin{equation}
	\varphi^* g' = \Omega^2 g
\end{equation}
where $\varphi* g'(X,Y) :=g'(T\varphi(X), T\varphi(Y))$ and $T\varphi: TU \to TV$ denote tangent map (derivative) of $\varphi$.  

$\Omega \equiv $ \emph{conformal factor} of $\varphi$.  
\end{definition}

Locally, $y^i = \varphi^i(x)$, \[
\begin{gathered}
	\frac{ \partial \varphi^i }{ \partial x^j} = \frac{ \partial y^i }{ \partial x^j}
\end{gathered}	
\]
Then
\[
X = X^k \frac{ \partial }{ \partial x^k} = X^k \frac{ \partial y^i }{ \partial x^k} \frac{ \partial }{ \partial y^i } = X^k \frac{ \partial \varphi^i }{ \partial x^k} \frac{ \partial }{ \partial y^k} \in TM
\]
and so 
\[
\begin{gathered}
	\varphi^* g'(X,Y) = g'(T\varphi(X), T\varphi(Y)) = (g')_{ij} X^k \frac{ \partial y^i }{ \partial x^k} Y^l \frac{ \partial y^j }{ \partial x^l} = (g')_{ij} X^k \frac{ \partial \varphi^i }{ \partial x^k } Y^l \frac{ \partial y^j}{ \partial x^l} \\ 
\Longrightarrow (\varphi^* g')_{kl} = (g')_{ij} \frac{ \partial y^i }{ \partial x^k } \frac{ \partial y^j}{ \partial x^l } \\ 
\Longrightarrow (\varphi^* g')_{kl} = (g')_{ij} \frac{ \partial \varphi^i }{ \partial x^k} \frac{ \partial \varphi^j}{ \partial x^l} = \Omega^2 g_{kl}
\end{gathered}
\]


% 20170926  

\begin{definition}
	\textbf{extension} of $G$ by group $A$ is (given by) an \emph{exact sequence} of group homomorphisms.  
	\begin{tikzpicture}
	%\matrix(m)[matrix of math nodes, row sep=3em, column sep=3em, text height=1.5ex, text depth=0.25ex]
	\matrix(m)[matrix of math nodes, row sep=4em, column sep=4em]
	{
		1   &  A & E & G & 1 \\
	};
	%\path[->,font=\scriptsize]
	\path[->]
	(m-1-1) edge node[auto]{$$} (m-1-2)
	(m-1-2) edge node[auto]{$i$} (m-1-3)
	(m-1-3) edge node[auto]{$\pi$} (m-1-4)
	(m-1-4) edge node[auto]{$$} (m-1-5)	
	;
	\end{tikzpicture} 
\end{definition}
cf. Def. 3.1 of Schottenloher (2008)  \cite{Scho2008}.  

Recall that an exact sequence, if $\begin{aligned} & \quad \\
	& \text{im}(1\to A) = \text{ker}(i) \\
	& \text{im}(i) = \text{ker}(\pi) \\
	& \text{im}(\pi) = \text{ker}(G\to 1)
\end{aligned}$

By Thm., 
$1\to A \xrightarrow{i} E$ exact so $i$ injective.  \\
$E\xrightarrow{\pi} G \to 1$ exact so $\pi$ surjective.  

Extension is called \textbf{central} if $A$ abelian and image $\text{im}i$ is in center of $E$, i.e. 
$a\in A, b\in E \Longrightarrow i(a) b = bi(a)$.  

\subsubsection{Examples of extensions of $G$, and central extensions of $G$ (which has a particular $E$)}
\begin{itemize}
\item e.g. central extension has form 
\[
\begin{tikzpicture}
%\matrix(m)[matrix of math nodes, row sep=3em, column sep=3em, text height=1.5ex, text depth=0.25ex]
\matrix(m)[matrix of math nodes, row sep=4em, column sep=4em]
{
	1   &  A & A\times G & G & 1 \\
};
%\path[->,font=\scriptsize]
\path[->]
(m-1-1) edge node[auto]{$$} (m-1-2)
(m-1-2) edge node[auto]{$i$} (m-1-3)
(m-1-3) edge node[auto]{$\text{pr}_2$} (m-1-4)
(m-1-4) edge node[auto]{$$} (m-1-5)	
;
\end{tikzpicture} 
\]
where  \\
$\begin{aligned}
 i:A & \to A\times G \\
a & \mapsto (a,1) \end{aligned}$ 

\[
\begin{gathered}
i(a)(a',g) = (a,1)(a',g) = (aa',g) = \\
= (a'a,g\cdot 1) = (a',g)(a,1) = (a',g)i(a)
\end{gathered}
\]

Notice that what the \emph{exactness} property of an exact sequence does:
\[
\text{pr}_2i(a) = \text{pr}_2(a,1) = 1
\]

\item e.g. of a \text{nontrivial central extension} is exact sequence 
\begin{equation}
\begin{tikzpicture}
%\matrix(m)[matrix of math nodes, row sep=3em, column sep=3em, text height=1.5ex, text depth=0.25ex]
\matrix(m)[matrix of math nodes, row sep=4em, column sep=4em]
{
	1   &  \mathbb{Z}/k\mathbb{Z} & E\times U(1) & U(1) & 1 \\
};
%\path[->,font=\scriptsize]
\path[->]
(m-1-1) edge node[auto]{$$} (m-1-2)
(m-1-2) edge node[auto]{$$} (m-1-3)
(m-1-3) edge node[auto]{$\pi$} (m-1-4)
(m-1-4) edge node[auto]{$$} (m-1-5)	
;
\end{tikzpicture} 
\end{equation}
with $\pi(z) = z^k$ \, $\forall \, k \in \mathbb{N}$, $k\geq 2$, since $E=U(1)$ and $\mathbb{Z}/k\mathbb{Z}$ are not isomorphic.  

Also, homomorphism $\tau:U(1) \to E$ with $\pi \circ \tau = 1_{U(1)}$, doesn't exist, since there's no global $k$th root.  

EY : 20170926 It's that in integer division of the argument in a complex number $z\in U(1)$, and exponent multiplication by $k$, you go from 1 to many and many to 1, depending upon the "branch" you're mapping to for complex numbers.  

For $[n] \in \mathbb{Z}/k\mathbb{Z}$, 
\[
[n]\xmapsto[]{ i } \exp{ \left( \frac{ [n] }{ k} 2\pi i \right) }
\]
and so 
\[
\text{ker}\pi = \lbrace z | \pi(z) = 1 \rbrace \text{ so that } \text{ker}\pi = \lbrace z = \exp{ \left( \frac{i 2\pi n}{k} \right) } \rbrace
\]

\item e.g. \emph{Semidirect products}.  

group $G$ acting on another group $H$, by homomorphism   
\[
\tau : G \to \text{Aut}(H)
\]




%  20170926  of END 

\begin{definition}[semi-direct product]\label{Def:Semidirectprod}
\textbf{semidirect product} group $G \ltimes H$ is set $H\times G$, with multiplication 
\[
(x,g) \cdot (x',g') := (x\tau(g)(x'), gg') \qquad \, \forall \, (x,g), (x',g') \in H\times G
\]
\end{definition}
\begin{equation}
\begin{tikzpicture}
%\matrix(m)[matrix of math nodes, row sep=3em, column sep=3em, text height=1.5ex, text depth=0.25ex]
\matrix(m)[matrix of math nodes, row sep=4em, column sep=4em]
{
	1   &  H &  G \ltimes H & G & 1 \\
};
%\path[->,font=\scriptsize]
\path[->]
(m-1-1) edge node[auto]{$$} (m-1-2)
(m-1-2) edge node[auto]{$i$} (m-1-3)
(m-1-3) edge node[auto]{$\pi$} (m-1-4)
(m-1-4) edge node[auto]{$$} (m-1-5)	
;
\end{tikzpicture} 
\end{equation}
with 
\begin{equation}
	\begin{aligned}
	& i : H\to G \ltimes H \\ 
	& i(x) = (x,1)
\end{aligned}
\end{equation}
$i$ group homomorphism, since 
\[
i(x_1x_2) = (x_1x_2 ,1) = (x_1 \tau(1)x_2 , 1) = (x_1,1)\cdot (x_2,1) = i(x_1)i(x_2)
\]
\begin{equation}
	\begin{aligned}
	& \pi : G \ltimes H \to G\\ 
	& \pi(x,g) = g 
\end{aligned}
\end{equation}
cf. \url{http://sierra.nmsu.edu/morandi/oldwebpages/math683fall2002/GroupExtensions.pdf}

Observe that 
\[
\pi i(x) = \pi(x,1)=1 \text{ so } \text{ker}\pi = \text{im}i
\]

\begin{definition}[Semi-direct product (2); with direct product]\label{Def:Semidirectprod2}
	\textbf{direct product} $G=HK$ if \\
$H,K$ subgroups of group $G$, s.t. \\
\begin{itemize}
\item $H$ and $K$ are normal in $G$ ($gkg^{-1} \in K$ \, $\forall \, g\in G$, $\forall \, k \in K$)  
\item $H\cap K = \lbrace 1 \rbrace$  
\item $HK=G$.  
\end{itemize} 

\textbf{semi-direct product}.  Relax the 1st condition (of direct products) so $H$ still normal in $G$, but $K$ need not be.  \\
\begin{itemize}
\item $H$ normal in $G$ ($ghg^{-1} \in H, \, \forall \, g , \, \forall \, h \in H$)  
\item $H\cap K = \lbrace 1 \rbrace$ 
\item $HK = G$
\end{itemize}
\end{definition}

\emph{Connection between} Def. \ref{Def:Semidirectprod} and Def. \ref{Def:Semidirectprod2} for the \emph{semidirect product}:  Consider $\tau : G \to \text{Aut}(H)$.  

Consider $G \ltimes H$ - what is the identity $1_{G\ltimes H} \equiv (1_H,1_G)$ of this group?  
\[
(x,g)\cdot (1_H,1_G) = (x\tau(g) 1_H, g1_G) = (x\tau(g)1_H, g) \Longrightarrow 1_H = \tau(g^{-1})1, \, 1_G=1
\]
and so the inverse, $\forall (x,g) \in G\ltimes H$, $(x,g)^{-1} \equiv ((x^{-1}), (g^{-1}))$, 
\[
\begin{gathered}
	(x,g) (x,g)^{-1} = (x\tau(g) (x^{-1}),g(g^{-1}) ) = (x\tau(g)(x^{-1}), 1) \text{ (if $(g^{-1}) = g^{-1}$) }
\end{gathered}
\]
Moving along, 
\[
\begin{gathered}
	x\tau(g) (x^{-1}) = \tau(g^{-1})1 \\
\Longrightarrow (x^{-1}) = \tau(g^{-1}) x^{-1}\tau(g^{-1})1
\end{gathered}
\]

Checking out the $H$ being a normal subgroup of $G\ltimes H$ condition, i.e. $H \lhd G$, 
\[
\begin{gathered}
	(x,g)(h,1)(\tau(g^{-1})x^{-1} \tau(g^{-1}) , g^{-1}) = (x\tau(g)h, g)(\tau(g^{-1})x^{-1}\tau(g^{-1}) , g^{-1}) = \\
= (x\tau(g)h \tau(g)\tau(g^{-1}) x^{-1}\tau(g^{-1}), 1) = (x\tau(g) hx^{-1}\tau(g^{-1}), 1) 
\end{gathered}
\]
$\Longrightarrow$ $H$ normal subgroup of $G\ltimes H \equiv H \lhd (G\ltimes H)$.  

\href{http://www.math.columbia.edu/~bayer/S09/ModernAlgebra/semidirect.pdf}{Notes on Semidirect products}
\item extension 
\begin{equation}
\begin{tikzpicture}
%\matrix(m)[matrix of math nodes, row sep=3em, column sep=3em, text height=1.5ex, text depth=0.25ex]
\matrix(m)[matrix of math nodes, row sep=4em, column sep=4em]
{
	1   &  SL(n,\mathbb{R}) &  GL(n,\mathbb{R}) & \mathbb{R}^* & 1 \\
};
%\path[->,font=\scriptsize]
\path[->]
(m-1-1) edge node[auto]{$$} (m-1-2)
(m-1-2) edge node[auto]{$i$} (m-1-3)
(m-1-3) edge node[auto]{$\text{det}$} (m-1-4)
(m-1-4) edge node[auto]{$$} (m-1-5)	
;
\end{tikzpicture} 
\end{equation}

with \\
$GL(n,\mathbb{R}) \equiv Gl_n(\mathbb{R}) = \lbrace A | A \in \text{Mat}_{\mathbb{R}}(n,n); \text{det}A \neq 0\rbrace$ \\
$\text{det}:GL(n,\mathbb{R}) \to \mathbb{R}^* \equiv \mathbb{R} \backslash \lbrace 0 \rbrace $, $\text{det}$ surjective homomorphism \\
$SL(n,\mathbb{R}) \equiv Sl_n(\mathbb{R}) = \lbrace A | A \in \text{Mat}_{\mathbb{R}}(n,n); \, \text{det}A=1\rbrace$ \\

Note that $\text{ker}(\text{det}) = SL(n,\mathbb{R})$.  

Now 
\[
\mathbb{R}^* \simeq \lbrace a 1_n | a \in \mathbb{R}^* \rbrace
\]
and $\text{det}(a1_n) = a^n$.  

If $n$ odd, and $\text{det}(a1_n)=a^n =1$, then $a=1$.  If $n$ even, $a=\lbrace -1, 1 \rbrace$.  

By the second definition of a semi-direct product, Def. \ref{Def:Semidirectprod2}, it's required that $SL(n,\mathbb{R}) \cap \mathbb{R}^* = 1$ (i.e. the intersection is only the identity).  This will only be the case if $n$ odd.  

cf. \url{http://sierra.nmsu.edu/morandi/oldwebpages/math683fall2002/GroupExtensions.pdf}

\end{itemize}

\part{Quantum Mechanics}

\section{The Wave function and the Schr\"{o}dinger Equation, its probability interpretation, some postulates}

cf. Ch. 2 "The Wave Function and the Schr\"{o}dinger Equation" in \textbf{Quantum Mechanics} by Franz Schwabl (2007) \cite{FrSc2007}.

From experimental considerations (Sec. 1.2.2, Schwabl (2007) \cite{FrSc2007}), with electron diffraction, electrons, $e^-$, have wavelike properties; let this wave be $\psi(\mathbf{x}, t)$. 

For free $e^-$ of momentum $\mathbf{p}$, energy $E = \frac{ \mathbf{p}^2}{2m}$, in accordance with diffraction experiments, consider as free plane waves 
\[
\psi(\mathbf{x}, t) = C \exp{ \left( i ( \mathbf{k} \cdot \mathbf{x} - \omega t)\right)}, \qquad \, \omega = E / \hbar = E, \, \mathbf{k} = \mathbf{p}/ hbar = \mathbf{p}
\]
with $\hbar = 1$

Hypothesis: wave function $\psi(\mathbf{x},t)$ gives probability distribution 
\[
\rho(\mathbf{x}, t) = | \psi(\mathbf{x}, t)|^2
\]
$\rho(\mathbf{x}, t) d^3 x = $ probability of finding $e^-$ at location $\mathbf{x}$ in volume element $d^3x$.

e.g. $e^-$ waves $\psi_1(\mathbf{x}, t)$ , $\psi_2(\mathbf{x},t)$

If both slits open, superposition of wave functions $\psi_1(\mathbf{x}, t) + \psi_2(\mathbf{x},t)$

Note $| \psi_1(\mathbf{x},t) + \psi_2(\mathbf{x},t) |^2 \neq | \psi_1(\mathbf{x},t) |^2 + |\psi_2(\mathbf{x},t) |^2$ if there are no interference terms.

Important remarks: 

\begin{enumerate}
	\item[(i)] Single $e^-$ not smeared out. $\rho(\mathbf{x},t)$ is \textbf{not} the charge distribution of $e^-$, but is the probability density for measuring particle at position $\mathbf{x}$ at time $t$.
	\item[(ii)] Prob. distribution doesn't occur by interference of many simultaneously incoming $e^-$, but one obtains same interference pattern if each $e^-$ enters separately, i.e. even for very low intensity source. Thus, wave function applies to every electron and describes state of single $e^-$.
\end{enumerate}

cf. 2.2 "The Schr\"{o}dinger Equation for Free Particles" in \textbf{Quantum Mechanics} by Franz Schwabl (2007) \cite{FrSc2007}.

(i) 1st. order DE (differential equation); (ii) linear in $\psi$ for linear superposition (iii) "homogeneous" $\int d^3x | \psi(\mathbf{x}, t) |^2 = 1$, (iv) plane waves
\[
\psi(\mathbf{x},t) = C \exp{ \left[ i (\mathbf{p} \cdot \mathbf{x} - \frac{p^2}{2m} t)/ \hbar\right]} \qquad \, \text{ plane waves }
\]
Should be solutions of the equations.

From postulates (i-iv),
\[
i \hbar \frac{\partial}{ \partial t} \psi(\mathbf{x}, t) = \frac{ -\hbar^2}{2m } \nabla^2 \psi(\mathbf{x},t)
\]
Time-dependent Schr\"{o}dinger equation for free particles.

\[
\int_{-\infty}^{\infty} d^3k e^{i\mathbf{k} \cdot \mathbf{x}} e^{-k^2 \alpha^2} = \prod_{j=x}^z \int_{-\infty}^{\infty} dk_j e^{ik_j x_j} e^{-k_j^2 \alpha^2}  = \prod_{j=x}^z \left( \sqrt{ \frac{\pi}{\alpha^2} } \exp{ \left( \frac{-x_j^2}{4\alpha^2} \right)} \right) = \left( \frac{\sqrt{\pi}}{\alpha} \right)^3 \exp{ \left( \frac{-x^2}{4\alpha^2} \right)}
\]


\part{Algebraic Topology}  

cf. Bredon (1997) \cite{Bred1997}


\section{Simplicial Complexes}  

cf. pp. 245, from Sec. 21 Simplicial Complexes of Ch. 4 Homology Theory in Bredon (1997) \cite{Bred1997}

$\mathbf{v}_0, \dots \mathbf{v}_n \in \mathbb{R}^{\infty}$, "affinely independent" if they span an affine $n$-plane, i.e. 
\[
\text{ if } \left( \sum_{i=0}^n \lambda_i \mathbf{v}_i =0 , \, \sum_{i=0}^n \lambda_i = 0 \right), \text{ then } \Longrightarrow \forall \, \lambda_i = 0
\]
If not, then, e.g. $\lambda_0 \neq 0$, assume $\lambda_0 =-1$, and solve the equations to get 

\[
\begin{gathered}
\mathbf{v}_0 = \sum_{i=1}^n \lambda_i \mathbf{v}_i \\
\sum_{i=1}^n \lambda_i = 1
\end{gathered}
\]
i.e. $\mathbf{v}_0$ is in affine space spanned by $\mathbf{v}_1\dots \mathbf{v}_n$.  

If $\mathbf{v}_0, \dots \mathbf{v}_n$ affinely independent, then 
\begin{equation}
\sigma = ( \mathbf{v}_0, \dots \mathbf{v}_n) = \lbrace \sum_{i=0}^n \lambda_i \mathbf{v}_i | \sum_{i=0}^n \lambda_i = 1, \, \lambda_i \geq 0 \rbrace
\end{equation}
is "affine simplex" spanned by $\mathbf{v}_i$; also convex hull of $\mathbf{v}_i$.  

$\forall \, k \leq n$, $k$-face of $\sigma$ is any affine simplex of form $(\mathbf{v}_{i_1}, \dots \mathbf{v}_{i_k})$, where vertices all distinct, so are affinely independent.  

\begin{definition}
	(geometric) simplicial complex $K:= $ collection of affine simplices s.t. \begin{enumerate}
		\item $\sigma \in K \Longrightarrow $ any face of $\sigma \in K$; and 
		\item $\sigma, \tau \in K \Longrightarrow \sigma \bigcap \tau $ is a face of both $\sigma$ and $\tau$, or $\sigma \bigcap \tau =\emptyset$
	\end{enumerate}

If $K$ simplicial complex, $|K| = \bigcup \lbrace \sigma | \sigma \in K \rbrace \equiv $ "polyhedron" of $K$
\end{definition}

\begin{definition}[Def. 21.2 of Bredon (1997) \cite{Bred1997}]
	polyhedron $:= $ space $X$ if $\exists \, $ homeomorphism $h: |K| \xrightarrow{ \approx } X$ for some simplicial complex $K$.  
	$h,K$ is triangulation of $X$; (map $h$, complex $K$)
\end{definition}

Let $K$ finite simplicial complex.  \\
Choose ordering of vertices $\mathbf{v}_0,\mathbf{v}_1\dots $ of $K$.  \\
If $\sigma = (\mathbf{v}_{\sigma_0}, \dots \mathbf{v}_{\sigma_n})$ is simplex of $K$, where $\sigma_0 < \dots < \sigma_n$, then  \\
\phantom{If } let $f_{\sigma} : \Delta_n \to |K|$ be 
\[
f_{\sigma} = [\mathbf{v}_{\sigma_b}, \dots \mathbf{v}_{\sigma_n}]
\]
in notation of Def. 1.2.  Bredon (1997) \cite{Bred1997}.  

Then this gives CW-complex structure on $|K|$ with $f_{\sigma}$ as characteristic maps.  




\part{Graphs, Finite Graphs}

\section{Graphs, Finite Graphs, Trees }

Serre (1980) \cite{Serr1980}  

cf. Chapter I. Trees and Amalgams, Section 1 Amalgams, Subsection 1.1 Direct limits of Serre (1980) \cite{Serr1980}  


Let $(G_i)_{i\in I}$, family of groups.    

$\forall \, $ pair $(i,j)$, let $F_{ij} = $ set of homomorphisms of $G_i$ into $G_j$

Want: group $G= \varinjlim G_i$ and 
\[
\lbrace f_i | f_i : G_i \to G \rbrace \text{s.t. } f_j \circ f = f_i \quad \, \forall \, f \in F_{ij}
\]
group $G$ and family $\lbrace f_i\rbrace$ universal in that  

(*) if $H$ group, if $\lbrace h_i | h_i :G_i \to H ; h_j \circ f = h_i \qquad \, \forall \, f \in F_{ij} \rbrace$, \\
then $\exists \, ! h: G\to H$ s.t. $h_i = h\circ f_i$  \\
i.e. $\text{Hom}(G,H) \simeq \varprojlim \text{Hom}(G_i,H)$, the inverse limit being taken relative to $F_{ij}$.  \\
i.e. $G$ direct limit of $G_i$ relative to the $F_{ij}$.  

EY : 20170918 this is my rewrite/reinterpretation:

Let $(G_i)_{i\in I}$, $\forall \, (i,j) \in I^2$, let $F_{ij} = \lbrace f \equiv f_{ij} | f:G_i \to G_j , f \text{ homomorphism of $G_i$ into $G_j$ } \rbrace$.  

Given group $G = \varinjlim G_i$ (for fixed $i$), $\lbrace f_i | f_i : G_i \to G  |  f_j \circ f = f_i \quad \, \forall \, f \in F_{ij} \rbrace$, i.e.  

\begin{tikzpicture}
\matrix(m)[matrix of math nodes, row sep=4em, column sep=8em]
{
G_i    &  G   \\
G_j   &  \\};
\path[->]
(m-1-1) edge node[auto]{$f_i$} (m-1-2)
edge node[auto]{$f_{ij} \equiv f$} (m-2-1) 
(m-2-1) edge node[right]{$ f_j$ } (m-1-2);
\end{tikzpicture} 

Then $G$,  $\lbrace f_i | f_i : G_i \to G  |  f_j \circ f = f_i \quad \, \forall \, f \in F_{ij} \rbrace$ \textbf{universal} \\
\phantom{Then } if $\forall \, $ group $H$, $\forall \, \lbrace h_i |  h_i : G_i \to H  | h_j \circ f = h_i \quad \, \forall \, f \in F_{ij} \rbrace$, \\
\phantom{Then if } then $\exists \, ! \  h : G\to H$, s.t. $h_i = h \circ f_i$ i.e. 
\begin{tikzpicture}
\matrix(m)[matrix of math nodes, row sep=4em, column sep=8em]
{
H & G_i    &  G   \\
& G_j   &  \\};
\path[->]
(m-1-2) edge node[auto]{$f_i$} (m-1-3)
edge node[auto]{$f_{ij} \equiv f$} (m-2-2) 
edge node [auto]{$h_i$} (m-1-1)
(m-2-2) edge node[right]{$ f_j$ } (m-1-3)
edge node [auto]{$h_j$} (m-1-1) 
(m-1-3) edge[bend right = 30] node [auto]{ $\exists \, ! h$ } (m-1-1)  
;
\end{tikzpicture} 






\begin{proposition}
	$\exists \, !$ pair $G$, family $(f_i)_{i\in I}$, i.e. (pair consisting of $G, (f_i)_{i\in I}$, unique up to unique isomorphism.  
\end{proposition}
\begin{proof}
Define $G$ by generators and relations.  \\
Take generating family to be disjoint union of those for $G_i$.  \\
relations - $xyz^{-1}$ where $x,y,z \in G_i$, $z=xy \in G_i$ \\
\phantom{relations - } $xy^{-1}$ where $x\in G_i$, $y \in G_j$, $y=f(x)$ for at least $f\in F_{ij}$.  

Thus, existence of $G,\lbrace f_i\rbrace$.  

$G$ represents functor $H\mapsto \varprojlim \text{Hom}{(G_i,H)}$.  

Thus, uniqueness (also from universal property).  
\end{proof}

e.g. groups $A,G_1,G_2$, homomorphisms $\begin{aligned} & \quad \\ 
& f_1 : A \to G_1 \\
& f_2 : A \to G_2 
\end{aligned}$.  

$G$ obtained by amalgamating $A$ in $G_1,G_2$ by $f_1,f_2 \equiv G_1 *_A G_2$.  \\
1 can have $G=\lbrace 1 \rbrace$, even though $f_1,f_2$ non-trivial.  

\emph{Application}: (Van Kampen Thm.)

Let topological space $X$ be covered by open $U_1,U_2$.   \\
Suppose $U_1,U_2, U_{12}=U_1\bigcap U_2$ arcwise connected.  

Let basept. $x\in U_{12}$.  

Then $\pi_1(X;x)$ obtained by taking 3 groups 
\[
\pi_1(U_1;x), \pi_1(U_2;x), \pi_1(U_{12};x)
\]
and amalagamating them according to homomorphism
\[
\begin{aligned}
& \pi_1(U_{12};x) \to \pi_1(U_1;x)  \\
& \pi_1(U_{12};x) \to \pi_1(U_2;x)
\end{aligned}
\]

\exercisehead{1}  
Let homomorphisms $\begin{aligned} & \quad \\
	& f_1 : A \to G_1 \\ 
	& f_2: A \to G_2 \end{aligned}
$
amalgam $G=G_1 *_A G_2$.  

Define subgroups $A^n,G_1^n, G_2^n$, of $A,G_1,G_2$ recursively by 
\[
\begin{aligned}
& A^1 = \lbrace 1 \rbrace \\
& G_1^1 = \lbrace 1 \rbrace \\ 
& G_2^1 = \lbrace 1 \rbrace \\ 
\end{aligned}
\]

$A^n = $ subgroup of $A$ generated by $f_1^{-1}(G_1^{n-1})$ and $f_2^{-1}(G_2^{n-1})$  
\[
G_1^n = \text{subgroup of $G_i$ generated by $f_i(A^n)$ }
\]

Let $A^{\infty}, G_i^{\infty}$ be unions of $A^n, G_i^n$ resp.  

Show that $f_i$ defines injection $A/A^{\infty} \to G_i/G_i^{\infty}$.  

So the amalgamation is $G \simeq G_1/G_1^{\infty} *_{A/A^{\infty}} G_2/G_2^{\infty}$.  

Take the first induction case (for intuition about the solution).  

\[
\begin{aligned}
	& A^2 = \langle f_1^{-1}( G_1^1), f_2^{-1}(G_2^1) \rangle = \langle f_1^{-1}(\lbrace 1 \rbrace), f_2^{-1}(\lbrace 1 \rbrace ) \rangle \\
	& G_i^2 = f_i(A^2)
\end{aligned}
\]
Let $f_i(a) = f_i(b) \in G_i/G_i^{\infty}$; $a,b\in A/A^{\infty}$.  

Then since $f_i(a),f_i(b) \in G_i/G_i^{\infty}$, $f_i(a),f_i(b) \in \lbrace gG_i^{\infty} | g\in G_i \rbrace$ (quotient is defined to be the set of all left cosets of $G_i^{\infty}$, which has to be a normal subgroup for $G_i/G_i^{\infty}$ to be a quotient group).  

Since $a,b \in A/A^{\infty}$, suppose we take $a,b\in A$.  

And suppose we take 
\[
\begin{aligned}
& 	f_i(a) = f_i(a)G_i^{\infty} = f_i(a) f_i(A^{n_a} ) = f_i(aA^{n_a}) \\ 
& 	f_i(b) = f_i(b)G_i^{\infty} = f_i(b) f_i(A^{n_b} ) = f_i(bA^{n_b})  
\end{aligned}
\]
Taking $f_i^{-1}$ (recall for group homomorphisms, they map inverse of element of 1st. group to inverse of image of this element).  

$aA^{n_a}=bA^{n_b}\in A/A^{\infty}$ (This is okay as we've "quotiented out $A^{\infty}$; so indeed, they're equal)


cf. Subsection 1.2 Structure of amalgams of Serre (1980) \cite{Serr1980} 

Suppose given group $A$, family of groups $(G_i)_{i\in I}$, and, $\forall \, i\in I$, injective homomorphism $A\to G_i$.  

$*_A G_i \equiv $ direct limit (cf. no. 1.1) of family $(A,G_i)$ with respect to these homomorphisms, call it \emph{sum} (in category theory sense, i.e. product) of $G_i$ with $A$ amalgamated.  

e.g. $A=\lbrace 1 \rbrace$, \\
$*G_i \equiv $ free product of $G_i$.  

\subsubsection{reduced word}  

$\forall \, i \in I$, choose set $S_i$ of right coset representations of $G_i$ modulo $A$, 

assume $1 \in S_i$, 

$(a,s)\mapsto as$ is bijection of $A\times S_i$ onto $G_i$,  \\
$A\times (S_i-\lbrace 1 \rbrace) \to G_i-A$ (onto)

Let $\mathbf{i} = (i_1\dots i_n)$, $n\geq 0$, $i_j \in I$, s.t. 
\begin{equation}
i_m \neq i_{m+1} \text{ for } 1 \leq m \leq n-1
\end{equation}
cf. (T) of Serre (1980) \cite{Serr1980}.  

So \emph{reduced word} $m$ is defined as 
\[
m = (a;s_1\dots s_n)
\]
where $a\in A, s_1\in S_{i_1} \dots s_n \in S_{i_n}$, and $s-j \neq 1\, \forall \, j$.  

$f\equiv $ canonical homomorphism of $A$ into group $G= *_A G_i$ \\ 
$f_i \equiv $ canonical homomorphism of $G_i$ into group $G= *_A G_i$

EY : 20170611 (Further explanations, basic examples, from me):  

Given $A, \lbrace G_i\rbrace_{i\in I}$, injective (group) homomorphisms $\lbrace f_i: A \to G_i\rbrace_i$.  

$G_i \backslash f_i(A) = \lbrace f_i(A)g | g\in G_i\rbrace$.  

Right coset representation of $f_i(A)g\mapsto g$.  

e.g. $A,G_1,G_2$, $\begin{aligned} & \quad \\
	& f_1:A \to G_1 \\
		& f_2 : A\to G_2 \end{aligned}$.  
		
	\[
	\begin{aligned}
	& G_1\backslash f_1(A) = \lbrace f_1(A)g| g\in G_1\rbrace \\
	& G_2\backslash f_2(A) = \lbrace f_2(A)g | g\in G_2 \rbrace
	\end{aligned}
	\]

$\mathbf{i} = (i_1\dots i_n)$, $i_j\in I$, $i_m\neq i_{m+1}$ for $1\leq m \leq n-1$.  

Consider $(1212\dots 12)$  

$m=(a;f_1 g_2 f_3 g_4 \dots f_{2n-1}, g_{2n})$ where $f$'s $\in S_1 \subset G_1$, $g$'s $\in S_2 \subset G_2$.  

and so 
\begin{definition}[reduced word]
	\textbf{reduced word} of type $\mathbf{i}$, $m$, \begin{equation}
	m=(a;s_1\dots s_n)
	\end{equation}
	where $a\in A, s_1 \in S_{i_1}, \dots s_n \in S_{i_n}$, $s_j\neq 1$ \, $\forall \, j$, \\
	\phantom{where } $\mathbf{i} = (i_1\dots i_n)$, $i_j \in I$, s.t. $i_m \neq i_{m+1}$ for $1\leq m \leq n-1$, \\
	with $S_i = \lbrace g | g\in f_i(A)g \in f_i(A) G_i\rbrace$  
\end{definition}




\begin{theorem}[1 of Serre (1980) \cite{Serr1980} ]
	$\forall \, g \in G$, $\exists \, $ sequence $\mathbf{i}$ s.t. $i_m \neq i_{m+1}$ for $1\leq m \leq n-1$ and 
	
	reduced word 
	\[
	m = (a;s_1\dots s_n) 
	\]
	of type $\mathbf{i}$ s.t. 
	\[
	g = f(a)f_{i_1}(s_1) \dots f_{i_n}(s_n)
	\]
\end{theorem}

Furthermore, $\mathbf{i}$ and $m$ unique.  

\emph{Remark}.  Thm. 1 implies $f;f_i$ injective.  

Then identify $A$ and $G_i$ with images $f(A), f_i(G_i)$ in $G$, and reduced decomposition (*) of $g\in G$ 
\[
g = as_1\dots s_n, \quad \, a\in A, \, s_1 \in S_{i_1} - \lbrace 1 \rbrace \dots s_n \in S_{i_n} - \lbrace 1 \rbrace
\]
Likewise, $G_i \bigcap G_j = A$ if $i\neq j$.  

In particular, $S_i - \lbrace 1 \rbrace$ pairwise disjoint in $G$.  

\begin{proof}
Let $X_i \equiv $set of reduced words of type $\mathbf{i}$, $X = \coprod X_i$.  

Make $G$ act on $X$.  

In view of universal property of $G$, sufficient to make $\forall \, i, G_i$ act, 

check action induced on $A$ doesn't depend on $i$  

Suppose then that $i\in I$, and let $Y_i = $ set of reduced words of form $(1;s_1 \dots s_n)$, with $i_1\neq i$.  

EY : 20170611

Recall that 
\[
S_i = \lbrace g| g\in f_i(A) g \in f_i(A) G_i \rbrace
\]
\[
\begin{aligned}
	& A \times S_i \to G_i \text{ onto } \\ 
	& A\times (S_i - \lbrace 1 \rbrace) \to G_i - A \text{ onto } \\ 
	& (a,s) \mapsto as \text{ bijection }
\end{aligned}
\]

Let $Y_i = $ set of reduced words of form $(1; s_1 \dots s_n) = \lbrace (1;s_1 \dots s_n) | 1\in A; s_1 \in S_{i_1}\dots s_n \in S_{i_n} ; \mathbf{i} = (i_1\dots i_n), \, i_j \in I \text{ s.t. } i_m \neq i_{m+1} \text{ for } 1\leq m \leq n -1 \rbrace$.  

\[
\begin{gathered}
\begin{gathered}
A \times Y_i \to X = \coprod_i X_i \\
(a,(1; s_1 \dots s_n)) \mapsto (a; s_1 \dots s_n)
\end{gathered} \\
\begin{gathered}
A\times \lbrace S_i - \lbrace 1 \rbrace ) \times Y_i \to X \\
((a,s), (1;s_1 \dots s_n)) \mapsto (a;s,s_1\dots s_n)
\end{gathered}
\end{gathered}
\]
and remember that $X_i = $ set of reduced words of type $\mathbf{i}$.  

It's clear that this yields a bijection $A\times Y_i \bigcup A\times (S_i - \lbrace 1 \rbrace) \times Y_i \to X$.  

Let $x\in X$.  Then $x\in X_{\mathbf{i}}$ for some $\mathbf{i}$.  So $x$ is a reduced word of type $\mathbf{i}$: $x = (a;s_1\dots s_n)$.  Then clearly $x = (a;s_1\dots s_n) \mapsto (a,(1;s_1\dots s_n)) \in A\times Y_i$.  So $\forall \, x \in X$, $\exists (a, (1; s_1 \dots s_n) \in A \times Y_i)$. So we've proven, for part of bijection, the mapping going one way. \\

Identify $A \bigcup A \times (S_i - \lbrace 1 \rbrace )$ with $G_i$, with \\
\phantom{Identify} $a \in A$, \, $A \times (S_i - \lbrace 1 \rbrace) \ni (a, s_i)$. \\

$G_i$ act on $G_i \times Y_i$ :  \\
\[
\begin{aligned}
G_i \times (G_i \times Y_i) & \mapsto G_i \times Y_i \\
g' \cdot (g, y) & = (g' g , y)
\end{aligned}
\]

(group $G_i, Y_i \equiv $ set of reduced words) \\

Transfer this to an action of $G_i$ on $X$ by means of $\theta_i$: \\
\[
\begin{aligned}
G_i \times X & \mapsto X \\
g' \cdot (a, s_1, \dots , s_n) & = (g'a, s_1 , \dots s_n) 
\end{aligned}
\]
$X \equiv $ set of reduced words of type $\mathbf{i}$. \\

restriction to $A \Longrightarrow a' \cdot (a; s_1 , \dots s_n ) = (a'a ; s_1, \dots s_n)$, which doesn't depend on $i$.

We've now defined action of $G$ on $X$.

\end{proof}


cf. pp. 13, Sec. 2. Trees, 2.1 Graphs of Serre (1980) \cite{Serr1980}

\begin{definition}[1. of Serre (1980) \cite{Serr1980}]
	\textbf{graph} $\Gamma = (X,Y, Y\to X\times X, Y\to Y)$, where $\begin{aligned} & \quad \\
		& \text{ set } X = \text{ vert } \Gamma \\ 
		& \text{ set } Y = \text{ edge } \Gamma \end{aligned}$  

\[
\begin{aligned}
& Y \to X\times X \\ 
& y\mapsto (o(y), t(y)) \\
& Y\to Y \\
& y\mapsto \overline{y}
\end{aligned}
\]
s.t. $\forall \, y \in Y$, $\overline{ \overline{y}} = y$, $\overline{y} \neq y$, $o(y) = t(\overline{y})$.  

vertex $P \in X$ of $\Gamma$. 

(oriented) edge $y\in Y$, $\overline{y} \equiv $ inverse edge.  

origin of $y := $ vertex $o(y) = t(\overline{y})$.  

terminus of $y:= $ vertex $t(y) = o(\overline{y})$   

extremities of $y:= \lbrace o(y),t(y)\rbrace$  

If 2 vertices \textbf{adjacent}, they're extremities of some edge.  

orientation of graph $\Gamma = Y_+ \subset Y = \text{ edge } \Gamma$ s.t. $Y = Y_+ \coprod \overline{Y}_+$.  It always exists.  

oriented graph defined, up to isomorphism, by giving 2 sets $X,Y_+$ and $Y+ \to X\times X$.  
	
	corresponding set of edges is $Y = Y_+\coprod \overline{Y}_+$ where $\overline{Y}_+ \equiv $ copy of $Y_+$  
\end{definition}

\subsubsection{Realization of a Graph}

cf. Realization of a Graph in Serre (1980) \cite{Serr1980}.  

Let graph $\Gamma$, $X = \text{vert}\Gamma$, $Y = \text{edge}\Gamma$.

topological space $T = X \coprod Y \times [0,1]$, where $X,Y$ provided with discrete topology.  

Let $R$ be finest equivalence relation on $T$ for which 
\begin{equation}
\begin{gathered} \begin{aligned}
	& (y,t) \equiv (\overline{y}, 1-t) \\ 
	& (y,0) \equiv o(y) \\
	& (y,1) \equiv t(y)
\end{aligned} \qquad \, \forall \, y \in Y, \, \forall \, t \in [0,1]
\end{gathered}
\end{equation}

quotient space $\text{real}(\Gamma) = T/R $ is \emph{realization} of graph $\Gamma$.  (realization is a functor which commutes with direct limits).  

Let $n\in \mathbb{Z}^+$.  Consider oriented graph of $n+1$ vertices $0,1,\dots n$,  \\

\begin{definition}
	path (of length $n$) in graph $\Gamma$ is morphism $c$ of $\mathbf{\text{Path}}_n$ into $\Gamma$  
\end{definition}

orientation given by $n$ edges $[i,i+1]$, $0\leq i <n$, $\begin{aligned} & \quad \\
& o([i,i+1]) = i \\
& t([i,i+1]) = i+1 \end{aligned}$  

For $n\geq 1$, \\
$(y_1\dots y_n)$ sequence of edges $y_i = c([i-1,i])$ s.t. 
\[
t(y_i) = o(y_{i+1}), \qquad \, 1 \leq i < n \text{ determine } c
\]
If $P_i = c(i)$,  \\
$c$ is a path from $P_0$ to $P_n$, and $P_0$ and $P_n$ are \emph{extremities of the path $c$}.  

pair of form $(y_i,y_{i+1})=(y_i, \overline{y}_i)$ in path is \textbf{backtracking}.  

path (of length $n-2$), from $P_0$ to $P_n$ given (for $n>2$) by $(y_1\dots y_{i-1}, y_{i+2}\dots y_n)$  

If $\exists \, $ path from $P$ to $Q$ in $\Gamma$, $\exists \, $ one without backtracking (by induction)  

direct limit $\mathbf{\text{Path}}_{\infty} = \varinjlim \mathbf{\text{Path}}_n$ provides notion of infinite path.  \\
$\mathbf{\text{Path}}_{\infty} \ni $ infinite sequence $(y_1,y_2 , \dots)$ of edges s.t. $t(y_i) = o(y_{i+1})$ \, $\forall \, i \geq 1$.  


\begin{definition}[connected graph; Def. 3 of Serre (1980) \cite{Serr1980}]
	graph connected if $\forall \, $ 2 vertices, 2 vertices are extremities of at least 1 path.  
	
	maximal connected subgraphs (under relation of inclusion) are \emph{connected components} of graph.  
\end{definition}

\subsubsection{Circuits}  

Let $n\in \mathbb{Z}^+$, $n\geq 1$.  

Consider \\
set of vertices $\mathbb{Z}/n\mathbb{Z}$, orientation given by $n$ edges $[i,i+1]$, $(i\in \mathbb{Z}/n\mathbb{Z})$ with $\begin{aligned} & \quad \\
 & o([i,i+1]) = i \\
 & t([i,i+1]) = i+1 \end{aligned}$

\begin{definition}[circuit; Def. 4 of Serre (1980) \cite{Serr1980}]
	circuit (length $n$) in graph is subgraph isormorphic to $\mathbf{\text{Circ}}_n$.  
\end{definition}
i.e. subgraph = path $(y_1\dots y_n)$, without backtracking, s.t. $P_i = t(y_i)$, \, $(1\leq i \leq n)$ distinct, s.t. $P_n = o(y_1)$

$n=1$ case: $\mathbf{\text{Circ}}_1$, $\mathbb{Z}/\mathbb{Z} = \lbrace 0 \rbrace$, $1$ edge, $[0,1]$, $0 \in \mathbb{Z}/1\mathbb{Z}$, $\begin{aligned} & \quad \\
	& o([0,1]) = 0 \\
	& t([0,1]) = 1 \end{aligned}$  
	
	Note $\mathbf{\text{Circ}}_1$ has automorphism of order 2, which changes its orientation, i.e. \\
	$\exists \, $ automorphism $\sigma \in \text{Aut}( \mathbf{\text{Circ}}_1) $ s.t. $|\sigma | = 2$, i.e. $\sigma^2=1$.  \\
	loop $:= $ circuit of length $1$; so loop $\in \overline{ \mathbf{\text{Circ}} }_1$.  
	
	path $(y_1)$, $P_1 = t(y_1) = o(y_1)$.  
	
	$n=2$ case: $\mathbf{\text{Circ}}_2$, $\mathbb{Z}/2\mathbb{Z} = \lbrace 0 ,1\rbrace$, 2 edges $[0,1], [1,2]$,  \\
	path $(y_1,y_2)$, $(1\leq i \leq 2)$, $\begin{aligned} & \quad \\
		& P_1 = t(y_1) \\
		& P_2 = t(y_2) = o(y_1) \end{aligned}$  
		
		
	

\subsection{Combinatorial graphs}

Let $(X,S)\equiv $ simplicial complex of dim. $\leq 1$, with \\
$X \equiv $ set \\
$S \equiv $ set of subsets of $X$ with $1$ or $2$ elements, containing all the 1-element subsets.  

associates with it a graph $\Gamma = (X, \lbrace (P,Q) \rbrace)$.  

$X$ is its set of vertices.  

edges $=\lbrace (P,Q)\in X\times X\rbrace$ s.t. $P\neq Q$, $\lbrace P ,Q \rbrace \in S$, with $\overline{(P,Q)} = (Q,P)$
\[
\begin{aligned}
& o(P,Q) = P \\
& t(P,Q) = Q
\end{aligned}
\]

In this graph, 2 edges with same origin and same terminus are equal.  This is equivalent to (see following Def.)

\begin{definition}[combinatorial; Def. 5 of Serre (1980) \cite{Serr1980}]
	graph is combinatorial if it has no circuit of length $\leq 2$
\end{definition}
Conversely, it's easy to see that 

every combinatorial graph $\Gamma$ derived (up to isomorphism) by construction above from simplicial complex $(X,S)$, where \\
$X = \text{vert} \Gamma$ \\
$S=$ set of subset $\lbrace P,Q \rbrace$ of $X$ s.t. $P$ and $Q$ either adjacent or equal. 

\part{Tensors, Tensor networks; Singular Value Decomposition, QR decomposition, Density Matrix Renormalization Group (DMRG), Matrix Product states (MPS)}

\section{Introductions to Tensor Networks}

Jos\'{e} Barbon (IFT-CSIC, Univ. Autonoma de Madrid) gave the \href{Workshop introductory overview}{https://youtu.be/nsxgAOAEgbg} for the workshop "Black Holes, Quantum Information, Entanglement, and all that," (29 May-1 June, 2017, with the organizing committee of Thibault Damour (IHES), Vasily Pestun (IHES), Eliezer Rabinovici (IHES \& Hebrew Univ. of Jerusalem).  

In the talk, 


cf. \href{https://youtu.be/nsxgAOAEgbg?t=43m13s}{43:13}  

\subsection*{The church of the doubled Hilbert space}
 
Any thermal box can be obtained by tracing over a second identical copy, if appropriately entangled into a global pure state.  

\[
\rho_R = \text{Tr}_L \sum_n C_n \Psi_n^L \otimes \Psi_n^R
\]
\[
(C_n)_{\text{thermal}} = \left[ \frac{ e^{-\beta E_n} }{ \sum_m e^{-\beta E_M} } \right]^{1/2}
\]

But!!

If the entanglement basis is taken to be the high-energy band of two "entangled" CFTs ... 
\[
|TFD \rangle \sim \sum_{E_n} e^{-\beta E_n/2} | E_n \rangle_L \otimes | E_n \rangle_R
\]
neglecting the tiny $e^{-S}$ spacings. we can approximate by continuous spectrum of fields in the background of an AdS black hole, to get ... 
 
\[
\int_E e^{-\beta E/2} |E\rangle_L \otimes | E\rangle_R 
\]
The HH state of the bulk fields!  

cf. \href{https://youtu.be/nsxgAOAEgbg?t=46m16s}{46:16}

SLOGAN: EPR $=$ ER
Maldacena-Susskind  

Accumulating a density of entanglement of $S \gg 1$ well-separated Bell pairs within a transversal size of order $(GS)^{1/2}$  seems to generate a geometrical bridge of area $GS$.  



cf. \href{https://youtu.be/nsxgAOAEgbg?t=49m26s}{49:26}  

\subsection*{Parametrizing complexity of entanglement}

Pick a tensor decomposition of Hilbert space of dimension $\exp{(S)}$ into $S$ factors of $O(1)$ dimension.  
\[
\mathcal{H} = \mathcal{H}_1 \otimes \mathcal{H}_2 \otimes \dots \otimes \mathcal{H}_S
\]
A tensor of S indices gives a generic state.  

cf. \href{https://youtu.be/nsxgAOAEgbg?t=50m27s}{50:27}  

The decomposition of the big tensor in small building blocks gives a notion of "complexity of entanglement"  

rather simple entanglement pattern  

somewhat more complex entanglement pattern

picture from M von Raamsdonk  

cf. \href{https://youtu.be/nsxgAOAEgbg?t=55m10s}{55:10}

\subsection*{A list of open questions \& problems}

\begin{itemize}
\item Need exactly calculable toy models of AdS/CFT along the lines of SYK model  
\item Give a "renormalized" definition of quantum complexity for continuum CFTs 
\item Can tensor networks describe bulk gravitons?  
\item What is the space-time meaning of quantum complexity saturation?  
\item Can we define approximate local observables for black hole inferiors?  
\item Are there obstructions related to firewalls and/or fuzzballs?   
\end{itemize}

\href{https://youtu.be/nsxgAOAEgbg}{Workshop introductory overview } by Jos\'{e} Barbon for the \href{https://www.youtube.com/channel/UC4R1IsRVKs_qlWKTm9pT82Q}{Institut des Hautes Études Scientifiques (IHÉS)} gave me the first impetus to understand tensor networks as I sought to also understand the condensates of entanglement pairs within the black hole.  

A Google search for introductions to tensor networks that are on arxiv ("Introduction Tensor Network arxiv") yielded Bridgeman and Chubb's course notes (bf. Bridgeman and Chubb (2017) \cite{BrCh2017}).    

\subsection{List of stuff I want to look at/do/study}  
I would like to compare/contrast the following:  
\begin{itemize}
\item Rotman (2010) \cite{JRotman2010}, Ch. 8, but starting from 8.4 Tensor Products, pp. 574  
\item Jeffrey Lee (2009) \cite{JLee2009}, Ch. 7 Tensors 
\item \url{http://www.irisa.fr/sage/bernard/publis/SVD-Chapter06.pdf}, \url{https://math.stackexchange.com/questions/694339/parallel-algorithms-for-svd}
\end{itemize}



Maldacena and Susskind (2013) \cite{MaSu2013}  

Lectures on Gravity and Entanglement.  Mark Van Raamsdonk  \cite{Raam2016}

\begin{itemize}
\item Consider as physical system AdS-Schwarzchild black hole   
\item CFT 
\begin{itemize}
\item \href{https://arxiv.org/pdf/1601.05000.pdf}{PFL Lectures on Conformal Field Theory in $D\geq 3$ Dimensions}, Rychkov (2016) \cite{Rych2016}.  
\end{itemize}
\end{itemize}

Evenbly and Vidal (2011) \cite{EvVi2011}, Tensor network states and geometry

Loose ends (might not be useful links)
\begin{itemize}
\item \url{https://arxiv.org/pdf/1506.06958.pdf}
\item \url{https://arxiv.org/pdf/1512.02532.pdf} One-point Functions in AdS/dCFT from Matrix Product States
\end{itemize}

Numerical implementation strategy: 1st, CUDA cuSolver, 2nd, Numerical Recepes version, 3rd, parallel algorithm review.


\subsection{Tensor operations; Tensor properties}

\subsubsection{rank}

$r=$ rank tensor of dim. $d_1\times \dots \times d_r$ is element of $\mathbb{C}^{d_1\times \dots \times d_r}$  

Tensor product
\begin{equation}
	[A \otimes B]_{i_1 \dots i_r, j_1 \dots j_s } := A_{i_1 \dots i_r} \cdot B_{j_1 \dots j_s }
\end{equation}

\subsubsection{Trace}
Given tensor $A$, $x$th, $y$th indices have identical dims. ($d_x = d_y$), \\
partial trace over these 2 dims. is simply joint summation over that index
\begin{equation}
	[\text{Tr}_{x,y} A]_{i_1\dots i_{x-1}i_{x+1} \dots i_{y-1}i_{y+1} \dots i_r} = \sum_{\alpha=1}^{d_x} A_{i_1 \dots i_{x-1} \alpha i_{x+1} \dots i_{y-1} \alpha i_{y+1} \dots i_r}
\end{equation}

\subsubsection{Contraction}

\subsubsection{Group and splitting, Bridgeman and Chubb (2017) \cite{BrCh2017} }

"Rank is a rather fluid concept in the study of tensor networks."  Bridgeman and Chubb (2017) \cite{BrCh2017}.  

$\mathbb{C}^{a_1 \times \dots \times a_n} \simeq \mathbb{C}^{b_1 \times \dots \times b_m}$ isomorphic as vector spaces if $\prod_i a_i = \prod_i b_i$.  

We can "group" or "split" indices to lower or raise rank of given tensor, resp.  

Consider contracting 2 arbitrary tensors.  

If we group together indices which are and are not involved in contraction, \\
"It should be noted that not only is this reduction to matrix multiplication pedagogically handy, but this is precisely the manner in which numerical tensor packages perform contraction, allowing them to leverage highly optimised matrix multiplication code." (cf. Bridgeman and Chubb (2017) \cite{BrCh2017}; check this)

"Owing to freedom in choice of basis, precise details of grouping and splitting aren't unique." (cf. Bridgeman and Chubb (2017) \cite{BrCh2017}).  

1 specific choice of convention:  \\
tensor product basis, defining basis on product space by product of respective bases.  

"The canonical use of tensor product bases in quantum information allows for grouping and splitting described above to be - dealt with implicitly."  


\begin{equation}
 | 0 \rangle \otimes | 1 \rangle \equiv | 0 \rangle 
\end{equation} and precisely this grouping, 
\begin{equation}
\begin{gathered}
	| 0 \rangle \otimes | 1 \rangle \in \text{Mat}_{\mathbb{C}}(2,2), \text{ whilst } \\ 
 | 0 1 \rangle \in \mathbb{C}^4  
\end{gathered}
\end{equation}

Suppose rank $n+m$ tensor $T$, group its first $n$ indices, last $m$ indices together.
\[
T_{I,J} := T_{i_1\dots i_n,j_1\dots j_m}
\]
where 
\[
\begin{aligned}
	& I := i_1 + d_1^{(i)} i_2 + d_1^{(i)}  d_2^{(i)} i_3 + \dots + d_1^{(i)} \dots d_{n-1}^{(i)} i_n \\ 
	& J := j_1 + d_1^{(j)} j_2 + d_1^{(j)}  d_2^{(j)} j_3 + \dots + d_1^{(j)} \dots d_{m-1}^{j)} j_m 
\end{aligned}
\]

EY : 20170627 to elaborate, consider a functor \verb|flatten| that does what's described above, in the context of category theory (and so this is the generalization):

\begin{equation}
\begin{gathered}
	\mathbb{K}^{d_1^{(i)} } \times \mathbb{K}^{d_2^{(i)} } \times \dots \times \mathbb{K}^{d_n^{(i)} } \times \mathbb{K}^{d_1^{(j)} } \times \mathbb{K}^{d_2^{(j)} } \times \dots \times \mathbb{K}^{d_m^{(j)} } \xrightarrow{ \text{ flatten } } \mathbb{K}^{ \prod_{p=1}^n d_p^{(i)} } \times \mathbb{K}^{ \prod_{q=1}^m d_q^{(j)} }   \\
T_{i_1 \dots i_n, j_1 \dots j_m } \xmapsto{ \text{ flatten } } T_{I,J}   \\
\lbrace 0 ,1, \dots d_1^{(i)} \rbrace \times \lbrace 0 ,1, \dots d_2^{(i)} \rbrace \times \dots \times \lbrace 0 ,1, \dots d_n^{(i)} \rbrace \times \lbrace 0 ,1, \dots d_1^{(j)} \rbrace \times \lbrace 0 ,1, \dots d_2^{(j)} \rbrace \times \dots \times \lbrace 0 ,1, \dots d_m^{(j)} \rbrace \xrightarrow{ \text{ flatten } } \\
\xrightarrow{ \text{ flatten } }  \lbrace 0 ,1, \dots  \prod_{p=1}^n d_p^{(i)} -1 \rbrace \times \lbrace 0 ,1, \dots \prod_{q=1}^m d_q^{(j)} - 1 \rbrace  \\
(i_1,i_2, \dots i_n, j_1,j_2 \dots j_m ) \xmapsto{ \text{ flatten } } (I,J) := (i_1 + d_1^{(i)} i_2 + \dots + d_1^{(i)} \dots d_{n-1}^{(i)} i_n ,j_1 + d_1^{(j)} j_2 + \dots + d_1^{(j)} \dots d_{m-1}^{(j)} j_m ) \\ 
\end{gathered}
\end{equation}
It doesn't make sense to call this "row-major" or "column-major" ordering generalization, because we are not dealing with only 2 indices where we can definitely say the first index indexes the "row" and the second index indexes the "column."  At most, possibly, you can alternatively have this:
\[
(i_1 \dots i_n,j_1\dots j_m) \xmapsto{ \text{ flatten } } (I,J) := (d_2^{(i)} \dots d_n^{(i)}i_1 + d_3^{(i)} \dots d_n^{(i)} i_2 + \dots + i_n , d_2^{(j)} \dots d_m^{(j)} j_1 + \dots + j_m )
\]
Note that this is all \emph{$0$-based counting} (i.e. we start counting from $0$ just like in C,C++,Python, etc.).  If you really wanted $1$-based counting, you'd have to complicate the above formulas as such:
\[
\begin{gathered}
(I,J) := (i_1 + d_1^{(i)} (i_2-1) + \dots + d_1^{(i)} \dots d_{n-1}^{(i)} (i_n-1) ,j_1 + d_1^{(j)} (j_2-1) + \dots + d_1^{(j)} \dots d_{m-1}^{(j)} (j_m-1) ) \\ 
\end{gathered}
\]
Note that formulas are easily checked by pluggin in the minimum and maximum values for the indices and seeing if they make sense (e.g. plug in $(0,0,\dots ,0)$ for all indices for $0$-based counting and make sure you get back $I=0$ or $J=0$).  

\subsection{Singular Value Decomposition}  

\begin{equation}
\begin{gathered}
	T_{I,J} = \sum_{\alpha} U_{I,\alpha} S_{\alpha,\alpha} \overline{V}_{J,\alpha} \\ 
 \text{Mat}_{\mathbb{K}}(N,M) \xrightarrow{ \text{ SVD } } \text{Mat}_{\mathbb{K}}(N,P) \times \text{Mat}_{\mathbb{K}}(P,P) \times \text{Mat}_{\mathbb{K}}(M,P)    \\
	T_{I,J} \xmapsto{ \text{ SVD } } U_{I,\alpha}, S_{\alpha,\alpha} , \overline{V}_{I,\alpha} \text{ s.t. } \\
T_{I,J} = \sum_{\alpha} U_{I,\alpha} S_{\alpha, \alpha} \overline{V}_{J,\alpha}    \\
T=USV^{\dag}
\end{gathered}
\end{equation}
For the higher-dimensional version of SVD, 
\begin{equation}
\begin{gathered}
	\mathbb{K}^{d_1^{(i)} } \otimes \dots \otimes \mathbb{K}^{d^{(i)}_N} \otimes \mathbb{K}^{d_1^{(j)} }\otimes \dots \otimes \mathbb{K}^{d_M^{(j)} }  \xrightarrow{ \text{ flatten } } \text{Mat}_{\mathbb{K}}(N,M) \xrightarrow{ \text{ SVD } }     \text{Mat}_{\mathbb{K}}(N,P) \times \text{Mat}_{\mathbb{K}}(P,P) \times \text{Mat}_{\mathbb{K}}(M,P) \xrightarrow{ \text{ splitting } } \\ 
\xrightarrow{ \text{ splitting } } \mathbb{K}^{d_1^{(i)} } \otimes \dots \otimes \mathbb{K}^{d^{(i)}_N} \otimes \mathbb{K}^P \times \text{Mat}_{\mathbb{K}}(P,P) \times  \mathbb{K}^{d_1^{(j)} }\otimes \dots \otimes \mathbb{K}^{d_M^{(j)} } \otimes \mathbb{K}^P  \\
T_{i_1\dots i_N,j_1 \dots j_M} = \sum_{\alpha} U_{i_1\dots i_N,\alpha} S_{\alpha,\alpha} \overline{V}_{j_1 \dots j_M, \alpha}
\end{gathered}
\end{equation}

\section{Density Matrix Renormalization Group; Matrix Product States (MPS)}

\subsection{Introduction; physical system (physical setup)}

cf. "Density Matrix Renormalization Group/Matrix Product States" lectures by Schollw\"{o}ck (2017) \cite{ArSo2017}.

Recall the fundamental Hamiltonian (frequently in solid state physics), for \emph{electrons moving in a Hamiltonian potential}. 
\begin{equation}
H = \sum_{j=1}^{ e^-} \frac{\mathbf{p}_j^2}{ 2m_e} + \frac{1}{2} \frac{1}{ 4\pi \epsilon_0} \frac{q_e^2}{ |\mathbf{r}_i - \mathbf{r}_j|^2 } + \sum_{j=1}^{e^-} V_{\text{eff}}(\mathbf{r}_j)
\end{equation}
where $\frac{\mathbf{p}_j^2}{ 2m_e}$ is the kinetic energy term, $\sum_{j=1}^{e^-} V_{\text{eff}}(\mathbf{r}_j)$ is the lattice potential.
The problem is in the 2nd. term, electron-electron interaction, $\frac{1}{2} \frac{1}{ 4\pi \epsilon_0} \frac{q_e^2}{ |\mathbf{r}_i - \mathbf{r}_j|^2 }$

Typical models include the following:

\begin{itemize}
	\item Hubbard model (tight, binding-like model; basis states are not energy states but \emph{Wannier basis} states):
	\begin{equation}
	H = -t \sum_{ \langle i, j \rangle, \sigma } c^{\dag}_{i \sigma} c_{j \sigma} + h.c. + U \sum_i n_{i \uparrow} n_{i \downarrow }
	\end{equation}
	where $\langle i, j \rangle$ denotes nearest neighbors, $\sigma$ index is for all possible states, $h.c.$ stands for hermitian conjugate, and \\
	$d \equiv$ number of states of single spin site. \\
	$-t \sum_{ \langle i, j \rangle, \sigma } c^{\dag}_{i \sigma} c_{j \sigma} + h.c.$ is the kinetic energy term, \\
	$U \sum_i n_{i \uparrow} n_{i \downarrow }$ is the Coulomb energy.
	
	Hilbert space for the Hubbard model is 
	\begin{equation}
	\lbrace | \emptyset \rangle , | \uparrow \rangle , | \downarrow \rangle , | \uparrow \downarrow \rangle \rbrace^{ \otimes L}, \qquad \, d = 4
	\end{equation}
	\item Heisenberg model (large -$U$ Hubbard at half-filling)
	\begin{equation}
	H = J \sum_{ \langle i , j \rangle } \mathbf{S}_i \cdot \mathbf{S}_j = J \sum_{ \langle i, j \rangle } \frac{1}{2} (S_i^{+} S_j^- + S_j^{+} S_i^-) + S_i^z S_j^z  )
	\end{equation}
	Hilbert space $\lbrace | \uparrow \rangle, | \downarrow \rangle \rbrace^{\otimes L}$, $d=2$ 
\end{itemize}

\subsubsection{Compression of information viewpoint for solid-state Hamiltonians, quantum many-body systems}.

"emergent" macroscopic quantities, $\tau, p$ (temperature, pressure). For 
\[
	H = J \sum_{ \langle i , j \rangle } \mathbf{S}_i \cdot \mathbf{S}_j = J \sum_{ \langle i, j \rangle } \frac{1}{2} (S_i^{+} S_j^- + S_j^{+} S_i^-) + S_i^z S_j^z  )
\]

$H$ as classical spins: thermodynamic limit $N \to \infty$. 2 angles required to describe unit vector on unit sphere ($S^3$) $\Longrightarrow 2N $ degrees of freedom (linear)

quantum spins: superposition of states, thermodynamic limit: $N \to \infty$, $2^N$ degrees of freedom (exponential).

\subsubsection{Definitions; notation and conventions}

Quantum system living on $L$ lattice sites; cf. Schollw\"{o}ck (2017) \cite{ArSo2017}, lattice can be in any dim., effectively most useful in 1-dim., think of the example of a 1-dim. chain of $L$ sites. \\

$d$ local states per site $\lbrace \sigma_i \rangle$, $i \in \lbrace 1,2, \dots L\rbrace$

e.g. spin $\frac{1}{2}$, $d=2$, $| \uparrow \rangle, | \downarrow \rangle$.

Hilbert space: $\mathcal{H} = \otimes_{i=1}^L \mathcal{H}_i$, $\mathcal{H}_i = \lbrace | 1_i \rangle , \dots | d_i \rangle \rbrace$. 

Notice, there are \emph{exponentially many coefficients}, $c$'s. Most general state (not necessarily 1-dim.) is 
\begin{equation}
|\psi \rangle = \sum_{\sigma_1 \dots \sigma_L} c^{\sigma_1 \dots \sigma_L} | \sigma_1 \dots \sigma_L \rangle
\end{equation}

abbreviations: $\lbrace \sigma \rbrace = \sigma_1 \dots \sigma_L$. And so we can write $c^{\lbrace \sigma \rbrace}$. 

\subsection{MPS, matrix product states}

\begin{equation}
| \psi \rangle = \sum_{\sigma_1 \dots \sigma_L} M^{\sigma_1} M^{\sigma_2} \dots M^{\sigma_L} | \sigma_1 \sigma_2 \dots \sigma_L \rangle
\end{equation}

The $\sum_{\sigma_1 \dots \sigma_L}$ means that all basis states participate; Schollw\"{o}ck is not kicking out any states arbitrarily. 
\[
c^{\lbrace \sigma \rbrace} = M^{\sigma_1} M^{\sigma_2} \dots M^{\sigma_L} \in \mathbb{C}
\] so

$M^{\sigma_1} \in \text{Mat}_{\mathbb{C}}(1, n_1)$ so to get a scalar in the product of matrices. Likewise, $M^{\sigma_L} \in \text{Mat}_{\mathbb{C}}(m_L, 1)$

(variational) constraint is in expansion coefficients. 

$\forall \, $ $d$ local basis states, $|\sigma_i \rangle \in V_i \equiv V$,$\text{dim}V = d$, let there be 1 matrix $M$, i.e. $M^{\sigma_i}$.  \\
Thus, $dL$ matrices altogether (in total).

Assume matrix size has upper limit $D$ (a computer limitation).

Up to $dLD^2$ coefficients, instead of exponentially many ($c^{\lbrace \sigma \rbrace}$, and sum over $\lbrace \sigma \rbrace$). 

\subsubsection{Product States and MPS}

Mean-filed approximation/product state misses essential quantum feature: \textbf{entanglement}. 

Consider 2 spin $\frac{1}{2}$ systems: $\mathcal{H} = \mathcal{H}_1 \otimes \mathcal{H}_2$, $\mathcal{H}_i = \lbrace | \uparrow \rangle, | \downarrow \rangle \rbrace$

General state is 
\[
| \psi \rangle = c^{ \uparrow \uparrow} | \uparrow \uparrow \rangle + c^{ \uparrow \downarrow} | \uparrow \downarrow \rangle + c^{ \downarrow \uparrow} | \downarrow \uparrow \rangle + c^{ \downarrow \downarrow} | \downarrow \downarrow \rangle 
\]

e.g. singlet state: $|\psi \rangle = \frac{1}{ \sqrt{2} } | \uparrow \downarrow \rangle - \frac{1}{ \sqrt{2} } | \downarrow \uparrow \rangle $. 

As an exercise, show that the singlet state cannot be written as product of local coefficients, i.e. 
\[
c_{\uparrow \downarrow } \neq c^{\uparrow} c^{ \downarrow }
\]

Instead of writing products of scalars, write product of matrices, i.e. $e^{\sigma_1} \cdot e^{\sigma_2} \to M^{\sigma_1} M^{\sigma_2}$

\[
\begin{gathered}
\begin{aligned}
	& M^{\uparrow 1} = \left[ \begin{matrix} 1 & 0 \end{matrix} \right]
	& M^{\downarrow 1} = \left[ \begin{matrix} 0 & 1 \end{matrix} \right] 
	\end{aligned} \quad \quad \, \begin{aligned}
	& M^{\uparrow 2 } = \left[ \begin{matrix} 0 \\ \frac{-1}{\sqrt{2}} \end{matrix} \right] \\
	& M^{\downarrow 2} = \left[ \begin{matrix} \frac{1}{\sqrt{2}} \\ 0 \end{matrix} \right] 
	\end{aligned}
\end{gathered}
\]

\[
\begin{gathered}
M^{\uparrow 1} M^{\downarrow 2} = \frac{1}{\sqrt{2}} \\ 
M^{\downarrow 1} M^{\uparrow 2} = \frac{-1}{\sqrt{2}} 
\end{gathered}
\]

\subsubsection{AKLT model (Affleck-Kennedy-Lieb-Tasaki)}

MPS is useful even for matrices of dim. 2.


\subsection{General matrix product state (MPS) and SVD (Singular Value Decomposition)}

cf. Schollw\"{o}ck (2017) \cite{ArSo2017}

The general matrix product state (MPS) is the following:
\begin{equation}
|\psi \rangle = \sum_{ \sigma_1 \dots \sigma_L } M^{\sigma_1} M^{\sigma_2} \dots M^{\sigma_L} | \sigma_1 \sigma_2 \dots \sigma_L \rangle
\end{equation}
where $\sigma_i \in V_i$, $\text{dim}V_i = d_i$ and \\
$M^{\sigma_1} \in \text{Mat}_{\mathbb{C}}(1, D_1)$ \\ 
$M^{\sigma_2} \in \text{Mat}_{\mathbb{C}}(D_1, D_2)$ \\ 
$\vdots$ \\ 
$M^{\sigma_{L-1}} \in \text{Mat}_{\mathbb{C}}(D_{L-2}, D_{L-1})$ \\ 
$M^{\sigma_L} \in \text{Mat}_{\mathbb{C}}(D_{L-1}, 1)$ \\ 

Notice the non-unique \textbf{gauge degree of freedom}:

$\forall \, A \in \text{Mat}_{\mathbb{C}}(m,n)$, then for $k = \min{(m,n)}$, 
\begin{equation}
\begin{gathered}
A = U SV^{\dagger} \equiv U \Sigma V^{\dagger} \text{ where }
\end{gathered}
\end{equation}

$U \in \text{Mat}_{\mathbb{C}}(m,k)$, $U^{\dagger} U =1$ (i.e. $U$ consists of orthonormal columns, or $k$ number of $u$'s $\in \mathbb{C}^m$); if $m=k$, $UU^{\dagger} = 1$, \\
$S \in \text{Mat}_{\mathbb{C}}(k,k)$ s.t. $S \in \text{diag}_{\mathbb{C}}(k)$, $s_1 \geq s_2 \geq s_3 \geq \dots s_i \geq 0$, $s_j$'s non-negative "singular values" (adjacent "singular" in name doesn't imply anything), non-vanishing = $\text{rank} r \leq k$. \\
$V^{\dagger} \in \text{Mat}_{\mathbb{C}}(k,n)$, $V^{\dagger} V = 1$, (orthonormal rows, or $k$ number of $v\in \mathbb{C}^n$); if $k=n $, $VV^{\dagger} = 1$

Recall eigenvalue equation and thus so-called eigenvalue decomposition.

For $A \in \text{Mat}_{\mathbb{C}}(m,m)$, 
\[
\begin{gathered}
	Au_j = \lambda_j u_j ; \qquad \, j =1 \dots r ; \, r \equiv \text{ rank }, \quad \, u_j \in \text{Mat}_{\mathbb{C}}(m, 1) \\
	A_{ik} u_{kj} = \lambda_j u_{ij} = u_{ik} \delta_{kj} \lambda_j \Longrightarrow AU = U \Lambda
\end{gathered}
\]
with $U \in \text{Mat}_{\mathbb{C}}(m, r)$, $\Lambda \in \text{Mat}_{\mathbb{C}}(r, r)$.

And so
\[
\begin{gathered}
\begin{aligned}
& AA^{\dagger} = USV^{\dagger} VSU^{\dagger} = US^2 U^{\dagger} \Longrightarrow (AA^{\dagger})U = US^2 \\ 
& A^{\dagger} A = VSU^{\dagger} U SV^{\dagger} = VS^2 V^{\dagger} \Longrightarrow (A^{\dagger}A)V = VS^2
\end{aligned}
\end{gathered}
\]
so if we treat $U$ and $V$, matrices of left, right singular vectors, then $S^2$ singular value squared are eigenvalues.

Start with 

\begin{equation}
| \psi \rangle = \sum_{\sigma_1 \dots \sigma_L} c^{\sigma_1 \dots \sigma_L} | \sigma_1 \dots \sigma_L \rangle \in V \text{ s.t. } \text{dim} V = d^L
\end{equation}

Note the \emph{abuse of notation}: while $c^{\sigma_1 \dots \sigma_L} \in \mathbb{C}$ itself, also denote $c^{\sigma_1 \dots \sigma_L} \in \mathbb{C}^{d^L}$ as a shorthand for $\sum_{\sigma_1 \dots \sigma_L} c^{\sigma_1 \dots \sigma_L} | \sigma_1 \dots \sigma_L \rangle$

Reshape coefficient vector into matrix of (size) dimension ($d\times d^{L-1}$). 
\[
\begin{gathered}
\mathbb{C}^{d^L} \xrightarrow{\text{reshape}} \text{Mat}_{\mathbb{C}}(d, d^{L-1}) \\
c^{\sigma_1 \dots \sigma_L} \xmapsto{\text{reshape}} \Psi_{\sigma_1, (\sigma_2 \dots \sigma_L)} 
\end{gathered}
\]

Then do SVD:
\[
\Psi_{\sigma_1, (\sigma_2 \dots \sigma_L)}  \stackrel{ \text{SVD} }{=} \sum_{a_1} U_{\sigma_1 a_1} S_{a_1 a_1} V^{\dagger}_{a_1, \sigma_2 \dots L} = U_{\sigma_1 a_1} S_{a_1 a_1 } V^{\dagger}_{a_1, \sigma_2 \dots \sigma_L}
\]


Let's utilize commutative diagrams to summarize the reshaping and SVD operations that we've done.

\[
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=1.55em, column sep=4.7em, minimum width=3.2em]
{
	\mathbb{C}^{d^L} = \text{Mat}_{\mathbb{C}}(1, d^L) & \text{Mat}_{\mathbb{C}}(d, d^{L-1}) & \text{Mat}_{\mathbb{C}}(d, r_1) \times \text{Mat}_{\mathbb{C}}(r_1, r_1) \times \text{Mat}_{\mathbb{C}}(r_1 , d^{L-1}) \\
	\left| \Psi \right. \rangle \equiv c^{\sigma_1 \dots \sigma_L} & \Psi_{\sigma_1, (\sigma_2 \dots \sigma_L) } & \Psi_{\sigma_1, (\sigma_2 \dots \sigma_L) } \stackrel{\text{SVD}}{=} U_{\sigma_1 a_1 } S_{a_1 a_1} V^{\dagger}_{a_1, \sigma_2 \dots \sigma_L} \\
};
\path[->]
(m-1-1) edge node [above] { \text{reshape} } (m-1-2)
(m-1-2) edge node [above] { \text{SVD} } (m-1-3)
;
\path[|->]
(m-2-1) edge node [above] { \text{reshape} } (m-2-2)
(m-2-2) edge node [above] { \text{SVD} } (m-2-3)
;
\end{tikzpicture}  
\]
where I abuse notation for the SVD operation in that, SVD maps a matrix (in this case, $\Psi$) into 3 matrices, that obey the equality relationship when they're multiplied together (i.e. $\Psi = USV^{\dagger}$). 


Slice $U$ into $d$ row vectors, i.e. for $U \in \text{Mat}_{\mathbb{C}}(d,r_1)$.
\[
\begin{gathered}
\begin{aligned}
\text{Mat}_{\mathbb{C}}(d, r_1) & \xrightarrow{\text{slice}} \text{Mat}_{\mathbb{C}}(1, r_1)^d \\
U_{\sigma_1 a_1} & \mapsto \lbrace A^{\sigma_1} \rbrace \equiv \lbrace A^{\sigma_1}_{1, a_1} \rbrace_{\sigma_1} \text{ s.t. } A^{\sigma_1}_{1,a_1} = U_{\sigma_1 a_1} \text{ and } | \lbrace A^{\sigma_1}_{1, a_1} \rbrace | = d
\end{aligned}
\end{gathered}
\]

Collecting all the operations, and doing the following notation rewrite,
\[
\begin{gathered}
c^{\sigma_1 \sigma_2 \dots \sigma_L} \mapsto \Psi_{\sigma_1 \sigma_2 \dots \sigma_L} = \sum_{a_1} A^{\sigma_1}_{1 a_1} S_{a_1 a_1} V^{\dagger}_{a_1, \sigma_2 \dots \sigma_L} = \sum_{a_1} A^{\sigma_1}_{1a_1} c^{a_1 \sigma_2 \sigma_3 \dots \sigma_L}
\end{gathered}
\]
where
\[
c^{a_1 \sigma_2 \sigma_3 \dots \sigma_L} = S_{a_1 a_1} V^{\dagger}_{a_1 \sigma_2 \dots \sigma_L}
\]

Do the same procedure again. 

\[
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=1.55em, column sep=4.7em, minimum width=3.2em]
{
	\text{Mat}_{\mathbb{C}}(r_1, d^{L-1}) & \text{Mat}_{\mathbb{C}}(r_1d, d^{L-2}) & \text{Mat}_{\mathbb{C}}(r_1d, r_2) \times \text{Mat}_{\mathbb{C}}(r_2, r_2) \times \text{Mat}_{\mathbb{C}}(r_2 , d^{L-2}) \\
	c^{a_1, \sigma_2 \sigma_3 \dots \sigma_L} & \Psi_{a_1\sigma_2, (\sigma_3 \dots \sigma_L) } & \Psi_{a_1 \sigma_2, (\sigma_3 \dots \sigma_L) } \stackrel{\text{SVD}}{=} U_{a_1 \sigma_2, a_2 } S_{a_2 a_2} V^{\dagger}_{a_2, \sigma_3 \dots \sigma_L} \\
};
\path[->]
(m-1-1) edge node [above] { \text{reshape} } (m-1-2)
(m-1-2) edge node [above] { \text{SVD} } (m-1-3)
;
\path[|->]
(m-2-1) edge node [above] { \text{reshape} } (m-2-2)
(m-2-2) edge node [above] { = } (m-2-3)
;
\end{tikzpicture}  
\]

Then slice $U$ into $d$ matrices, and then matrix multiply the $S$ and $V^{\dagger}$ matrices together:
\[
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=1.55em, column sep=4.7em, minimum width=3.2em]
{
	\text{Mat}_{\mathbb{C}}(r_1d, r_2) \times \text{Mat}_{\mathbb{C}}(r_2, r_2) \times \text{Mat}_{\mathbb{C}}(r_2 , d^{L-2}) & \text{Mat}_{\mathbb{C}}(r_1, r_2)^d \times \text{Mat}_{\mathbb{C}}(r_2, d^{L-2}) \\
	\sum_{a_2} U_{a_1 \sigma_2, a_2 } S_{a_2 a_2} V^{\dagger}_{a_2, \sigma_3 \dots \sigma_L} & = \sum_{a_2} A^{\sigma_2}_{a_1 a_2} c^{a_2, a_3 \dots \sigma_L} \text{ where } A^{\sigma_2}_{a_1 a_2} = U_{a_1\sigma_2, \sigma_3 \dots \sigma_L } \\
};
\path[->]
(m-1-1) edge node [above] { \text{slice and multiply} } (m-1-2)
;
\path[|->]
(m-2-1) edge node [above] { = } (m-2-2)
;
\end{tikzpicture}  
\]

\end{multicols*}
%\begin{multicols*}{1}


Thus, generalize the \emph{$i$th procedure}: for $i = 1 \dots L$, 

Let $r_0 = 1$.

\begin{equation}\label{Eq:LeftMPSoperation}
\begin{tikzpicture}[framed]
\matrix (m) [matrix of math nodes, row sep=2.55em, column sep=7.7em, minimum width=6.2em]
{
	\text{Mat}_{\mathbb{C}}(r_{i-1}, d^{L-(i-1)}) & \text{Mat}_{\mathbb{C}}(r_{i-1}d, d^{L-i}) & \text{Mat}_{\mathbb{C}}(r_{i-1}d, r_i) \times \text{Mat}_{\mathbb{C}}(r_i, r_i) \times \text{Mat}_{\mathbb{C}}(r_i , d^{L-i}) & \text{Mat}_{\mathbb{C}}(r_{i-1}, r_i)^d \times \text{Mat}_{\mathbb{C}}(r_i, d^{L-i}) \\
	c^{a_{i-1}, \sigma_i \sigma_{i+1} \dots \sigma_L} & \Psi_{a_{i-1}\sigma_i, (\sigma_{i+1} \sigma_{i+2} \dots \sigma_L) } &  U_{a_{i-1} \sigma_i, a_i } S_{a_i a_i} V^{\dagger}_{a_i, \sigma_{i+1} \dots \sigma_L} & A^{\sigma_i}_{a_{i-1}, a_i} c^{a_i, \sigma_{i+1} \dots \sigma_L} \\
};
\path[->]
(m-1-1) edge node [above] { \text{reshape} } (m-1-2)
(m-1-2) edge node [above] { \text{SVD} } (m-1-3)
(m-1-3) edge node [above] { \text{slice and multiply} } (m-1-4)
;
\path[|->]
(m-2-1) edge node [above] { \text{reshape} } (m-2-2)
(m-2-2) edge node [above] { = } (m-2-3)
(m-2-3) edge node [above] { = } (m-2-4)
;
\end{tikzpicture}  
\end{equation}

Remember that $r_i \leq \min{(r_{i-1} d, d^{L-i})} $ and for $i=L$, there is no need to do a SVD, but only a reshape, and slice and multiply.

Collecting all the $A$ matrices:

\begin{equation}
\boxed{
	\begin{gathered}
\begin{aligned}
& A^{\sigma_1}_{1, a_1} \in \text{Mat}_{\mathbb{C}}(1,r_1); \qquad \, r_1 \leq d \\
& A^{\sigma_2}_{a_1, a_2} \in \text{Mat}_{\mathbb{C}}(r_1,r_2); \qquad \, r_2 \leq r_1 d \\
& \vdots \\
& A^{\sigma_i}_{a_{i-1}, a_i} \in \text{Mat}_{\mathbb{C}}(r_{i-1},r_i); \qquad \, r_i \leq \min{(r_{i-1}d, d^{L-i})} \\
& \vdots \\
& A^{\sigma_L}_{a_{L-1}, a_L} \in \text{Mat}_{\mathbb{C}}(r_{L-1}, 1); \qquad \, r_{L-1} \leq d
\end{aligned}
	\end{gathered}}
\end{equation}

\begin{multicols*}{2}

\subsubsection{Left and Right Normalization, $A$ and $B$ matrices, "special gauge" from normalization}

Choose orthonormal basis states $\forall \, a_l, \, \forall \, l = 1, 2, \dots L$
For
\[
\begin{aligned}
& | a_l \rangle = \sum_{ a_{l-1} \sigma_l } M^{\sigma_l}_{a_{l-1}a_l } | a_{l-1} \sigma_l \rangle \\
& \langle a_l' | = \sum_{a'_{l-1} \sigma_l'} \langle a'_{l-1} \sigma'_l | (M^{\sigma_l'}_{a'_{l-1} a'_l})^*
\end{aligned}
\]
then,
\begin{equation}
\begin{gathered}
\delta_{a'_l a_l} = \langle a'_l | a_l \rangle = \sum_{a'_{l-1}\sigma_l', a_{l-1}\sigma_l } M^{\sigma_l' *}_{a'_{l-1} a'_l} M^{\sigma_l}_{a_{l-1} a_l} \langle a'_{l-1} \sigma'_l | a_{l-1} \sigma_l \rangle = \sum_{a_{l-1} \sigma_l } M^{\sigma_l *}_{a_{l-1} a'_l} M^{\sigma_l}_{a_{l-1} a_l} = \\
= \sum_{\sigma_l} ( (M^{\sigma_l})^{\dag} M^{\sigma_l})_{a_l' a_l}
\end{gathered}
\end{equation}

\textbf{Left normalization} comes from a property of SVD in that $\forall \, U$ matrices, $U^{\dagger} U =1$, and so 
\begin{equation}
\begin{gathered}
(U^{\dagger})_{a'_i k_i} U_{k_i a_i} =  \delta_{a'_i a_i} = U^*_{ k_i a_i'} U_{k_i a_i} = U^*_{a'_{i-1} \sigma_i, a_i'} U_{a''_{i-1}\sigma_i, a_i} = \\ 
= A^{\sigma_i *}_{a''_{i-1}, a_i'} A^{\sigma_i}_{a''_{i-1}, a_i} = (A^{\sigma_i})^{\dagger} A^{\sigma_i} = \boxed{ \sum_{\sigma_i} (A^{\sigma_i})^{\dagger} A^{\sigma_i} = 1 }
\end{gathered}
\end{equation}

For right normalization, consider doing the operations of Eq. \ref{Eq:LeftMPSoperation} "on the right":


\end{multicols*}
%\begin{multicols*}{1}


\[
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=2.55em, column sep=7.7em, minimum width=6.2em]
{
	\text{Mat}_{\mathbb{C}}( d^{L}, 1 ) & \text{Mat}_{\mathbb{C}}(d^{L-1}, d ) & \text{Mat}_{\mathbb{C}}(d^{L-1},r_1 ) \times \text{Mat}_{\mathbb{C}}(r_1, r_1) \times \text{Mat}_{\mathbb{C}}(r_1 , d) & \text{Mat}_{\mathbb{C}}(d^{L-1}, r_1) \times \text{Mat}_{\mathbb{C}}(r_1, 1)^d \\
	c^{\sigma_1 \sigma_{2} \dots \sigma_L} & \Psi_{\sigma_1 \dots  \sigma_{L-1}, \sigma_L } &  U_{ \sigma_1 \dots \sigma_{L-1} a_1 } S_{a_1 a_1} V^{\dagger}_{a_1, \sigma_{L} } & \sum_{\sigma_L} c^{\sigma_{1} \dots \sigma_{L-1}, a_1 } B^{\sigma_L}_{a_{1}, 1}\\
};
\path[->]
(m-1-1) edge node [above] { \text{reshape} } (m-1-2)
(m-1-2) edge node [above] { \text{SVD} } (m-1-3)
(m-1-3) edge node [above] { \text{slice and multiply} } (m-1-4)
;
\path[|->]
(m-2-1) edge node [above] { \text{reshape} } (m-2-2)
(m-2-2) edge node [above] { = } (m-2-3)
(m-2-3) edge node [above] { = } (m-2-4)
;
\end{tikzpicture}  
\]


\[
\begin{gathered}
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=2.55em, column sep=7.7em, minimum width=6.2em]
{
	\text{Mat}_{\mathbb{C}}( d^{L-1}, r_1 ) & \text{Mat}_{\mathbb{C}}(d^{L-2}, r_1d ) & \text{Mat}_{\mathbb{C}}(d^{L-2},r_2 ) \times \text{Mat}_{\mathbb{C}}(r_2, r_2) \times \text{Mat}_{\mathbb{C}}(r_2 , r_1d) & \text{Mat}_{\mathbb{C}}(d^{L-2}, r_2) \times \text{Mat}_{\mathbb{C}}(r_2, r_1)^d \\
	c^{\sigma_1  \dots \sigma_{L-1} a_1} & \Psi_{\sigma_1 \dots \sigma_{L-2}, \sigma_{L-1} a_1 } &  U_{ \sigma_1 \dots \sigma_{L-2}, a_2 } S_{a_2 a_2} V^{\dagger}_{a_2, \sigma_{L-1} a_1 } & \sum_{\sigma_{L-1}} c^{\sigma_{1} \dots \sigma_{L-2}, a_2 } B^{\sigma_{L-1}}_{a_{2}, a_1} \\
};
\path[->]
(m-1-1) edge node [above] { \text{reshape} } (m-1-2)
(m-1-2) edge node [above] { \text{SVD} } (m-1-3)
(m-1-3) edge node [above] { \text{slice and multiply} } (m-1-4)
;
\path[|->]
(m-2-1) edge node [above] { \text{reshape} } (m-2-2)
(m-2-2) edge node [above] { = } (m-2-3)
(m-2-3) edge node [above] { = } (m-2-4)
;
\end{tikzpicture}   \\
\vdots
\end{gathered}
\]

\begin{equation}\label{Eq:RightMPSoperation}
\begin{gathered}
\begin{tikzpicture}[framed]
\matrix (m) [matrix of math nodes, row sep=2.55em, column sep=7.7em, minimum width=6.2em]
{
	\text{Mat}_{\mathbb{C}}( d^{L-(i-1)}, r_{i-1} ) & \text{Mat}_{\mathbb{C}}(d^{L-i}, r_{i-1}d ) & \text{Mat}_{\mathbb{C}}(d^{L-i},r_i ) \times \text{Mat}_{\mathbb{C}}(r_i, r_i) \times \text{Mat}_{\mathbb{C}}(r_i , r_{i-1}d) & \text{Mat}_{\mathbb{C}}(d^{L-i}, r_i) \times \text{Mat}_{\mathbb{C}}(r_i, r_{i-1})^d \\
	c^{\sigma_1  \dots \sigma_{L-(i-1)} a_{i-1}} & \Psi_{\sigma_1 \dots \sigma_{L-i}, \sigma_{L-(i-1)} a_{i-1 } } &  U_{ \sigma_1 \dots \sigma_{L-i}, a_i } S_{a_i a_i} V^{\dagger}_{a_i, \sigma_{L-(i-1)} a_{i-1} } & \sum_{\sigma_{L-(i-1)}} c^{\sigma_{1} \dots \sigma_{L-i}, a_i } B^{\sigma_{L-(i-1)}}_{a_{i}, a_{i-1}} \\
};
\path[->]
(m-1-1) edge node [above] { \text{reshape} } (m-1-2)
(m-1-2) edge node [above] { \text{SVD} } (m-1-3)
(m-1-3) edge node [above] { \text{slice and multiply} } (m-1-4)
;
\path[|->]
(m-2-1) edge node [above] { \text{reshape} } (m-2-2)
(m-2-2) edge node [above] { = } (m-2-3)
(m-2-3) edge node [above] { = } (m-2-4)
;
\end{tikzpicture}   
\end{gathered}
\end{equation}

Remember that $r_i \leq \min{(d^{L-i}, r_{i-1} d)} $ and for $i=L$, just do reshape and slice and multiply operations.

Then, finally, the \textbf{right normalization} is derived and is such:
\[
	\begin{gathered}
	V^{\dagger}V = 1 \Longrightarrow \\
	(V^{\dagger}V)_{a_i a'_i} = \delta_{a_i a'_i} = V^{\dagger}_{a_i, \sigma_{L-(i-1)}a_{i-1}} V_{\sigma_{L-(i-1)}a_{i-1}, a_i'} = B^{\sigma_{L - (i-1)}}_{a_i, a_{i-1}} (V^{\dagger})^{\dagger}_{ \sigma_{L - (i-1)}a_{i-1}, a_i' } = \\
	= B^{\sigma_{L- (i-1)}}_{ a_i a_{i-1}} (V^{\dagger})^*_{a_i', \sigma_{L- (i-1)}, a_{i-1}} = B^{\sigma_{L-(i-1)}}_{ a_i, a_{i-1}} B^{\sigma_{L - (i-1)}}_{a_i' , a_{i-1}} = B^{\sigma_{L-(i-1)}}_{a_i a_{i-1}} (B^{\dagger})^{\sigma_{L-(i-1)}}_{ a_{i-1} a_i'} \qquad \, \forall i = 1 \dots L
	\end{gathered}
\]

\begin{equation}
\Longrightarrow \sum_{ \sigma_{L-(i-1)}} B^{\sigma_{L-(i-1)}} (B^{\dagger})^{\sigma_{L-(i-1)}} = 1
\end{equation}



\begin{multicols*}{2}





cf. Sec. 4, Matrix Product States (MPS) of Schollw\"{o}ck \cite{Scho2010}.  

Necessarily, given matrix $M\in \text{Mat}_{\mathbb{K}}(M,N)$ (notation in Bridgeman and Chubb (2017) \cite{BrCh2017} and \href{http://docs.nvidia.com/cuda/cusolver/index.html}{CUDA Toolkit Documentation}; I will follow the notation in Schollw\"{o}ck \cite{Scho2010} since his $A$,$B$ denote specific physical meaning).  

For 
\[
U\in \text{Mat}_{\mathbb{K}}(N_A, \min{(N_A,N_B)}) \text{ s.t. } UU^{\dag}=1
\]
\[
S \in \text{Mat}_{\mathbb{K}}(\min{(N_A,N_B)}, \min{(N_A,N_B)} )
\]
s.t. $S$ diagonal with nonnegative $S_{aa} = s_a$, i.e. $S_{ij} = \delta_{ij}s_i$ s.t. $s_i\geq 0$ \, $\forall \, i = 1,2, \dots \min{(N_A,N_B)}$.  

$r\equiv $ (Schmidt) rank of $M :=$ number of nonzero singular values.  

Assume $s_1\geq s_2 \geq \dots \geq s_r \geq 0$.  

$V^{\dag} \in \text{Mat}_{\mathbb{K}}(\min{(N_A,N_B)},N_B)$ s.t. $V^{\dag}V=1$.  

\begin{tikzpicture}
  \matrix (m) [matrix of math nodes, row sep=1.75em, column sep=4.8em, minimum width=1.2em]
  {
	\text{Mat}_{\mathbb{K}}(N_A,N_B) & U_{\mathbb{K}}(N_A,\min{(N_A,N_B)}) \times \text{diag}_{\mathbb{K}}(\min{(N_A,N_B)}) \times U_{\mathbb{K}}(\min{(N_A,N_B)},N_B) \\ 
    M &  USV^{\dag} \\
};
  \path[->]
  (m-1-1) edge node [above] { SVD } (m-1-2)
  ;
  \path[|->]
  (m-2-1) edge node [above] {  SVD } (m-2-2)
  ;
\end{tikzpicture}  

Optimal approximation of $M$ (rank $r$ by matrix $M'$ (rank $r' <r$) property.  

In Frobenius norm $\| M \|_F^2 := \sum_{i,j} |M_{ij}|^2$, induced by inner product $\langle M | N \rangle =\text{tr}M^{\dag}N$.  Indeed, 
\[
\text{tr}M^{\dag}N = (M^{\dag})_{ik} N_{ki} = \overline{M}_{ki} N_{ki}
\]
and so for 
\begin{equation}
M'=US'V^{\dag}, \qquad \, S'=\text{diag}(s_1,s_2 \dots s_{r'}, 0 \dots ) \qquad \,
\end{equation}
cf. Eq. (19) of Schollw\"{o}ck \cite{Scho2010}, i.e. 1 sets all but 1st $r'$ singualr values to $0$.  

Use singular value decomposition (SVD) to derive Schmidt decomposition of general quantum state. 

$\forall \, $ pure state $|\psi \rangle$ on $AB$, 
\[
|\psi \rangle = \sum_{i,j} \Psi_{ij}|i\rangle_A |j\rangle_B
\]
where $\lbrace |i\rangle_A \rbrace, \lbrace |j\rangle_B \rbrace$ orthonormal bases of $A,B$ ((complex) Hilbert spaces), with dim. $N_A,N_B$, respectively.  

Let $\Psi_{i,j} \in \text{Mat}_{\mathbb{K}}(N_A,N_B)$.  

Then \textbf{reduced density operators} $\widehat{\rho}_A,\widehat{\rho}_B$ are such that 
\[
\begin{gathered}
\begin{aligned} 
	& \widehat{\rho}_A = \text{tr}_B|\psi \rangle \langle \psi | \\ 
	& \widehat{\rho}_B = \text{tr}_A|\psi \rangle \langle \psi | \\ 
\end{aligned}
\end{gathered}
\]
In matrix form, 
\[
\begin{aligned}
	& \rho_A = \Psi \Psi^{\dag} \\ 
	& \rho_B = \Psi^{\dag} \Psi 
\end{aligned}
\]
Indeed, 
\[
\begin{gathered}
\begin{aligned} 
	& (\rho_A)_{ij} = \Psi_{ik} \overline{\Psi}_{jk} \\
	& (\rho_B)_{ij} = \overline{\Psi}_{ki}  \Psi_{kj} \end{aligned} \\
\begin{gathered}
|\psi \rangle \langle \psi | = \sum_{i,j} \Psi_{ij} |i\rangle_A |j\rangle_B \sum_{l,m} \overline{\Psi}_{lm}\langle l |_A \langle m |_B \\
\text{tr}_B|\psi \rangle \langle \psi | = \sum_{i,j} \Psi_{ik} \overline{\Psi}_{jk} |i \rangle_A \rangle j |_A
\end{gathered}
\end{gathered}
\]
In matrix form, 
\[
\begin{aligned}
	& \rho_A = \Psi \Psi^{\dag} \\ 
	&  \rho_B = \Psi^{\dag} \Psi
\end{aligned}
\]
Carry out SVD on $\Psi$ in Eq. (20) of Schollw\"{o}ck \cite{Scho2010}, 
\[
|\psi \rangle = \sum_{i,j} \Psi_{ij} |i\rangle_A |j\rangle_B
\]
\[
\begin{gathered}
|\psi \rangle = \sum_{ij} \Psi_{ij} | i \rangle_A |j \rangle_B = \sum_{ij} \sum_{a=1}^{\min{(N_A,N_B)}} U_{ia} S_{aa} \overline{V}_{ja} |i \rangle_A | j \rangle_B = \sum_{a=1}^{ \min{(N_A,N_B)}} \sum_i U_{ia} | i \rangle_A s_a \sum_j \overline{V}_{ja} | j \rangle_B = \sum_{a=1}^{ \min{ (N_A,N_B)} } s_a |a \rangle_A |a\rangle_B
\end{gathered}
\]
Due to orthogonality of $U,V^{\dag}$, $\lbrace |a \rangle_A \rangle, \lbrace | a \rangle_B \rbrace$ orthonormal, and can be extended to be orthonormal bases of $A,B$.  

If we restrict the sum to run only over the $r\leq \min{(N_A,N_B)}$ positive nonzero singular values (i.e., for $\sum_{a=1}^{\min{(N_A,N_B)}}$, $_a>0$ \, $\forall \, a \leq r$, and so 
\[
|\psi \rangle =\sum_{a=1}^r s_a |a\rangle_A |a\rangle_B
\]
$r=1$ (classical) product states.  $|\psi \rangle = s_1 |1\rangle_A |1\rangle_B$.  \\
$r>1$ entangled (quantum) states.  

Schmidt decomposition on reduced density operators for $A$ and $B$:  

\[
\begin{aligned}
	& \widehat{\rho}_A =\sum_{a=1}^r s_a^2 |a\rangle_A \langle a |_A \\ 
	& \widehat{\rho}_B = \sum_{a=1}^r s_a^2 |a\rangle_B \langle a |_B
\end{aligned}
\]
Respective eigenvectors are left and right singular vectors.  

Von Neumann entropy can be read off:  
\[
S_{A|B}(|\psi \rangle) = -\text{tr}\widehat{\rho}_A \log_2{\widehat{\rho}_A} = -\sum_{a=1}^r s_a^2 \log_2{s_a^2}
\]

In view of large size of Hilbert spaces, approximate $| \psi \rangle$ by some $| \widetilde{\psi} \rangle$ spanned over state spaces $A,B$ that have dims. $r'$ only.  

Since 2-norm of $| \psi \rangle$, 
\[
\| | \psi\rangle \|_2^2 = \sum_{ij} |\Psi_{ij} |^2 = \| \Psi \|^2_F
\]
since
\[
\| | \psi\rangle \|_2^2 = \sum_{a=1}^r s_a^2 = \sum_{ij} |\Psi_{ij} |^2
\] 
iff $\lbrace |i \rangle \rbrace , \lbrace | j  \rangle \rbrace$ orthonormal.  Optimal approx. of 2-norm given by optimal approx. of $\Psi$ by $\overline{\Psi}$ in Frobenius norm, where $\overline{\Psi}$ is matrix of rank $r'$.  

$\overline{\Psi} = US'V^{\dag}$, $S' =\text{diag}(s_1 , \dots s_{r'} , 0\dots )$ from above. 

$\Longrightarrow $ Schmidt decomposition of approximate state 
\begin{equation}
| \overline{\Psi}\rangle = \sum_{a=1}^{r'} s_a|a\rangle_A | a \rangle_B
\end{equation}
cf. Eq. (27) of  Schollw\"{o}ck \cite{Scho2010}, where $s_a$ must be rescaled if normalization desired.  

\subsection{QR decomposition}
cf. 4.1.2. of  Schollw\"{o}ck \cite{Scho2010}.  

If actual value of singular values not used explicitly, then use \emph{QR decomposition}.  

QR decomposition: $\forall \, M \in \text{Mat}_{\mathbb{K}}(N_A,N_B)$, 
\begin{equation}
M=QR, \, Q\in U_{\mathbb{K}}(N_A), \text{ i.e. } Q^{\dag}Q = 1=QQ^{\dag} , \, R \in \text{Mat}_{\mathbb{K}}(N_A,N_B) \text{ s.t. } \text{ upper triangular, i.e. } R_{ij}= 0 \text{ if } i >j 
\end{equation}
\textbf{thin} QR decomposition: assume $N_A>N_B$.  Then bottom $N_A-N_B$ rows of $R$ are $0$, so 
\[
\begin{gathered}
M=Q \left[ \begin{matrix} R_1 \\ 0 \end{matrix} \right] = \left[ \begin{matrix} Q_1 & Q_2 \end{matrix} \right] \left[ \begin{matrix} R_1 \\ 0 \end{matrix} \right] = Q_1R_1 \\
\begin{aligned}
& Q_1 \in \text{Mat}_{\mathbb{K}}(N_A,N_B) \\ 
& R_1 \in \text{Mat}_{\mathbb{K}}(N_B,N_B) 
\end{aligned}
\end{gathered}
\]
While $Q_1^{\dag}Q_1=1$ in general $Q_1 Q_1^{\dag} \neq 1$

\section{Matrix Product States (MPS)}

cf. Section 4.13 Decomposition of arbitrary quantum states into MPS of  Schollw\"{o}ck \cite{Scho2010}.  

Consider lattice of $L$ sites, $d$-dim. local state spaces $\lbrace \sigma_i \rbrace_{i=1,\dots L}$.  

Most general pure quantum state on lattice (assume normalized) 
\begin{equation}
|\psi \rangle = \sum_{\sigma_1 \dots \sigma_L} c_{\sigma_1 \dots \sigma_L }|\sigma_1 \dots \sigma_L \rangle
\end{equation}
cf. Eq. (30) of  Schollw\"{o}ck \cite{Scho2010},

\subsection{Left-canonical matrix product state}  
cf.  Schollw\"{o}ck \cite{Scho2010},

Consider the process of refactoring or "flattening", which I claim to be a functor \emph{flatten}: 
\[
| \psi \rangle \in \mathcal{H} \text{ s.t. } \text{dim}\mathcal{H} = d^L \mapsto \Psi \in \text{Mat}_{\mathbb{K}}(d,d^{L-1})
\]
\[
\Psi_{\sigma_1, (\sigma_2 \dots \sigma_L) } = c_{\sigma_1 \dots \sigma_L}
\]
\begin{equation}
\begin{gathered}
\xrightarrow{ \text{ SVD } } c_{\sigma_1 \dots \sigma_L} = \Psi_{\sigma_1, (\sigma_2 \dots \sigma_L)} = \sum_a^{r_1} U_{\sigma_1, a_1} S_{a_1,a_1} (V^{\dag})_{a_1, (\sigma_2 \dots \sigma_L)} \equiv \sum_{a_1}^{r_1} U_{\sigma_1 , a_1} c_{a_1 , \sigma_2 \dots \sigma_L}
\end{gathered}
\end{equation}
i.e.
\[
\begin{aligned}
	& (\mathbb{K}^d)^L \to \text{Mat}_{\mathbb{K}}(1,r) \times \text{Mat}_{\mathbb{K}}(r_1 d, d^{L-2}) \\ 
	& c_{\sigma_1 \dots \sigma_L} \mapsto A_{a_1}^{\sigma_1} , \Psi_{(a_1\sigma_2), (\sigma_3\dots \sigma_L)} 
\end{aligned}
\]
s.t. 
\[
c_{\sigma_1\dots \sigma_L} = \sum_{a_1}^{r_1} A_{a_1}^{\sigma_1} \Psi_{(a_1\sigma_2), (\sigma_3 \dots \sigma_L)}
\]
where rank $r_1 \leq d$.  
\[
U \in \text{Mat}_{\mathbb{K}}(d,\min{(d,r)}) = \text{Mat}_{\mathbb{K}}(d,r)
\]
Consider $d$ row vectors $A^{\sigma_1}$, $A^{\sigma_1}_{a_1} = U_{\sigma_1,a_1}$.  

\[
\begin{gathered}
c_{a_1\sigma_2 \dots \sigma_L } = \sum_{a_1}^{r_1} A_{a_1}^{\sigma_1} \Psi_{(a_1,\sigma_2),(\sigma_3\dots \sigma_L)} \text{ with } \\
\Psi_{(a_1\sigma_2),(\sigma_3\dots \sigma_L)}\in \text{Mat}_{\mathbb{K}}(r_1d,d^{L-2})
\end{gathered}
\]
So from Eq. (34) of  Schollw\"{o}ck \cite{Scho2010},
\begin{equation}
\begin{gathered}
	c_{\sigma_1 \dots \sigma_L} = \sum_{a_1}^{r_1} \sum_{a_2}^{r_2} A_{a_1}^{\sigma_1} U_{ (a_1\sigma_2) , a_2} S_{a_2,a_2} (V^{\dag})_{a_2, (\sigma_3\dots \sigma_L)} = \sum_{a_1}^{r_1} \sum_{a_2}^{r_2} A_{a_1}^{\sigma_1} A_{a_1,a_2}^{\sigma_2} \Psi_{(a_2\sigma_3), (\sigma_4\dots \sigma_L)}
\end{gathered}
\end{equation}
So for 
\[
U\in \text{Mat}_{\mathbb{K}}(d,r_1\times r_2) \mapsto \lbrace A^{\sigma_2} \rbrace_{\sigma_2}, \qquad \, | \lbrace A^{\sigma_2} \rbrace_{\sigma_2} | = d , \qquad \, A^{\sigma_2} \in \text{Mat}_{\mathbb{K}}(r_1,r_2)
\]
$A^{\sigma_2}_{a_1,a_2} = U_{(a_1,\sigma_2),a_2}$ and multiplied $S$ and $V^{\dag}$, 
\[
SV^{\dag} \mapsto \Psi \in \text{Mat}_{\mathbb{K}}(r_2d, d^{L-3}); \qquad \, r_2 \leq r_1 d \leq d^2
\]
and so continuing the application of SVD and refactoring (what I call applying the \emph{flatten} functor)
\[
\begin{gathered}
\xrightarrow{ \text{ SVD } } c_{\sigma_1 \dots \sigma_L} = \sum_{a_1 \dots a_{L-1}} A^{\sigma_1}_{a_1} A^{\sigma_2}_{a_1 a_2} \dots A^{\sigma_{L-1}}_{a_{L-2}, a_{L-1} } A^{\sigma_L }_{a_L-1 } \equiv A^{\sigma_1} A^{\sigma_2} \dots A^{\sigma_{L-1}} A^{\sigma_L}
\end{gathered}
\]

\subsubsection{Matrix Product State (definition)}

\begin{definition}[Matrix Product State]
\begin{equation}
|\psi \rangle = \sum_{\sigma_1 \dots \sigma_L} A^{\sigma_1}A^{\sigma_2} \dots A^{\sigma_{L-1}} A^{\sigma_L} | \sigma_1 \dots \sigma_L \rangle
\end{equation}
\end{definition}

Maximally, the dims. are 
\[
(1\times d), (d\times d^2) \dots (d^{L/2-1} \times d^{L/2} ), (d^{L/2} \times d^{L/2-1} ) \dots (d^2 \times d), (d\times 1)
\]
Since $\forall \, $ SVD, $U^{\dag} U=1$, 
\[
\delta_{a_l , a_l'} = \sum_{a_{l-1} a_l} (U^{\dag})_{a_l,(a_{l-1} \sigma_l)} U_{(a_{l-1} \sigma_l),a'_l } = \sum_{a_{l-1} \sigma_l} (A^{\sigma_l})^{\dag}_{a_l,a_{l-1}} A^{\sigma_l}_{a_{l-1},a_l'} = \sum_{\sigma_l} ( (A^{\sigma_2})^{\dag} A^{\sigma_l} )_{a_l,a_l'}
\]
or 
\begin{equation}
	\sum_{\sigma_l} (A^{\sigma_l})^{\dag} A^{\sigma_l} = 1
\end{equation}
cf. Eq. (38) of  Schollw\"{o}ck \cite{Scho2010},

If for $\lbrace A^{\sigma_l} \rbrace_{\sigma_l} $, $\sum_{\sigma_l} (A^{\sigma_l})^{\dag} A = 1$, $\lbrace A^{\sigma_l} \rbrace_{\sigma_l}$ are \textbf{left-normalized}; matrix product states that consist of only left-normalized matrices are \textbf{left-canonical}.  

View Density Matrix Renormalization Group (DMRG) decomposition of universe into blocks $A$ and $B$, split lattice into parts $A$,$B$, where $A$ compries sites $1$ through $l$ and $B$ sites $l+1$ through $L$.  

\[
\begin{aligned}
	& | a_l \rangle_A = \sum_{\sigma_1 \dots \sigma_l} (A^{\sigma_1} A^{\sigma_2} \dots A^{\sigma_l} )_{a_l,1} | \sigma_1 \dots \sigma_l \rangle \\ 
		& | a_l \rangle_B = \sum_{\sigma_{l+1} \dots \sigma_L} (A^{\sigma_{l+1}} A^{\sigma_{l+2}} \dots A^{\sigma_L} )_{a_l,1} | \sigma_{l+1} \dots \sigma_L \rangle 
\end{aligned}
\]
s.t. matrix product state (MPS) is 
\[
|\psi \rangle =\sum_{a_l} | a_l \rangle_A | a_l \rangle_B
\]

\subsubsection{Summarize this procedure of constructing, from a pure state, the matrix product state (version) by successive application Singular Value Decomposition (SVD) from the Category Theory point of view}

Consider all applications of SVD to get to a matrix product state (MPS): 
\begin{tikzpicture}
  \matrix (m) [matrix of math nodes, row sep=1.75em, column sep=4.8em, minimum width=1.2em]
  {
	(\mathbb{K}^d)^L & (\text{Mat}_{\mathbb{K}}(1,r_1))^d \times (\text{Mat}_{\mathbb{K}}(r_1,r_2))^d \times \dots \times (\text{Mat}_{\mathbb{K}}(r_{L-2},r_{L-1}))^d \times (\text{Mat}_{\mathbb{K}}(r_{L-1},1))^d \\
    c_{\sigma_1 \dots \sigma_L}  &  c_{\sigma_1\dots \sigma_L} = \sum_{a_1 \dots a_{L-1}} A^{\sigma_1}_{a_1} A_{a_1a_2}^{\sigma_2} \dots A^{\sigma_{L-1}}_{a_{L-2}, a_{L-1}} A_{a_{L-1}}^{\sigma_L} \\
};
  \path[->]
  (m-1-1) edge node [above] { SVD } (m-1-2)
  ;
  \path[|->]
  (m-2-1) edge node [above] {  SVD } (m-2-2)
  ;
\end{tikzpicture}  
and remember the maximal values that the $r_i$'s can take:
\[
\begin{gathered}
	\begin{aligned}
& r_1 \leq d \\ 
	& r_2 \leq d^2 
\end{aligned}	 \qquad \, 	\begin{aligned}
& r_{L/2} \leq d^{L/2} \\ 
	& r_{L/2+1} \leq d^{L/2-1} 
\end{aligned} \qquad \, 	\begin{aligned}
& r_{L-2} \leq d^2 \\ 
	& r_{L-1} \leq d 
\end{aligned}
\end{gathered}
\]

Let us explicitly note the functors (that were applied) flatten (and its inverse), and the application of SVD, explicitly:

\end{multicols*}
%\begin{multicols*}{1}

\[
\begin{tikzpicture}
  \matrix (m) [matrix of math nodes, row sep=1.75em, column sep=2.8em, minimum width=1.2em]
  {
	(\mathbb{K}^d)^L & \text{Mat}_{\mathbb{K}}(d,d^{L-1})  & U_{\mathbb{K}}(d,r_1) \times \text{diag}_{\mathbb{K}}(r_1) \times U_{\mathbb{K}}(r_1,d^{L-1}) &  (\text{Mat}_{\mathbb{K}}(1,r_1))^d \times \text{Mat}_{\mathbb{K}}(r_1d, d^{L-2}) &   (\text{Mat}_{\mathbb{K}}(1,r_1))^d \times (\mathbb{K}^{r_1}) \times (\mathbb{K}^d)^{L-1}  
 \\
	    c_{\sigma_1 \dots \sigma_L} & c_{\sigma_1 \dots \sigma_L} = \Psi_{\sigma_1,(\sigma_2\dots \sigma_L)} & \Psi_{\sigma_1,(\sigma_2\dots \sigma_L)} = \sum_{a_1}^{r_1}U_{\sigma_1a_1} S_{a_1,a_1} (V^{\dag})_{a_1,(\sigma_2 \dots \sigma_L)} & c_{a_1\sigma_2\dots \sigma_L} = \sum_{a_1}^{r_1} A_{a_1}^{\sigma_1} \Psi_{(a_1,a_2),(\sigma_3 \dots \sigma_L)} &  c_{a_1\sigma_2\dots \sigma_L} = \sum_{a_1}^{r_1} A^{\sigma_1}_{a_1} c_{a_1 \sigma_2 \dots \sigma_L} \\
};
  \path[->]
  (m-1-1) edge node [above] { $\text{flatten}^{-1}$ } (m-1-2)
  (m-1-2) edge node [above] { SVD } (m-1-3)
  (m-1-3) edge node [above] { $\cong$ } (m-1-4)
  (m-1-4) edge node [above] { flatten } (m-1-5)
  ;
  \path[|->]
  (m-2-1) edge node [above] { $\text{flatten}^{-1}$ } (m-2-2)
  (m-2-2) edge node [above] { SVD } (m-2-3)
  (m-2-3) edge node [above] { $\cong$ } (m-2-4)
  (m-2-4) edge node [above] { flatten } (m-2-5)
  ;
\end{tikzpicture}  
\]
with $\cong$ in this case denoting an isomorphism (clearly).  


In considering some kind of recursive algorithm, so to repeat some series of steps until a matrix product state is obtained, consider this:
\[
\begin{tikzpicture}
  \matrix (m) [matrix of math nodes, row sep=1.75em, column sep=4.8em, minimum width=1.2em]
  {
	(\mathbb{K}^d)^L & (\text{Mat}_{\mathbb{K}}(1,r_1))^d \times \mathbb{K}^{r_1} \times (\mathbb{K}^d)^{L-1} \\
    c_{\sigma_1 \dots \sigma_L}  &  c_{\sigma_1\dots \sigma_L} = \sum_{a_1}^{r_1} A^{\sigma_1}_{a_1} c_{a_1 \sigma_2\dots \sigma_L} \\ 
};
  \path[->]
  (m-1-1) edge node [above] {  } (m-1-2)
  ;
  \path[|->]
  (m-2-1) edge node [above] {  } (m-2-2)
  ;
\end{tikzpicture}  
\]

So in summary, to obtain matrix product states, starting from a matrix, 
\begin{equation}
\begin{tikzpicture}[framed]
  \matrix (m) [matrix of math nodes, row sep=1.55em, column sep=1.7em, minimum width=1.2em]
  {
	\text{Mat}_{\mathbb{K}}(d,d^{L-1})  & (\text{Mat}_{\mathbb{K}}(1,r_1))^d \times \text{Mat}_{\mathbb{K}}(r_1d, d^{L-2}) & \dots &   (\text{Mat}_{\mathbb{K}}(1,r_1))^d \times (\text{Mat}_{\mathbb{K}}(r_1,r_2))^d \times \dots \times (\text{Mat}_{\mathbb{K}}(r_{n-1},r_{n}))^d \times (\text{Mat}_{\mathbb{K}}(r_{n}d,d^{L-(n+1)}))^d    \\
    \Psi_{\sigma_1,(\sigma_2\dots \sigma_L)} &   \sum_{a_1}^{r_1} A_{a_1}^{\sigma_1} \Psi_{(a_1,\sigma_2),(\sigma_3 \dots \sigma_L)}  & \dots & \sum_{a_1,a_2,\dots a_n}^{r_1,r_2,\dots r_n} A^{\sigma_1}_{a_1} A^{\sigma_2}_{a_1a_2}\dots A^{\sigma_n}_{a_{n-1}a_n} \Psi_{ (a_n \sigma_{n+1}), (\sigma_{n+2}\dots \sigma_L) } \\ 
};
  \path[->]
  (m-1-1) edge node [above] {  } (m-1-2)
  (m-1-2) edge node [above] {  } (m-1-3)
  (m-1-3) edge node [above] {  } (m-1-4)
  ;
  \path[|->]
  (m-2-1) edge node [above] {  } (m-2-2)
  (m-2-2) edge node [above] {  } (m-2-3)
  (m-2-3) edge node [above] {  } (m-2-4)
;
\end{tikzpicture}  
\end{equation}



%\end{multicols*}
%\begin{multicols*}{2}

\subsection{Right-canonical matrix product state}  
cf.  Schollw\"{o}ck \cite{Scho2010},

We can start from right in order to obtain 
\[
\begin{gathered}
	c_{\sigma_1\dots \sigma_L} = \Psi_{(\sigma_1 \dots \sigma_{L-1}), \sigma_L } = \sum_{a_{L-1}} U_{(\sigma_1 \dots \sigma_{L-1} ), a_{L-1} } S_{a_{L-1}, a_{L-1} } (V^{\dag})_{a_{L-1}, \sigma_L } = \sum_{a_{L-1}} \Psi_{(\sigma_1\dots \sigma_{L-2}), (\sigma_{L-1} a_{L-1} ) } B^{\sigma_L}_{a_{L-1}} = \\ 
 = \sum_{a_{L-1},a_{L-2}} U_{(\sigma_1 \dots \sigma_{L-2} ), a_{L-2} } S_{a_{L-2}, a_{L-2} } (V^{\dag})_{a_{L-2}, (\sigma_{L-1}a_{L-1}) } B^{\sigma_L}_{a_{L-1}}  = \sum_{a_{L-2},a_{L-1}} \Psi_{(\sigma_1\dots \sigma_{L-3}), (\sigma_{L-2} a_{L-2} ) } B^{\sigma_{L-1}}_{a_{L-2},a_{L-1}} B^{\sigma_L}_{a_{L-1}} = \dots \\ 
\end{gathered}
\]
or consider 
\[
\begin{tikzpicture}
  \matrix (m) [matrix of math nodes, row sep=1.95em, column sep=3.8em, minimum width=1.8em]
  {
	(\mathbb{K}^d)^L & \text{Mat}_{\mathbb{K}}(d^{L-1},d)  & U_{\mathbb{K}}(d^{L-1},r_{L-1}) \times \text{diag}_{\mathbb{K}}(r_{L-1}) \times U_{\mathbb{K}}(r_{L-1},d ) &  \text{Mat}_{\mathbb{K}}(d^{L-2},d r_{L-1})  \times ( \text{Mat}_{\mathbb{K}}(r_{L-1}, 1))^d &   \qquad \, 
 \\
	    c_{\sigma_1 \dots \sigma_L} & c_{\sigma_1 \dots \sigma_L} = \Psi_{(\sigma_1\dots \sigma_{L-1}),\sigma_L} & c_{\sigma_1 \dots \sigma_L} =  \sum_{a_{L-1}}^{r_{L-1}}U_{(\sigma_1 \dots \sigma_{L-1}), a_{L-1}} S_{a_{L-1},a_{L-1}} (V^{\dag})_{a_{L-1}, \sigma_L} & \begin{gathered}
	U_{(\sigma_1 \dots \sigma_{L-1}), a_{L-1} } S_{a_{L-1}, a_{L-1}} = \Psi_{(\sigma_1\dots \sigma_{L-2}), (\sigma_{L-1} a_{L-1}) } \\ 
(V^{\dag})_{a_{L-1},\sigma_L} = B^{\sigma_L}_{a_{L-1}} \\
c_{\sigma_1\dots \sigma_L} = \sum_{a_{L-1}} \Psi_{(\sigma_1 \dots \sigma_{L-2} ) , (\sigma_{L-1}, a_{L-1})} B_{a_{L-1}}^{\sigma_L} 
\end{gathered}  &  \qquad \,  \\
\qquad \, & U_{\mathbb{K}}(d^{L-2},r_{L-2}) \times \text{diag}_{\mathbb{K}}(r_{L-2}) \times U_{\mathbb{K}}(r_{L-2},dr_{L-1} ) \times  ( \text{Mat}_{\mathbb{K}}(r_{L-1}, 1))^d  & \text{Mat}_{\mathbb{K}}(d^{L-3},d r_{L-2})   \times  ( \text{Mat}_{\mathbb{K}}(r_{L-2}, r_{L-1}))^d  \times  ( \text{Mat}_{\mathbb{K}}(r_{L-1}, 1))^d &  &  \\
\qquad \,  & c_{\sigma_1\dots \sigma_L} = \sum_{a_{L-1},a_{L-2}} U_{(\sigma_1 \dots \sigma_{L-2} ), a_{L-2} } S_{a_{L-2}, a_{L-2} } (V^{\dag})_{a_{L-2}, (\sigma_{L-1}a_{L-1}) } B^{\sigma_L}_{a_{L-1}} &   \begin{gathered}
	U_{(\sigma_1 \dots \sigma_{L-2}), a_{L-2} } S_{a_{L-2}, a_{L-2}} = \Psi_{(\sigma_1\dots \sigma_{L-3}), (\sigma_{L-2} a_{L-2}) } \\ 
(V^{\dag})_{a_{L-2},(\sigma_{L-1}a_{L-1})} = B^{\sigma_{L-1}}_{a_{L-2}a_{L-1}} \\
c_{\sigma_1\dots \sigma_L} = \sum_{a_{L-1}, a_{L-2}} \Psi_{(\sigma_1 \dots \sigma_{L-3} ) , (\sigma_{L-2}, a_{L-2})} B_{a_{L-2},a_{L-1}}^{\sigma_{L-1}} B^{\sigma_L}_{a_{L-1}} 
\end{gathered}   & &  \\
};
  \path[->]
  (m-1-1) edge node [above] { $\text{flatten}^{-1}$ } (m-1-2)
  (m-1-2) edge node [above] { SVD } (m-1-3)
  (m-1-3) edge node [above] { $\cong$ } (m-1-4)
  (m-1-4) edge node [above] { SVD } (m-1-5)
 (m-3-1) edge node [above] { SVD } (m-3-2)
  (m-3-2) edge node [above] { $\cong$ } (m-3-3)
  ;
  \path[|->]
  (m-2-1) edge node [above] { $\text{flatten}^{-1}$ } (m-2-2)
  (m-2-2) edge node [above] { SVD } (m-2-3)
  (m-2-3) edge node [above] { $\cong$ } (m-2-4)
  (m-2-4) edge node [above] { SVD } (m-2-5)
  (m-4-1) edge node [above] { SVD } (m-4-2)
  (m-4-2) edge node [above] { $\cong$ } (m-4-3)
  ;
\end{tikzpicture}  
\]
with $\cong$ in this case denoting an isomorphism (clearly).  

And so we can explicitly state the recursion step, for the purpose of writing numerical implementations/algorithms: $\forall \, l = 1,2\dots L$,

\begin{tikzpicture}
  \matrix (m) [matrix of math nodes, row sep=1.75em, column sep=4.8em, minimum width=1.2em]
  {
\text{Mat}_{\mathbb{K}}(d^{L-l},d r_{L-(l-1)}) 	 & \text{Mat}_{\mathbb{K}}(d^{L-(l+1)},d r_{L-l}) \times (\text{Mat}_{\mathbb{K}}(r_{L-l},r_{L-(l-1)}))^d \\
    \Psi_{(\sigma_1\dots \sigma_{L-l}), (\sigma_{L-(l-1)} a_{L-(l-1)}) }   &      \Psi_{(\sigma_1\dots \sigma_{L-l}), (\sigma_{L-(l-1)} a_{L-(l-1)}) } = \sum_{a_{L-l}}     \Psi_{(\sigma_1\dots \sigma_{L-(l+1)}), (\sigma_{L-l} a_{L-l}) } B_{a_{L-l},a_{L-(l-1)}}^{\sigma_{L-(l-1)}}  \\ 
};
  \path[->]
  (m-1-1) edge node [above] {  } (m-1-2)
  ;
  \path[|->]
  (m-2-1) edge node [above] {  } (m-2-2)
  ;
\end{tikzpicture}  

and we finally obtained, after successive applications SVD, the matrix product state:

\begin{tikzpicture}
  \matrix (m) [matrix of math nodes, row sep=1.75em, column sep=4.8em, minimum width=1.2em]
  {
(\mathbb{K}^d)^L  & \text{Mat}_{\mathbb{K}}(d^{L-1},d )  & (\text{Mat}_{\mathbb{K}}( 1, r_1))^d \times  (\text{Mat}_{\mathbb{K}}(r_1,r_2))^d \times \dots \times (\text{Mat}_{\mathbb{K}}(r_{L-2},r_{L-1}))^d \times (\text{Mat}_{\mathbb{K}}(r_{L-1}, 1 ))^d \\
    c_{\sigma_1\dots \sigma_L} & \Psi_{(\sigma_1\dots \sigma_{L-l}), \sigma_L }   & c_{\sigma_1\dots \sigma_L} =      \sum_{ a_1 \dots a_{L-1} }  B_{a_1}^{\sigma_1}  B_{a_1a_2}^{\sigma_2 } \dots  B_{a_{L-2}a_{L-1}}^{\sigma_{L-1} }  B_{a_{L-1}}^{\sigma_L} \\ 
};
  \path[->]
  (m-1-1) edge node [above] {  } (m-1-2)
  (m-1-2) edge node [above] {  } (m-1-3)
  ;
  \path[|->]
  (m-2-1) edge node [above] {  } (m-2-2)
  (m-2-2) edge node [above] {  } (m-2-3)
  ;
\end{tikzpicture}  

\begin{multicols*}{2}

Since 
\begin{equation}
V^{\dag} V =1
\end{equation},
then
\begin{equation}
	\delta_{a_l a_l'} = \sum_{\sigma_m a_m } (V^{\dag})_{a_l (\sigma_ma_m) } V_{(\sigma_m a_m) a_l'} = \sum_{\sigma_m a_m } B_{a_l a_m}^{\sigma_m} \overline{B}^{\sigma_m}_{a_l' a_m} \Longrightarrow \sum_{\sigma_m} \boxed{ B^{\sigma_m} (B^{\sigma_m})^{\dag} = 1 }
\end{equation}
The $B$-matrices that obey this condition are referred to as \textbf{right-normalized} matrices.  A matrix product state (MPS) entirely consisting of a product of these right-normalized matrices is called \textbf{right-canonical}.  

\subsection{Matrix Product Operators (MPO)}

The form of a general operator, $\widehat{O}$ is the following:
\begin{equation}
\begin{gathered}
\widehat{O} = \sum_{ \lbrace \sigma \rbrace } \sum_{ \lbrace \sigma' \rbrace } c^{\sigma_1 \dots \sigma_L, \sigma_1' \dots \sigma_L'} | \sigma_1 \dots \sigma_L \rangle \langle \sigma_1' \dots \sigma_L' | \in \mathcal{H} \otimes \mathcal{H}^* 
\end{gathered}
\end{equation}
with $\text{dim}\mathcal{H} = \text{dim}\mathcal{H}^* = d^L$. 

For MPO, do the same decomposition as done in Eq. \ref{Eq:LeftMPSoperation} or in \ref{Eq::RightMPSoperation}, but with the double index $\sigma_i \sigma_i'$ taking the role of index $\sigma_i$ in MPS (i.e. do this substitution and the decomposition will proceed \emph{exactly} as before).

\end{multicols*}
%\begin{multicols*}{1}


\[
\begin{tikzpicture}
\matrix (m) [matrix of math nodes, row sep=2.55em, column sep=7.7em, minimum width=6.2em]
{
	\text{Mat}_{\mathbb{C}}(d^L, d^L)  \\
	\text{Mat}_{\mathbb{C}}(1, (d^2)^{L}) & \text{Mat}_{\mathbb{C}}(d^2, (d^2)^{L-1}) & \text{Mat}_{\mathbb{C}}(d^2, r_i) \times \text{Mat}_{\mathbb{C}}(r_i, r_i) \times \text{Mat}_{\mathbb{C}}(r_i , (d^2)^{L-1}) & \text{Mat}_{\mathbb{C}}(1, r_i)^d \times \text{Mat}_{\mathbb{C}}(r_i, (d^2)^{L-1}) \\
	c^{\sigma_1 \dots \sigma_L, \sigma_1' \dots \sigma_L'}  \\
	c^{\sigma_1 \sigma_1' \sigma_2 \sigma_2' \dots \sigma_L \sigma_L'} & \Psi_{\sigma_1 \sigma_1', (\sigma_{2} \sigma_2', \sigma_{3} \sigma_3' \dots \sigma_L \sigma_L') } &  U_{ \sigma_1\sigma_1', a_1 } S_{a_1 a_1} V^{\dagger}_{a_1, (\sigma_{2} \sigma_2' \dots \sigma_L \sigma_L'} & \sum_{\sigma_1 \sigma_1'} A^{\sigma_1 \sigma_1'}_{1, a_1} c^{a_1, \sigma_{2}\sigma_2' \dots \sigma_L\sigma_L'} \\
};
\path[->]
(m-1-1) edge node [right] { \text{reorder} } (m-2-1)
(m-2-1) edge node [above] { \text{reshape} } (m-2-2)
(m-2-2) edge node [above] { \text{SVD} } (m-2-3)
(m-2-3) edge node [above] { \text{slice and multiply} } (m-2-4)
;
\path[|->]
(m-3-1) edge node [right] { \text{reorder} } (m-4-1)
(m-4-1) edge node [above] { \text{reshape} } (m-4-2)
(m-4-2) edge node [above] { = } (m-4-3)
(m-4-3) edge node [above] { = } (m-4-4)
;
\end{tikzpicture}  
\]

\begin{equation}\label{Eq:LeftMPOoperation}
\begin{tikzpicture}[framed]
\matrix (m) [matrix of math nodes, row sep=2.55em, column sep=7.7em, minimum width=6.2em]
{
	\text{Mat}_{\mathbb{C}}(r_{i-1}, (d^2)^{L-(i-1)}) & \text{Mat}_{\mathbb{C}}(r_{i-1}d^2, (d^2)^{L-i}) & \text{Mat}_{\mathbb{C}}(r_{i-1}d^2, r_i) \times \text{Mat}_{\mathbb{C}}(r_i, r_i) \times \text{Mat}_{\mathbb{C}}(r_i , (d^2)^{L-i}) & \text{Mat}_{\mathbb{C}}(r_{i-1}, r_i)^{d^2} \times \text{Mat}_{\mathbb{C}}(r_i, (d^2)^{L-i}) \\
	c^{a_{i-1}, \sigma_i \sigma_i' \sigma_{i+1} \sigma_{i+1}' \dots \sigma_L \sigma_L'} & \Psi_{a_{i-1}\sigma_i \sigma_i', (\sigma_{i+1}\sigma_{i+1}' \sigma_{i+2}\sigma_{i+2}' \dots \sigma_L\sigma_L') } &  U_{a_{i-1} \sigma_i \sigma_i', a_i } S_{a_i a_i} V^{\dagger}_{a_i, \sigma_{i+1} \sigma_{i+1}' \dots \sigma_L\sigma_L'} & \sum_{\sigma_i \sigma_i'}^{max}A^{\sigma_i \sigma_i'}_{a_{i-1}, a_i} c^{a_i, \sigma_{i+1} \sigma_{i+1}' \dots \sigma_L \sigma_L'} \\
};
\path[->]
(m-1-1) edge node [above] { \text{reshape} } (m-1-2)
(m-1-2) edge node [above] { \text{SVD} } (m-1-3)
(m-1-3) edge node [above] { \text{slice and multiply} } (m-1-4)
;
\path[|->]
(m-2-1) edge node [above] { \text{reshape} } (m-2-2)
(m-2-2) edge node [above] { = } (m-2-3)
(m-2-3) edge node [above] { = } (m-2-4)
;
\end{tikzpicture}  
\end{equation}


\begin{multicols*}{2}


\subsubsection{Numerical implementation; both in BLAS and cuBLAS}

As stated in the \href{http://docs.nvidia.com/cuda/cusolver/index.html#cuds-lt-t-gt-gesvd}{CUDA Toolkit Documentation v8.0} for cuSOLVER, under section 5.3.6. \verb|cusolverDn<t>gesvd()| and Remark 1, \verb|gesvd| "only supports" \verb|m>=n|, for matrix you want to decompose $A\in \text{Mat}_{\mathbb{K}}(m,n)$.  So number of rows must be greater than or equal to number of columns.  And so we can only consider right-normalized matrices in a practical implementation.  

I suspect it's the same in BLAS.  

Consider the very first step, $l=1$, in a procedure to calculate the matrix product state.  

\begin{tikzpicture}
  \matrix (m) [matrix of math nodes, row sep=1.95em, column sep=3.8em, minimum width=1.8em]
  {
	 \text{Mat}_{\mathbb{K}}(d^{L-1},d)  &  U_{\mathbb{K}}(d^{L-1},r_{L-1}) \times \text{diag}_{\mathbb{K}}(r_{L-1}) \times U_{\mathbb{K}}(r_{L-1},d ) &  \text{Mat}_{\mathbb{K}}(d^{L-2},d r_{L-1})  \times ( \text{Mat}_{\mathbb{K}}(r_{L-1}, 1))^d &   \qquad \,  \\	    
 \Psi_{(\sigma_1\dots \sigma_{L-1}),\sigma_L} &  = \sum_{a_{L-1}}^{r_{L-1}}U_{(\sigma_1 \dots \sigma_{L-1}), a_{L-1}} S_{a_{L-1},a_{L-1}} (V^{\dag})_{a_{L-1}, \sigma_L} & \begin{gathered}
	U_{(\sigma_1 \dots \sigma_{L-1}), a_{L-1} } S_{a_{L-1}, a_{L-1}} = \Psi_{(\sigma_1\dots \sigma_{L-2}), (\sigma_{L-1} a_{L-1}) } \\ 
(V^{\dag})_{a_{L-1},\sigma_L} = B^{\sigma_L}_{a_{L-1}} 
\end{gathered} \\
};
  \path[->]
  (m-1-1) edge node [above] { SVD } (m-1-2)
  (m-1-2) edge node [above] { $\cong$ } (m-1-3)
  ;
  \path[|->]
  (m-2-1) edge node [above] { SVD } (m-2-2)
  (m-2-2) edge node [above] { $\cong$ } (m-2-3)
  ;
\end{tikzpicture}  
with $\cong$ in this case denoting an isomorphism, the \emph{reshaping} of a matrix into different matrix size dimensions, which should be the inverse of a "flatten" functor, which I'll denote as $\text{flatten}^{-1}$ as well (and this is this same isomorphism we're talking about).  

Let's deal with the specific procedure of $\text{flatten}^{-1}$, how it reshapes indices in accordance with different matrix size dimensions, and with the so-called "stride" when going from, say, 2-dimensional indices to a "flattened" 1-dimensional index.  

Note also as a practical numerical implementation design point, LAPACK's linear algebra BLAS library package and CUBLAS assumes \emph{column}-major ordering.  

Consider $i= 1,2,\dots L-1$ (for site $i$) (or for $0$-based counting, starting to count from $0$, $i=0,1,\dots L-2$; be aware of this difference as in practical numerical implementation, in C, C++, Python, it assumes $0$-based counting).  

For a state space of dimension $d$, we can consider the specific example of $d=2$, representing say a spin-$1/2$ system.  Then index $\sigma_i$ can be $0$ or $1$: $\sigma_i \in \lbrace 0 ,1\rbrace$.  In general, $\sigma_i \in \lbrace 0 ,1, \dots d-1\rbrace$.  I may use $d$ or $2$ in the context of the number of states (basis vectors) of the spin system (state vector space).  

Consider site $i$.  Suppose the spin system there interacts most with sites $i-1$, $i+1$, and then next sites $i-2$, $i+2$, etc.  So the values at $\sigma_{i-1}, \sigma_{i+1}$, etc. are most important in calculating interactions with spin system at site $i$.  

Then we seek this reshaping of the matrix index - assuming $0$-based counting/ordering, for $l=1$:
\begin{tikzpicture}
  \matrix (m) [matrix of math nodes, row sep=1.95em, column sep=3.8em, minimum width=1.8em]
  {
	\lbrace 0 ,1 \rbrace^{L-1} & \lbrace 0 ,1, \dots 2^{L-1} -1 \rbrace \\
	(\sigma_0,\sigma_1, \dots \sigma_{L-2}) & I_{L-1} := \sigma_0 + 2\sigma_1 + \dots + 2^i \sigma_i + \dots + 2^{L-2}\sigma_{L-2} = \sum_{i=0}^{L-2} 2^i \sigma_i \\
};
  \path[->]
  (m-1-1) edge node [above] { $(\text{flatten})^{-1}$ } (m-1-2)
  ;
  \path[|->]
  (m-2-1) edge node [above] { $(\text{flatten})^{-1}$ } (m-2-2)
  ;
\end{tikzpicture}  

In this way, states of a site $i$ are closest in memory addresses in the allocation of a 1-dim. array, on CPU or GPU memory, so that memory access operations should be efficient.  

Assuming SVD doesn't change the striding, and defining the result of matrix multiplication:
\[
U_{(\sigma_0, \sigma_1 \dots \sigma_{L-2}), a_{L-1} } S_{a_{L-1}, a_{L-1}} =: (US)_{(\sigma_0 \dots \sigma_{L-2} ), a_{L-1} } \in \text{Mat}_{\mathbb{K}}(d^{L-1},r_{L-1} )
\]

We can reshape (i.e. $(\text{flatten})^{-1}$) in such a manner: 
\[
\begin{tikzpicture}
  \matrix (m) [matrix of math nodes, row sep=1.95em, column sep=3.8em, minimum width=1.8em]
  {
	\text{Mat}_{\mathbb{K}}(d^{L-1},r_{L-1})  & \text{Mat}_{\mathbb{K}}(d^{L-2},dr_{L-1}) \\ 
	(US)_{(\sigma_0 \dots \sigma_{L-2} ), a_{L-1} }  & \Psi_{(\sigma_0,\sigma_1 ,\dots \sigma_{L-3}), (\sigma_{L-2} a_{L-1}) }     \\
	\lbrace 0 ,1,\dots 2^{L-1}-1 \rbrace \times \lbrace 0 ,1,\dots r_{L-1} -1 \rbrace & \lbrace 0 ,1,\dots 2^{L-2}-1 \rbrace \times \lbrace 0 ,1,\dots dr_{L-1} -1 \rbrace \\
I_{L-1}, a_{L-1}  & I_{L-1} \mod{ 2^{L-2}} , \frac{ I_{L-1} }{ 2^{L-2} } + da_{L-1} \\
};
  \path[->]
  (m-1-1) edge node [above] { $(\text{flatten})^{-1}$ } (m-1-2)
  (m-3-1) edge node [above] { $(\text{flatten})^{-1}$ } (m-3-2)
  ;
  \path[|->]
  (m-2-1) edge node [above] { $(\text{flatten})^{-1}$ } (m-2-2)
  (m-4-1) edge node [above] { $(\text{flatten})^{-1}$ } (m-4-2)
  ;
\end{tikzpicture}  
\]
Reshaping $V^{\dag}$ at iteration $l=1$ can be done as follows:  
\[
\begin{tikzpicture}
  \matrix (m) [matrix of math nodes, row sep=1.95em, column sep=3.8em, minimum width=1.8em]
  {
	U_{\mathbb{K}}(r_{L-1},d)  & ( \text{Mat}_{\mathbb{K}}( r_{L-1} , 1) )^d \\ 
	(V^{\dag})_{a_{L-1},\sigma_{L-1 } }   & (V^{\dag})_{a_{L-1},\sigma_{L-1} } = B_{a_{L-1}}^{\sigma_{L-1}}     \\
	\lbrace 0 ,1,\dots r_{L-1} -1  \rbrace \times \lbrace 0 ,1,\dots d -1 \rbrace &  (   \lbrace 0 ,1,\dots  r_{L-1}-1 \rbrace )^d \\
a_{L-1}, \sigma_{L-1}  & a_{L-1}  \\
};
  \path[->]
  (m-1-1) edge node [above] { $(\text{flatten})^{-1}$ } (m-1-2)
  (m-3-1) edge node [above] { $(\text{flatten})^{-1}$ } (m-3-2)
  ;
  \path[|->]
  (m-2-1) edge node [above] { $(\text{flatten})^{-1}$ } (m-2-2)
  (m-4-1) edge node [above] { $(\text{flatten})^{-1}$ } (m-4-2)
  ;
\end{tikzpicture}  
\]

Let's do this same procedure, reshaping or $(\text{flatten})^{-1}$, for a general $l$ iteration.  

\[
\begin{tikzpicture}
  \matrix (m) [matrix of math nodes, row sep=1.95em, column sep=3.8em, minimum width=1.8em]
  {
	\text{Mat}_{\mathbb{K}}(d^{L-l},r_{L-l})  & \text{Mat}_{\mathbb{K}}(d^{L-(l+1)},dr_{L-l}) \\ 
	(US)_{(\sigma_0 \dots \sigma_{L-(l+1)} ), a_{L-l } }  & \Psi_{(\sigma_0,\sigma_1 ,\dots \sigma_{L-(l+2)}), (\sigma_{L-(l+1)} a_{L-l}) }     \\
	\lbrace 0 ,1,\dots d^{L-l}-1 \rbrace \times \lbrace 0 ,1,\dots r_{L-l} -1 \rbrace & \lbrace 0 ,1,\dots d^{L-(l+1)}-1 \rbrace \times \lbrace 0 ,1,\dots dr_{L-l} -1 \rbrace \\
I_{L-l}, a_{L-l}  & I_{L-l} \mod{ d^{L-(l+1)}} , \frac{ I_{L-l} }{ d^{L-(l+1)} } + da_{L-l} \\
};
  \path[->]
  (m-1-1) edge node [above] { $(\text{flatten})^{-1}$ } (m-1-2)
  (m-3-1) edge node [above] { $(\text{flatten})^{-1}$ } (m-3-2)
  ;
  \path[|->]
  (m-2-1) edge node [above] { $(\text{flatten})^{-1}$ } (m-2-2)
  (m-4-1) edge node [above] { $(\text{flatten})^{-1}$ } (m-4-2)
  ;
\end{tikzpicture}  
\]

\[
\begin{tikzpicture}
  \matrix (m) [matrix of math nodes, row sep=1.95em, column sep=3.8em, minimum width=1.8em]
  {
	U_{\mathbb{K}}(r_{L-l},dr_{L-(l-1)})  & ( \text{Mat}_{\mathbb{K}}( r_{L-l} , r_{L-(l-1)}) )^d \\ 
	(V^{\dag})_{a_{L-l}, (\sigma_{L-l } a_{L-(l-1)}) }   & (V^{\dag})_{a_{L-l}, ( \sigma_{L-l} a_{L-(l-1)} ) } = B^{\sigma_{L-l}}_{a_{L-l}, a_{L-(l-1)}}         \\
	\lbrace 0 ,1,\dots r_{L-l} -1  \rbrace \times \lbrace 0 ,1,\dots d r_{L-(l-1)} -1 \rbrace &  (   \lbrace 0 ,1,\dots  r_{L}-1 \rbrace \times \lbrace 0 ,1,\dots  r_{L-(l-1)}-1 \rbrace  )^d \\
a_{L-l}, ( \sigma_{L-l} a_{L-(l-1)} ) := a_{L-l}, \sigma_{L-1} + da_{L-(l-1)}   & a_{L-l} , \frac{ (\sigma_{L-1}  a_{L-(l-1)} ) }{d} \, ; \, \sigma_{L-l}  = (\sigma_{L-l} a_{L-(l-1)} ) \mod{d} \\
};
  \path[->]
  (m-1-1) edge node [above] { $(\text{flatten})^{-1}$ } (m-1-2)
  (m-3-1) edge node [above] { $(\text{flatten})^{-1}$ } (m-3-2)
  ;
  \path[|->]
  (m-2-1) edge node [above] { $(\text{flatten})^{-1}$ } (m-2-2)
  (m-4-1) edge node [above] { $(\text{flatten})^{-1}$ } (m-4-2)
  ;
\end{tikzpicture}  
\]

\subsubsection{Numerical implementations of initial states}

Something else that shouldn't be overlooked is the numerical implementation of \emph{initial states}, the $c$'s of a state $| \psi \rangle = \sum_{ \lbrace \sigma \rbrace } c^{\sigma} | \lbrace \sigma \rbrace \rangle$ for a many-body quantum system. Remember what the postulates of quantum mechanics say and interpret accordingly (and correctly). While we call them "probability amplitudes", one should be careful about what physical interpretation we may (or may not!) assign them. One thing's for certain: $c \in \mathbb{C}$ and normalization of the quantum state: $ | \langle \psi | \psi \rangle |^2 = 1$

Here are some setups to try:

$d= 2, L=2$, $d^L = 2^2=4$.
\[
\left[ \begin{matrix} c_{\uparrow \uparrow} & c_{\uparrow \downarrow} & c_{\downarrow \uparrow} & c_{\downarrow \downarrow} \end{matrix} \right] \mapsto \left[ \begin{matrix} c_{\uparrow \uparrow} & c_{\uparrow \downarrow} \\
c_{\downarrow \uparrow} & c_{\downarrow \downarrow} \end{matrix} \right]
\]

Singlet state: $|\psi \rangle = \frac{1}{ \sqrt{2}} | \uparrow \downarrow \rangle -  \frac{1}{\sqrt{2}} | \downarrow \uparrow \rangle $, $\left[ \begin{matrix} 0 & \frac{1}{\sqrt{2}} \\ \frac{-1}{\sqrt{2}} & 0 \end{matrix} \right]$ 

$d=2, L=3, d^L = 2^8 = 8$

For notational convenience, let $\uparrow \equiv 1$, $\downarrow \equiv 0$

\[
\left[ \begin{matrix} c_{000} & c_{001} & c_{010} & c_{011} & c_{100} & \dots & c_{111}  \end{matrix} \right] \mapsto \left[ \begin{matrix} c_{000} & c_{001} & \dots & c_{011} \\
c_{100} & c_{001} & \dots & c_{111} \end{matrix} \right]
\]

$d=3, L=2$, $d^L = 3^2 = 9$

\[
\left[ \begin{matrix} c_{-1-1} & c_{-10 } & c_{-11} & \dots  & c_{11} \end{matrix} \right] \mapsto \left[ \begin{matrix} c_{-1-1} & c_{-10} &  c_{-11} \\
c_{0-1} & c_{00} &  c_{01} \\ 
c_{1-1} & c_{10} & c_{11} \end{matrix} \right]
\]


%\end{multicols*}
%\begin{multicols*}{2}







%\end{multicols*}

\part{Algebraic Geometry}

\section{Affine and Projective Varieties}

cf. Harris (1992)\cite{Har1992}

For (algebraically closed) field $K$,  \\
vector space $K^n$,  \\
affine space $\mathbb{A}^n_K \equiv \mathbb{A}^n = K^n$, but origin plays no special role in affine space. \\
Affine variety $X \subset \mathbb{A}^n := $ common zero locus of collection of polynomials $f_{\alpha} \in K [z_1 \dots z_n] :=$ 
\[
X = \lbrace Z | f_{\alpha}(Z) = 0 \quad \, \forall \, \alpha , \quad \, f_{\alpha} \in K(z_1 \dots z_n), Z = (z_1 \dots z_n) \rbrace 
\]

\subsection{Projective Space and Projective Varieties} 

Projective space over field $K = $ set of 1-dim. subspaces of vector space $K^{n+1} \equiv \mathbb{P}^n_K \equiv \mathbb{P}^n = (K^{n+1} - \lbrace 0 \rbrace ) / K^*$, \\
where $(K^{n+1} - \lbrace 0 \rbrace ) / K^*$ is the quotient of $K^{n+1} - \lbrace 0 \rbrace$ by the action of the group $K^n$ acting by scalar multiplication. 

$\mathbb{P}(V) \equiv \mathbb{P}V \equiv $ projective space of 1-dim. subspaces of a vector space $V$ over field $K$. \\
$P \in \mathbb{P}^n$ usually written as homogeneous vector $[Z_0 \dots Z_n]$, by which be mean line spaced by $(Z_0 \dots Z_n) \in K^{n+1}$. 

For $U_n$ s.t. $\forall \, P \in U_n \subset \mathbb{P}^n \subset V^{n+1}$, $Z_n \neq 0$.  Then $[Z_0 \dots Z_n] \sim \left[ \frac{ Z_0}{ Z_n} , \dots , \frac{Z_{n-1}}{Z_n} , 1 \right] \cong \left[ \frac{Z_0}{Z_n} , \dots \frac{Z_{n-1}}{ Z_n } \right] \in K^n$.  

$\forall \, v \neq 0$ , $v\in V$, $[v] = $ corresponding pt. in $\mathbb{P}V \cong \mathbb{P}^n$

Polynomial $F \in K[Z_0 \dots Z_n]$ on vector space $K^{n+1}$ doesn't define a function on $\mathbb{P}^n$, but \\
if $F$ is homogeneous of degree $d$, \\
\phantom{if }then since 
\[
	F(\lambda Z_0 , \dots , \lambda Z_n) = \lambda^d F(Z_0 \dots Z_n)
\]
it does make sense to talk about $0$ locus of polynomial $F$.

\begin{definition}[Projective variety]
	projective variety $X \subset \mathbb{P}^n = \lbrace P | F_{\alpha}(P) = 0 \, \, \forall \, \alpha, \, \, F_{\alpha}(\lambda P) = \lambda^d F_{\alpha}(P) \rbrace = $ zero locus of a collection of homogeneous polynomials $F_{\alpha}$. 
\end{definition}

Group $PGL_{n+1}K$ acts on space $\mathbb{P}^n$ (in Lecture 18, $PGL_{n+1}K$ are automorphisms of $\mathbb{P}^n$).

Varieties $X, Y \subset \mathbb{P}^n$ are projectively equivalent, if they're congruent, modulo this group.

Note that if $\mathbb{P}^n = \mathbb{P}V$ is projective space associated with vector space $V$, \\
\begin{itemize}
	\item homogeneous coordinates on $\mathbb{P}V$ correspond to elements of dual space $V^*$ 
	\item similarly, space of homogeneous polynomials of degree $d$ on $\mathbb{P}V$ naturally identified with vector space $\text{Sym}^d(V^*)$
\end{itemize}
Meaning, set of linear coordinates on vector space $V$, $\text{dim}V = n$, over field $K$ (so $V= K^n$), $\alpha_i \equiv z_i$, $i=1 \dots n$, is a \emph{basis} $(\alpha_i)$ of $V^*$, since 
\[
\begin{gathered}
	\begin{gathered}
	\alpha : V \to K^n \\
	v \mapsto (\alpha_1(v) , \dots \alpha_n(v)) 
	\end{gathered} \text{ i.e. } \equiv \begin{gathered}
	z : V \to K^n \\
	v \mapsto (z_1(v) \dots z_n(v))
	\end{gathered}
\end{gathered}
\]

Now $\mathbb{P}(V) = (V \backslash \lbrace 0 \rbrace ) / K^*$ and homogeneous coordinates on $\mathbb{P}(V)$ are just linear coordinates on $V$ up to action $K^*$

cf. \href{https://math.stackexchange.com/questions/62588/correspondence-between-the-projective-space-associated-to-a-vector-space-and-the}{"Correspondence between the projective space associated to a vector space and the dual space of the vector space?", stackexchange}, \href{https://math.stackexchange.com/questions/2093271/can-dual-vector-spaces-be-thought-of-as-linear-coordinate-functions}{Can dual vector spaces be thought of as linear coordinate functions? stackexchange}

From $Z_i \in V^*$, $i = 0, 1 \dots n$, $Z_i : V \to K$, $Z_i : v \mapsto Z_i(v) = Z_i \in K$, \\
let $f$ be a homogeneous polynomial of degree $d$ on $\mathbb{P}V$:
\[
f = \sum a_{i_0 i_1 \dots i_n} z_0^{i_0} z_1^{i_1} \dots z_n^{i_n} 
\]
where summation $\sum$ is over $0 \leq i_0, i_1, \dots i_n \leq d$ s.t. $\sum_{j=0}^n i_j = d$.

$\text{dim}{\text{Sym}^d(V^*)} = \binom{d+n}{n}$

$\lbrace z_0^{i_0} z_1^{i_1} \dots z_n^{i_n} \rbrace_{ \substack{ 0 \leq i_0 , i_1 \dots i_n \leq d \\ \sum_{j=0}^n i_j = d } }$ form a basis for $\text{Sym}^d(V^*)$
 
Let $U_i \subset \mathbb{P}^n$, $U_i = \lbrace [Z_0 \dots Z_n ] | Z_i \neq 0 \rbrace$. Then $[Z_0 \dots Z_n ] \sim \left[ \frac{Z_0}{Z_i} \dots \frac{Z_{i-1}}{ Z_i }, 1 \dots \frac{Z_n}{Z_i} \right] \equiv [ z_0, \dots z_{i-1} , 1 , z_i \dots z_{n-1} ] \cong (z_0 , z_1 \dots z_{n-1}) \in K^n$. 

So there's a bijection $U_i \to K^n$.

Geometrically, this map is associating line $L \subset K^{n+1}$ not contained in hyperplane ($Z_i = 0$), its pt. $p$ of intersection with affine plane $(Z_i = 1) \subset K^{n+1}$.  

Coordinates $z_j$ on $U_i$ are called affine or Euclidean coordinates on projective space or open set $U_i$ \\
- open sets $U_i$ comprise standard cover of $\mathbb{P}^n$ by affine open sets.

If $X \subset \mathbb{P}^n$ is a variety, $X_i = X \cup U_i$ is affine variety: \\
if $X$ given by polynomials $F_{\alpha} \in K[Z_0 , \dots Z_n]$, then e.g. $X_0$ will be zero locus of polynomials
\[
\begin{gathered}
f_{\alpha}(z_0 \dots z_n) = F_{\alpha}(Z_0 \dots Z_n) / Z_0^d = F_{\alpha}(1, z_1 \dots z_n)
\end{gathered}
\]
where $d = \deg{F_{\alpha}}$. 

For (projective) variety $X \subset \mathbb{P}^n$, $X = \lbrace P | F_{\alpha}(P) = 0, \forall \, \alpha, F_{\alpha} \text{ homogeneous, } P = [ Z_0 , Z_1 \dots Z_n] \in \mathbb{P}^n \rbrace$, \\
obtain affine variety $X_i = X \cup U_i$ as follows: for 
\[
z_j = \begin{cases} \frac{ Z_{j-1}}{ Z_i } & j \leq i \\ \frac{Z_j}{ Z_i} , & j > i \end{cases}
\]

\[
\begin{gathered}
f_{\alpha}(z_1 \dots z_n) = f_{\alpha}\left( \frac{Z_0}{Z_i} , \dots \frac{Z_{i-1}}{Z_i} , \frac{Z_{i+1}}{Z_i} \dots \frac{Z_n}{Z_i} \right) = \frac{1}{Z_i}^{d_{\alpha}} F_{\alpha}(Z_0 \dots Z_n) = F_{\alpha}(z_1 \dots z_i, 1, z_{i+1}, \dots z_n)
\end{gathered}
\]

If $F_{\alpha}(Z_0 \dots Z_n) = 0$, then $f_{\alpha}(z_1 \dots z_n) =0$

$\forall \, $ projective variety $X$, $X$ is union of affine varieties. 

If affine variety $X_i \subset K^n \cong U_i \subset \mathbb{P}^n$, by def. $X_i$ given by polynomials $\lbrace f_{\alpha} \rbrace_{\alpha}$

\[
f_{\alpha} (z_1 \dots z_n) = \sum a_{i_1 \dots i_n} z_1^{i_1} \dots z_n^{i_n} = 0
\]
of degree $d_{\alpha}$ (i.e. $i_1+ \dots i_n = d_{\alpha}$)

Then
\[
\begin{gathered}
F_{\alpha}(Z_0 \dots Z_n) = Z_i^{D_{\alpha}} F_{\alpha}\left( \frac{ Z_0}{Z_i} \dots \frac{Z_n}{Z_i} \right) = Z_i^{D_{\alpha}}f_{\alpha}(z_1 \dots z_n) = \sum a_{i_1 \dots i_n} Z_i^{D_{\alpha} - \sum i_l} Z_0^{i_0} \dots Z_n^{i_n} = \\
= \sum a_{i_1 \dots i_n} Z_i^{ D_{\alpha} - d_{\alpha}} Z_0^{i_0} \dots \widehat{Z}_i^{i_i} \dots Z_n^{i_n}
\end{gathered}\]

\subsubsection{Example: ellipse}

\begin{equation}
\begin{gathered}
\mathbb{P}^n \to U_Z \cong K^n \\
[X,Y,Z] \mapsto (x,y) = \left( \frac{X}{Z}, \frac{Y}{Z} \right) 
\end{gathered}
\end{equation}

Consider 
\begin{equation}
\frac{x^2}{a^2} + \frac{y^2}{b^2} = 1 \text{ or } f(x,y) = \frac{x^2}{a^2} + \frac{y^2}{b^2} -1
\end{equation}

For affine variety $X_Z \subset K^2$, 
\begin{equation}
F(X,Y,Z) = \left( \frac{X^2}{Z^2 a^2} + \frac{Y^2}{Z^2 b^2} - 1 \right) Z^2 = \frac{X^2}{a^2} + \frac{Y^2}{b^2} - Z^2
\end{equation}



\section{Algebraic Curves; Conic sections}

cf. Reid (2013) \cite{Reid2013}.

cf. Ch. 0 "Woffle" of Reid (2013) \cite{Reid2013}.

Given field $k$, $k[x_1 \dots x_n]$ colelction of all polynomials in $x_1 \dots x_n$, with coefficients in $k$, 
\[
f  \in k[x_1 \dots x_n] = \lbrace f | f = \sum_{\alpha} c_{\alpha} x^{\alpha}, x^{\alpha} = x_1^{\alpha_1} \dots x_n^{\alpha_n}, \, c_{\alpha} \in k \rbrace 
\]
Variety is (roughly) locus defined by polynomial equations
\[
V = \lbrace P \in k^n | f_i(P) = 0 \rbrace \subset k^n, \, f_i \in k[x_1 \dots x_n]
\]
e.g. plane curves $C$: $(f(x,y) = 0) \subset \mathbb{R}^2$ or $\mathbb{C}^2$


Groups of transformations (i.e. transformation groups) are of central importance throughout geometry; properties of geometric figures must be invariant under appropriate kind of transformations before they're significant.

\emph{affine change of coordinates in} $\mathbb{R}^2$ is of form
\begin{equation}
T(\mathbf{x}) = A \mathbf{x} + B \quad \, (\text{affine change of coordinates})
\end{equation}
where $\mathbf{x} = (x,y) \in \mathbb{R}^2$, $A$ $2\times 2$ invertible matrix (i.e. $A \in GL(2, \mathbb{R})$), $B\in \mathbb{R}^2$. 

If $A$ orthogonal, transformation $T$ is \emph{Euclidean}.

$\forall \, $ nondegenerate conic can be reduced to "standard form" by Euclidean transformation.

\textbf{projectivity} or projective transformation $\mathbb{P}^2_{\mathbb{R}}$ is map $T(\mathbf{X}) = M \mathbf{X}$, $M \in GL(3, \mathbb{R})$.  

Understand $T$ on affine piece $\mathbb{R}^2 \subset \mathbb{P}^2_{\mathbb{R}}$ is partially defined map $\mathbb{R}^2 \to \mathbb{R}^2$; it's a fractional linear transformation.

\[
\begin{gathered}
	\begin{aligned}
	& (x,y) \xmapsto{\cong} [x,y, 1] \\
	& (x,y) \mapsto \left( \begin{matrix} A \left( \begin{matrix} x \\ y \end{matrix} \right) + B \\ cx + dy + e \end{matrix} \right) 
	\end{aligned}
\end{gathered}
\]
where 
\[
M = \left( \begin{array}{c|c} A & B \\ \begin{matrix} c & d \end{matrix} & e \end{array} \right) 
\]
e.g. 2 different photographs of same (plane) object are obviously related by a projectivity.

For inhomogeneous quadratic polynomial $q$, homogeneous quadratic polynomial $Q$, then there exists bijection
\[
\begin{gathered}
	q \in K[x,y] \xmapsto{\cong} Q \in K[X,Y,Z] \\
	q(x,y) = ax^2 + bxy + cy^2 + dx + ey + f \mapsto Q(X,Y,Z) = aX^2 + bXY + cY^2 + dXZ + eYZ + fZ^2 
\end{gathered}
\]
so
\[
q(x,y) = Q\left( \frac{X}{Z} , \frac{Y}{Z} , 1 \right) \text{ with } x= X/Z, \, y = Y/Z
\]
inverse:
\[
Q = Z^2 q(X/Z, Y/Z)
\]


\subsubsection{"Line at infinity" and asymptotic directions}

cf. Ch. 1 of Reid (2013)

Points of $\mathbb{P}^2$ with $Z=0$, $[X,Y,0]$, form \emph{line at infinity}, a copy of $\mathbb{P}^1_{\mathbb{R}} = \mathbb{R} \cup \lbrace \infty \rbrace$ (since $[X,Y] \mapsto X/Y$) define bijection $\mathbb{P}^1_{\mathbb{R}} \to \mathbb{R} \cup \lbrace \infty \rbrace$. 

Line in $\mathbb{P}^2$, $L$, $L: = \lbrace [ X, Y,Z] | aX + bY + cZ = 0 \rbrace$. 

$L$ passes through $(X,Y,0) \Longleftrightarrow a X + bY = 0$. 



\begin{enumerate}
	\item[(a)]  hyperbola $\left( \frac{x^2}{a^2} - \frac{y^2}{b^2} = 1 \right)$. Recall that the lines of asymptotes (asymptotic lines). They are found in the following manner: 
	\[
	\begin{gathered}
	\frac{(bx-ay)(bx + ay)}{a^2 b^2} = 1 \text{ or } \frac{bx-ay}{a^2 b^2} =  \frac{1}{ bx + ay} \xrightarrow{ x,y \to \infty} \frac{bx- ay}{a^2 b^2 } =0 \text{ or } y = \frac{b}{a} x
	\end{gathered}\]
	
	Now, $\left( \frac{x^2}{a^2} - \frac{y^2}{b^2} = 1 \right)$ in $\mathbb{R}^2$ 
	corresponds in $\mathbb{P}^2_{\mathbb{R}}$ to $C: \left( \frac{X^2}{a^2} - \frac{Y^2}{b^2} = Z^2 \right)$.
	
	This meets ($Z=0$) in 2 pts. $(a, \pm b, 0) \in \mathbb{P}^2_{\mathbb{R}}$, corresponding to asymptotic lines of hyperbola, $y = \frac{b}{a}x$, $y = \frac{-b}{a} x$
	
	For affine piece $U_x \subset \mathbb{P}^2_{\mathbb{R}}$, $U_x = \lbrace p \in \mathbb{P}^2_{\mathbb{R}} | p = [X,Y,Z] \text{ s.t. } X \neq 0 \rbrace$, then \\
	bijection $U_x \to \mathbb{R}^2$, 
	\[
	\begin{gathered}
	[X,Y,Z \sim [1, \frac{Y}{X}, \frac{Z}{X} ] \mapsto (u,v) = \left( \frac{Y}{X}, \frac{Z}{X} \right), \text{ so } \\
	C : X^2/a^2  - Y^2/b^2 = Z^2 \mapsto u^2 + \frac{v^2}{b^2} = \frac{1}{a^2} \text{ or } \frac{u^2}{1/a^2} + \frac{v^2}{ (b/a)^2 } = 1 \qquad \, (\text{an ellipse!})
	\end{gathered}
	\]
	\item[(b)] $y = mx^2$ (parabola) in $\mathbb{R}^2 \mapsto  C: YZ = mX^2$ in $\mathbb{P}^2_{\mathbb{R}}$.
	
	For $Z = 0$, $C$ meets $Z=0$ at single pt. $[0, 1, 0] \sim [0, Y, 0]$. So in $\mathbb{P}^2$, "2 branches of parabola meet at infinity."
\end{enumerate} 

\subsubsection{Classification of conics in $\mathbb{P}^2$}

cf. 1.6. Classification of conics in $\mathbb{P}^2$, Reid (2013) \cite{Reid2013}

Let $K$ be any field of characteristic $\neq 2$.

Recall 2 linear algebra results for quadratic forms:

\begin{proposition}
	$\exists \, $ bijections
	
	$\lbrace \text{ homogeneous quadratic polynomials } \rbrace = \lbrace \text{ quadratic forms $K^3 \to K$ } \rbrace \cong \lbrace \text{ symmetric bilinear forms on $K^3$ } \rbrace $
given by
\[
\begin{gathered} 
	aX^2 + 2bXY + cY^2 + 2dXZ + 2eYZ + fZ^2 \cong \left( \begin{matrix} a & b & d \\ b & c & e \\  d & e & f \end{matrix} \right) \text{ since } \\
	[ \begin{matrix} X & Y & Z \end{matrix} ] \left( \begin{matrix} a & b & d \\ b & c & e \\  d & e & f \end{matrix} \right) \left[ \begin{matrix} X \\ Y \\ Z \end{matrix} \right] = aX^2 + 2bXY + cY^2 + 2d XZ +2eYZ + fZ^2 
\end{gathered} 
\]
\end{proposition}
Quadratic form nondegenerate if corresponding bilinear form nondegenerate, i.e. matrix is nonsingular.

\begin{theorem}\label{Thm:DiagonalizedQuadraticForm}
Let $V$ be vector space over $K$, quadratic form $Q:V \to K$, then $\exists \, $ basis of $V$ s.t.
\begin{equation}
Q = \epsilon_1 x_1^2 + \epsilon_2 x_2^2 + \dots + \epsilon_n x_n^2 \text{ with } \epsilon_i \in K
\end{equation}
\end{theorem}
This theorem is proved by Gram-Schmidt orthogonalization.

For $\lambda \in K \backslash \lbrace 0 \rbrace$, $x_i \mapsto \lambda x_i$ takes $\epsilon_i \mapsto \lambda^{-2} \epsilon_i$.  

\begin{corollary}\label{Cor:ConicsClassification}
In a suitable coordinate system, any conic in $\mathbb{P}^2$ is one of 
\begin{enumerate}
\item[(a)] nondegenerate conic $C: (X^2 + Y^2- Z^2 =0)$
\end{enumerate}
\end{corollary}

\subsubsection{Parametrization of a conic}

Let $C$ be a nondegenerate, nonempty conic of $\mathbb{P}^2_{\mathbb{R}}$.

Then by Corollary \ref{Cor:ConicsClassification} (cf. Corollary 1.6 (cf. Reid (2013) \cite{Reid2013}), and taking new coordinates $[X+Z, Y, Z-X]$, 
\[
X^2 + Y^2-Z^2 = 0 \mapsto (X+Z)^2 + Y^2 - (Z-X)^2 = X^2 + 2XZ + Z^2 + Y^2 - (Z^2 - 2ZX + X^2) = Y^2 + 4XZ = 0
\]
$\Longrightarrow C$ is projectively equivalent to curve $(Y^2 =XZ)$.

This is a curve parametrized by 
\[
\begin{aligned} 
& \Phi : \mathbb{P}^1_{\mathbb{R}} \to C \subset \mathbb{P}^2_{\mathbb{R}} \\
& [U,V] \mapsto [ U^2, UV, V^2]
\end{aligned} 
\]

This is because 
\[
\begin{gathered}
	[X, Y, Z ] \sim [X^2 , XY , XZ ] = [X^2 , XY, Y^2]
\end{gathered}
\]
and so let $U=X, V=Y$.  Note that if $X \mapsto X+Z$, then $U=X+Z$.  

Inverse map $\Psi = \Phi^{-1}$, $\Psi : C \to \mathbb{P}^1_{\mathbb{R}}$ given by 
\[
[X,Y,Z] \mapsto [X,Y] = [Y,Z]
\]
$[X,Y]$ defined if $X \neq 0$, $[Y,Z]$ defined if $Z\neq 0$.

$\Phi, \Psi$ are inverse isomorphisms of varieties. 





cf. Ch. 2 "Cubics and the group law" of Reid (2013) \cite{Reid2013}.

cf. Sec. 2.1 "Examples of parametrized cubics" in Ch. 2 of Reid (2013) \cite{Reid2013}.

Nodal cubic: $C: (y^2 = x^3 + x^2) \subset \mathbb{R}^2$, is image of map $\varphi : \mathbb{R}^1 \to \mathbb{R}^2$, $t \mapsto (t^2 - 1, t^3 - t)$, since 
\[
\begin{gathered}
	(t^2 - 1)^3 + (t^2 - 1)^2 = t^6- 3t^4 + 3t^2  - 1 + t^4 - 2t^3 + 1 = t^6 - 2t^4 + t^2 = t^2 (t^4 - 2t^2 + 1) = t^2 (t^2 -1)^2 = y^2
\end{gathered}
\]

Cuspidal cubic 
$C : (y^2 = x^3) \subset \mathbb{R}^2$ is image of $\varphi: \mathbb{R}^1 \to \mathbb{R}^2$, $t\mapsto (t^2 , t^3)$

\subsubsection{Curve $y^2 = x(x-1)(x-\lambda )$ has no rational parametrization}

cf. Sec. 2.2 "Curve $y^2 = x(x-1)(x-\lambda)$" in Ch. 2 of Reid (2013) \cite{Reid2013}.

$f = f(t)$ \emph{rational function} if it's a quotient of 2 polynomials. 

\begin{lemma}\label{Lem:SquaresOfCoprimesAreConstant}
	Let $\overline{K}$ algebraically closed field, $p, q \in \overline{K}[t]$ coprime elements (i.e. if $\exists \, x $ s.t. $p/x$, $q/x \in \overline{K}$ (i.e. $x | p$, $x | q$), then $x=1$), \\
	assume 4 distinct linear combinations (i.e. $\lambda p + \mu q$ for 4 distinct ratios $(\lambda : \mu) \in \mathbb{P}^1K$) are squares in $\overline{K}[t]$, \\ 
	then $p,q \in \overline{K}$
\end{lemma}

cf. Lemma 2.3 of Reid (2013) \cite{Reid2013}

\begin{proof}
	(Fermat's method of "infinite descent")
	
	Without loss of generality, 
	\[
	\begin{aligned}
		& p' = ap + bq \\ 
		& q' = cp + dq
	\end{aligned}
	\]
	$a,b,c, d \in K$, $ad-bc \neq 0$. 
	
	Hence, assume 4 given squares are 
	\[
	p, p-q, p-\lambda q , q
	\]
	i.e. $\lambda p + \mu q$, for $\lambda = 1, \mu = 0$; $\lambda = 1, \mu = -1$; $\lambda = 1, \mu = -\lambda$; $\lambda = 0, \mu = 1$
	
	Since $a,b,c,d$ arbitrary linear transformation.
	
	Then $p = u^2, q = v^2$, $u,v \in \overline{K}[t]$ are coprime, with 
	\[
	\max{ (\deg{u} , \deg{v} )} < \max{ (\deg{p}, \deg{q})}
	\]
	Suppose $\max{(\deg{p}, \deg{q})} >0$ and is minimal among all $p,q$ satisfying lemma condition.
	
	Then 
	\[
	\begin{aligned}
	& p - q = u^2 - v^2 = (u-v)(u+v) \\
	& p - \lambda q = u^2 - \lambda v^2 = (u-\mu v) (u + \mu v)
	\end{aligned}
	\]
	where $\mu = \sqrt{\lambda}$, are squares in $\overline{K}[t]$. 
	
	So by $u,v $ being coprime, \\
	\phantom{ \qquad \, } Then $u-v, u+v, u- \mu v, u + \mu v$ are squares.
	
	This contradicts minimality of $\max{(\deg{p}, \deg{q})}$


\end{proof}	





\begin{theorem}[$y^2 = x(x-1)(x-\lambda)$ has no rational parametrization]\label{Thm:SomeEqnHasNoRationalParametrization}
	Let $K$ be field of characteristic $\neq 2$, let $\lambda \in K$, $\lambda \neq 0, 1$; let $f,g \in K(t)$ be rational functions s.t.\[
	f^2 = g(g-1)(g-\lambda)
	\]
	Then $f, g\in K$. 	
\end{theorem}
	EY (20181229). Recall, \emph{characteristic of ring} $R$ (e.g. field), $\text{char}(K)$, smallest number of times $1$ must using ring's multiplicative identity $1$ in a sum to get additive identity ($0$). 
	
	$\text{char}(K) = 0$ for case that $\underbrace{n}{1 + \dots + 1} = \sum_{i=1}^n 1 \neq 0 \quad \, \forall \, n \in \mathbb{Z}^+$.  

	Theorem \ref{Thm:SomeEqnHasNoRationalParametrization} is equivalent to $\nexists $ nonconstant map $\mathbb{R}^1 \to C : (y^2 = x(x-1)(x-\lambda))$ given by rational functions.
	
	\begin{proof}
$K[t]$ UFD; unique factorization domain (given).

EY: 20181229, recall the definitions:
integral domain - nonzero commutative ring in which product of any 2 nonzero elements is nonzero. \\
unique factorization domain is an integral domain $R$ s.t. $\forall \, x \in R$, $x\neq 0$, $x$ can be written as 
\[
x = u p_1 p_2 \dots p_n , \quad \, n \geq 0
\]		
with irreducible elements $p_i$ of $R$, unit $u$.

\[
\begin{gathered}
\Longrightarrow \begin{aligned} & f = r/s \\ & g = p /q \end{aligned} \qquad \quad \, 
\begin{aligned}
& r,s \in K[t] \text{ and coprime } \\
& p,q \in K[t] \text{ and coprime } 
\end{aligned}
\end{gathered}
\]

\[
\begin{gathered}
\Longrightarrow f^2 = g(g-1)(g-\lambda) = \frac{r^2 }{s^2} = \frac{p}{q} \left( \frac{ p-q}{q} \right)\left( \frac{ p - \lambda q}{q} \right) \Longrightarrow r^2 q^3 = s^2 p(p-q)(p-\lambda q)
\end{gathered}
\]
$r,s$ are coprime, so RHS $s^2$ must divide $q^3$. \\
$p,q$ are coprime, LHS $q^3$ must divide $s^2$

EY (20181229): observe that LHS and RHS are different and equal. How to get them into the same form? Try to divide both sides!

\[
\Longrightarrow s^2 | q^3 \text{and } q^3 | s^2, \text{ so } s^2 = aq^3 \text{ with } a \in K
\]

Then $aq = (s/q)^2$ is square in $K[t]$

Then $r^2 = ap(p-q)(p-\lambda q)$

Consider factorization into primes $\Longrightarrow$ nonzero constants $b,c,d \in K$, s.t. $bp, c(p-q), d(p-\lambda q)$ are all squares in $K[t]$. \\
Let algebraic closure $\overline{K}$ (algebraic extension of $K$ s.t. $\overline{K}$ algebraically closed, i.e. $\forall \, $ nonconstant $f(x) \in K[x]$ has a root in $K$).

Then $\forall \, p, q \in \overline{K}(t)$, by lemma, $p,q \in \overline{K}$. Then $r,s \in \overline{K}$.  Then $\boxed{ f, g \in \overline{K}}$.

		\end{proof}
	

cf. Sec. 2.4 "Linear systems" in Ch. 2 of Reid (2013) \cite{Reid2013}.

Let $S_d \equiv \lbrace \text{ forms of degree $d$ in $(X, Y, Z)$ } \rbrace$; recall form is just a homogeneous polynomial.

$\forall \, F \in S_d$, $\exists \, $ unique form for $F$: $F = \sum a_{ijk} X^i Y^j Z^k$, $a_{ijk} \in K$, and $\sum \equiv \sum_{ \substack{ i,j,k \geq 0 \\ i + j + k = d } }$.

$\Longrightarrow S_d $ is $K$-vector space with basis $\lbrace Z^d, XZ^{d-1}, YZ^{d-1}, \dots X^{d-2} Y^2 \dots Y^d \rbrace$, where
\[
\boxed{ \text{dim}S_d  = \binom{d+2}{2} }
\]
(to see this, imagine $d$ stars, 2 bars, and the 2 bars distinguish which are $X$'s, $Y$'s, or $Z$'s). 

For $P_1 \dots P_n \in \mathbb{P}^2$, let 
\[
S_d(P_1 \dots P_n) = \lbrace F \in S_d | F(P_i) =0 \quad \, \forall \, i = 1 \dots n \rbrace \subset S_d
\]

$\forall \, $ condition $F(P_i) = 0$ (e.g. $F(X_i, Y_i, Z_i) =0$, where $P_i = (X_i, Y_i, Z_i)$) is 1 linear condition on $F$, so $S_d(P_1 \dots P_n)$ is a vector space of $\text{dim} \geq \binom{ d+2}{2} - n$

\begin{lemma}[Special case of Nullstellensatz]\label{Lem:SpecialCaseOfNullstellensatz}
	\begin{enumerate}
		\item[(i)] Let $L \subset \mathbb{P}_K^2$ be a line; if $F \equiv 0$ on $L$, then $F$ divisible in $K[X, Y, Z]$ by equation of $L$, i.e. $F = H \cdot F'$, where $H$ is equation of $L$, and $F' \in S_{d-1}$. 
		\item[(ii)] Let $C \subset \mathbb{P}^2_K$ be nonempty nondegenerate conic; if $F =0$ on $C$, then $F$ divisible in $K[X,Y,Z]$, by equation of $C$, i.e. $F = QF'$, where $Q$ is equation of $C$, and $F' \in S_{d-2}$. 
	\end{enumerate}
\end{lemma}

cf. Lemma 2.5 of Reid (2013). 

\begin{proof}
\begin{enumerate}
	\item[(i)] By change of coordinates, assume $H = X$, 
	Then, $\forall \, F \in S_d$, $\exists \, ! \, F = X \cdot F'_{d-1} + G(Y,Z)$, since, just gather together all monomials involving $X$ into 1st. summand, and what's left must be a polynomial $Y,Z$.
	
	Since \\
	$F = 0$ on $L$, $F(0) = 0 = 0 \cdot F'_{d-1} + G(Y,Z) $ $\Longrightarrow G(Y,Z) = 0\quad \, \forall \, Y,Z$. 
	
	Otherwise, if $G(Y,Z) \neq 0$, then it has at most $d$ zeros on $\mathbb{P}_K^1$, whereas if $K$ is infinite, then so is $\mathbb{P}_K^1$.  
	\item[(ii)] By change of coordinates $Q = XZ - Y^2$, \\ 
	Consider why 
	\[
	F = QF_{d-2}' + A(X,Z) + YB(X,Z)
	\]
	where $d-2$ in $F_{d-2}'$ denotes the \emph{degree} of the polynomial (to be $d-2$).
	
	This is because if $Y^2 = XZ - Q$, then $F(Y^2 = XZ - Q)$ has degree $\leq 1$ in $Y$, and so would have the form 
	\[
	F(Y^2 = XZ - Q) = A(X,Z) + YB(X,Z)
	\]
	$C$ is a parametrized conic given by 
	\[
	X = U^2 , Y = UV, \, Z = V^2
	\]
	so that, \\
	$F = 0$ on $C$ $\Longleftrightarrow  A(U^2, V^2) + UVB(U^2 , V^2) = 0$ on $C$ \\
	$\Longrightarrow A(U^2, V^2) + UVB(U^2 , V^2)  =0  \in K[U,V]$. \\
	$\Longrightarrow A(X,Z) = B(X,Z) =0 $
	
	Since here the last equality comes by considering separately terms of even and odd degrees in form 
	\[
	A(U^2, V^2)  + UVB(U^2, V^2)
	\]
	
\end{enumerate}	
\end{proof}

cf. Exercises to Ch. 2, Reid (2013)

\exercisehead{2.2}
Let $\begin{aligned} & \quad \\ 
& \varphi : \mathbb{R}^1 \to \mathbb{R}^2	\\
& t \mapsto (t^2, t^3) \end{aligned}$. 

$\forall \, $ polynomial $f \in \mathbb{R}[X, Y]$, s.t. $f= 0$ on image $C = \varphi(\mathbb{R}^1)$, $f$ divisible by $Y^2 - X^3$. 

\begin{proof}
	Given $\varphi(t) = (t^2, t^3) = (x,y)$, then $y^2 = x^3$ \, $\forall \, t \in \mathbb{R}$, or $y^2 - x^3 = 0$.
	
	Let $q= q(x,y) = y^2 - x^3 \in K[x,y]$.
	
	Suppose $f$ of degree $d$.
	
	Then 
	\[
	f = q f'_{d-2} + a(x) + y b(x)
	\]
	
	This is because, if $y^2 = q- x^3$, $f(y^2 = q- x^3)$ has degree $\leq 1$ in $y$, so would have the previous form.
	
	Now 
	\[
	\begin{gathered}
	f(y^2 = q- x^3) = 0 = 0 + a(x) + yb(x)
	\end{gathered}
	\]
	$f = 0$ on $C = \varphi(\mathbb{R}^1) \Longrightarrow $ $a(x) + yb(x) =0 = a(t^2) + t^3 b(t^2) = 0$.
	
	Suppose for $t_1 > 0$, $t_1^3 b(t_1^2) = -a(t_1^2)$. 
	
	Consider $-t_1 < 0$: 
	\[
	\begin{gathered}
	\Longrightarrow -t_1^3 b(t_1^3) = -a(t_1^2) \Longrightarrow a(t_1^2) = 0 \quad \, \forall \, t_1 >0
	\end{gathered}
	\]
	Then $b(t_1^2) = 0$ $\forall \, t_1 > 0$.
	
	$\Longrightarrow f = qf_{d-2}'$ where $q = y^2-x^3$.
	
	$K$ needs to have "negative numbers" (i.e. additive inverses) to exist, for this proof to work.
	\end{proof}	

\part{Algebraic Geometry applications}

\section{References for Algebraic Geometry applications}

 A tutorial on geometric programming
	Stephen Boyd, Seung-Jean Kim, Lieven Vandenberghe, Arash Hassibi

\url{https://math.berkeley.edu/~bernd/math275old.html}

\url{https://arxiv.org/pdf/math/0103170.pdf}

\url{https://www.researchgate.net/publication/257426699_Lossless_Convexification_of_Nonconvex_Control_Bound_and_Pointing_Constraints_in_the_Soft_Landing_Optimal_Control_Problem}

\end{multicols*}


\begin{thebibliography}{9}

%--------------------------------------------------------------------------------
% 20180203 
%-------------------------------------------------------------------------------
\bibitem{KaSch2006}
Masaki Kashiwara and Pierre Schapira. \textbf{Categories and Sheaves}.  \emph{Grundlehren der mathematischen Wissenschaften}.  Volume 332.  2006. Springer-Verlag Berlin Heidelberg.  eBook ISBN 978-3-540-27950-1

%--------------------------------------------------------------------------------
% END of 20180203 
%-------------------------------------------------------------------------------

%--------------------------------------------------------------------------------
% 20180311 
%-------------------------------------------------------------------------------
\bibitem{DuFo2003}
David S. Dummit, Richard M. Foote. \textbf{Abstract Algebra}. 3rd. Ed.  Wiley; (July 14, 2003). ISBN-13: 978-0471433347 
%--------------------------------------------------------------------------------
% END of 20180311 
%-------------------------------------------------------------------------------

\bibitem{BW1998}
Michael Barr, Charles Wells.  \textbf{Category Theory for Computing Science}.  \url{http://www.tac.mta.ca/tac/reprints/articles/22/tr22.pdf}, \url{http://www.math.mcgill.ca/triples/Barr-Wells-ctcs.pdf}
 
\bibitem{AHS2004}
Ji\v{r}\'{i} Ad\'{a}mek, Horst Herrlich, George E. Strecker.   \textbf{Abstract and Concrete Categories The Joy of Cats}. 2004.  \url{http://katmat.math.uni-bremen.de/acc/acc.pdf}

\bibitem{MacL1978}
Saunders Mac Lane. \textbf{Categories for the Working Mathematician}. Graduate Texts in Mathematics. Volume 5. 1978. Springer-Verlag New York. eBook ISBN
978-1-4757-4721-8

\bibitem{Simm2011}
Harold Simmons. \textbf{An Introduction to Category Theory}. 1st Edition. Cambridge University Press; 1 edition (November 21, 2011). ISBN-13: 978-0521283045

\bibitem{Turi2001}
Daniele Turi. \textbf{Category Theory Lecture Notes}.  September 1996 – December 2001.  \url{http://www.dcs.ed.ac.uk/home/dt/CT/categories.pdf}

\bibitem{Lein2014}
Tom Leinster.  \textbf{Basic Category Theory} (Cambridge Studies in Advanced Mathematics) 1st Edition.  2014.  ISBN-13: 978-1107044241

\bibitem{Pare2004}
Prof. Dr. B. Pareigis. \textbf{Category Theory}. Summer Semester 2004. June 14, 2004. \url{http://www.mathematik.uni-muenchen.de/~pareigis/Vorlesungen/04SS/Cats1.pdf}

\bibitem{Cuki2018}
Ivan \v{C}uki\'{c}. \textbf{Functional Programming in C++: How to improve your C++ programs using functional techniques}. Manning Publications; 1st edition (November 19, 2018). ISBN-13: 978-1617293818


%%--------------------------------------------------------------------------------------------------
%%% Applications of Category Theory
%%--------------------------------------------------------------------------------------------------
\bibitem{Ames2006}
Aaron David Ames. "A Categorical Theory of Hybrid Systems." PhD dissertation. Dec. 11, 2006. Technical Report No. UCB/EECS-2006-165. \url{http://www.eecs.berkeley.edu/Pubs/TechRpts/2006/EECS-2006-165.html}


\bibitem{CLS2005}
David A. Cox.  John Little. Donal O'Shea. \textbf{Using Algebraic Geometry}.  Second Edition.  Springer.  2005.  ISBN 0-387-20706-6 QA564.C6883 2004

\bibitem{CLS2015}
David Cox, John Little, Donal O'Shea. \textbf{Ideals, Varieties, and Algorithms: An Introduction to Computational Algebraic Geometry and Commutative Algebra}, Fourth Edition, Springer

\bibitem{GrDu2017}
Torsten Grust, Christian Duta. \emph{Datenbanksysteme I}. Winter 2017-2018. Eberhard Karls Universit\"{a}t T\"{u}bingen.  \url{https://www-db.informatik.uni-tuebingen.de/teaching/DatenbanksystemeIWS2017-2018.html}


\bibitem{Spiv2009}
David I. Spivak. \emph{Simplicial Databases}. \href{https://arxiv.org/abs/0904.2012}{arXiv: 0904.2012v1} [cs.DB] 13 Apr 2009.

\bibitem{Spiv2012}
David I. Spivak. \emph{Categorical Databases}. Presented on 2012/01/13. \url{http://math.mit.edu/~dspivak/informatics/talks/CTDBIntroductoryTalk}

\bibitem{Yang2012}
Jun Yang. \emph{CompSci 316}: \emph{Introduction to Database Systems}. Fall 2012. Duke University. \url{https://www2.cs.duke.edu/courses/fall12/compsci316/index.html}

\bibitem{SpCu2011}
Carlo Curino. David Spivak. \emph{Category Theory as a Unifying Database Formalism}. 2011. \url{http://math.mit.edu/~dspivak/informatics/notes/unorganized/PODS.pdf}

\bibitem{Awod2010}
Steve Awodey. \textbf{Category Theory} (Oxford Logic Guides) 2nd Edition. Oxford Logic Guides (Book 52). Oxford University Press; 2 edition (August 13, 2010). ISBN-13: 978-0199237180

\bibitem{BaWe2012}
Michael Barr, Charles Wells. \textbf{Category Theory for Computing Science}. 2012

\bibitem{Schu2016}
\href{https://www.youtube.com/c/FredericSchuller}{Frederic Schuller}. \href{https://youtube.com/playlist?list=PLPH7f_7ZlzxQVx5jRjbfRGEzWY_upS5K6&si=rtLLBi4xcb-Z6bfH}{\textbf{Lectures on Quantum Theory}}. March 2016.

\bibitem{Durr2019}
Rick Durrett. \textbf{Probability: Theory and Examples}. Version 5. Jan. 11, 2019.

\bibitem{Mauc2004}
Sean Mauch. \textbf{Introduction to Methods of Applied Mathematics or Advanced Mathematical Methods for Scientists and Engineers}. January 24, 2004. Mauch Publishing Company, un-Incorporated. 

\bibitem{Geor1992}
Howard Georgi. \textbf{The Physics of Waves}. Benjamin Cummings; 1st edition. 1992. ISBN-13:978-0136656210.


\bibitem{FrSc2007} 
Franz Schwabl. \textbf{Quantum Mechanics}. Springer-Verlag Berlin Heidelberg. 2007. 4th Edition. ISBN 978-3-540-71933-5

\bibitem{Scho2008}  
Schottenloher, Martin.  \textbf{A Mathematical Introduction to Conformal Field Theory}.  Springer, 2008.  

\bibitem{LaLi1980}
L.D. Landau and E.M. Lifshitz.  \textbf{Statistical Physics}, Third Edition, Part 1: Volume 5 (Course of Theoretical Physics, Volume 5) 3rd Edition.  Butterworth-Heinemann; 3 edition (January 15, 1980).  ISBN-13: 978-0750633727

\bibitem{Hjor2015}
M. Hjorth-Jensen, \textbf{Computational Physics}, University of Oslo (2015) \url{http://www.mn.uio.no/fysikk/english/people/aca/mhjensen/}



\bibitem{NeBa1999} 
M.E.J. Newman and G.T. Barkema.  \textbf{Monte Carlo Methods in Statistical Physics}.  Oxford University Press.  1999.  


\bibitem{Bred1997}
Glen E. Bredon.  \textbf{Topology and Geometry}. Graduate Texts in Mathematics (Book 139).  Springer; Corrected edition (October 17, 1997).  ISBN-13: 978-0387979267

\bibitem{Rotm1988}
Joseph Rotman. \textbf{An Introduction to Algebraic Topology}. \emph{Graduate Texts in Mathematics}. Volume 119. 1988. Springer-Verlag New York. eBook ISBN
978-1-4612-4576-6

\bibitem{Serr1980}  
Jean-Pierre Serre (Author), J. Stilwell (Translator).  \textbf{Trees} (Springer Monographs in Mathematics) 1st ed. 1980. Corr. 2nd printing 2002 Edition.  ISBN-13: 978-3540442370

\bibitem{JRotman2010}
Joseph J. Rotman, \textbf{Advanced Modern Algebra} (Graduate Studies in Mathematics) 2nd Edition, American Mathematical Society; 2 edition (August 10, 2010), ISBN-13: 978-0821847411

\bibitem{Lang2005}
Serge Lang. \textbf{Algebra} (Graduate Texts in Mathematics) 3rd Edition. \emph{Graduate Texts in Mathematics} (Book 211). Springer; 3rd edition (June 21, 2005). ISBN-13: 978-0387953854

\bibitem{Sche2006}
Edward Scheinerman.  \textbf{C++ for Mathematicians: An Introduction for Students and Professionals}. 1st Edition.  CRC Press; 1 edition (June 8, 2006).  ISBN-13: 978-1584885849 


\bibitem{JLee2009}
Jeffrey M. Lee. \textbf{Manifolds and Differential Geometry}, \emph{Graduate Studies in Mathematics} Volume: 107, American Mathematical Society, 2009. ISBN-13: 978-0-8218-4815-9

\bibitem{BrCh2017}
Jacob C. Bridgeman and Christopher T. Chubb.  \emph{Hand-waving and Interpretive Dance: An Introductory Course on Tensor Networks: \textbf{Lecture Notes}}.  \href{https://arxiv.org/abs/1603.03039}{arXiv:1603.03039 \textbf{[quant-ph]}}

\bibitem{Scho2004}
Ulrich Schollwoeck.  \emph{The density-matrix renormalization group}.   \emph{Rev. Mod. Phys.} \textbf{77}, 259 (2005)	\href{https://arxiv.org/abs/cond-mat/0409292}{arXiv:cond-mat/0409292 \textbf{[cond-mat.str-el]}}

\bibitem{Scho2010}
Ulrich Schollwoeck.  \emph{The density-matrix renormalization group in the age of matrix product states}.  \emph{Annals of Physics} \textbf{326}, 96 (2011).  \href{https://arxiv.org/abs/1008.3477}{arXiv:1008.3477 \textbf{[cond-mat.str-el]}}

\bibitem{ArSo2017}
Ulrich Schollw\"{o}ck, et. al. \emph{Numerical methods for correlated many-body systems}. \href{https://www.asc.physik.lmu.de/activities/schools/archiv/asc_school_17/index.html}{\textbf{2017 Arnold Sommerfeld School}}. 

\href{https://cast.itunes.uni-muenchen.de/clips/WE0Gf4L6f3/vod/high_quality.mp4}{Matrix product states (MPS), Density matrix renormalization group (DMRG) Lecture 1} 

\href{https://cast.itunes.uni-muenchen.de/clips/1PTFIT1n42/vod/high_quality.mp4}{Matrix product states (MPS), Density matrix renormalization group (DMRG) Lecture 2} 

\href{https://cast.itunes.uni-muenchen.de/clips/uN8yxWC8m9/vod/high_quality.mp4}{Matrix product states (MPS), Density matrix renormalization group (DMRG) Hands on Session 1} 

\href{https://cast.itunes.uni-muenchen.de/clips/xJRe4DD7Fo/vod/high_quality.mp4}{Matrix product states (MPS), Density matrix renormalization group (DMRG) Hands on Session 2} 

\href{https://www.asc.physik.lmu.de/activities/schools/archiv/asc_school_17/extramaterial/schollwoeck_asc_1.pdf}{Ulrich Schollw\"{o}ck (LMU): \emph{Matrix product states (MPS), Density matrix renormalization group (DMRG)}}

\href{https://www.asc.physik.lmu.de/activities/schools/archiv/asc_school_17/extramaterial/schollwoeck_asc_2.pdf}{Ulrich Schollw\"{o}ck (LMU): \emph{Matrix product states (MPS), Density matrix renormalization group (DMRG)}}


\bibitem{BaRa2015}
Jos\'{e} L.F. Barb\'{o}n and Eliezer Rabinovici.  "Holographic Complexity And Spacetime Singularities."  \href{https://arxiv.org/abs/1509.09291v3}{arXiv:1509.09291 \textbf{[hep-th]}}

\bibitem{MaSu2013}  
Juan Maldacena, Leonard Susskind.  "Cool horizons for entangled black holes."  \href{https://arxiv.org/abs/1306.0533}{ 	arXiv:1306.0533 \textbf{[hep-th]}}

\bibitem{Rych2016}
Slava Rychkov.  "EPFL Lectures on Conformal Field Theory in $D \geq 3$ Dimensions."    \href{https://arxiv.org/abs/1601.05000}{arXiv:1601.05000 \textbf{[hep-th]}}

\bibitem{EvVi2011}
G. Evenbly, G. Vidal.  "Tensor network states and geometry."  \href{https://arxiv.org/abs/1106.1082}{arXiv:1106.1082 \textbf{[quant-ph]}}

\bibitem{Raam2016} 
Mark Van Raamsdonk.  "Lectures on Gravity and Entanglement."  \href{https://arxiv.org/abs/1609.00026}{arXiv:1609.00026 \textbf{[hep-th]}}


\bibitem{Reid2013}
Miles Reid. \textbf{Undergraduate Algebraic Geometry}. October 20, 2013. \url{https://homepages.warwick.ac.uk/staff/Miles.Reid/MA4A5/UAG.pdf}

\bibitem{Har1992} 
Joe Harris. \textbf{Algebraic Geometry: A First Course}. Graduate Texts in Mathematics. 1992. Springer-Verlag New York.   eBook ISBN 978-1-4757-2189-8
    




\end{thebibliography}


\end{document}
